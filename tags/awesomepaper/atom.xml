<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
    <title>「靡不有初，鲜克有终」 - awesomepaper</title>
    <subtitle>blog of david</subtitle>
    <link href="https://wendajiang.github.io/tags/awesomepaper/atom.xml" rel="self" type="application/atom+xml"/>
    <link href="https://wendajiang.github.io"/>
    <generator uri="https://www.getzola.org/">Zola</generator>
    <updated>2021-08-15T23:30:00+00:00</updated>
    <id>https://wendajiang.github.io/tags/awesomepaper/atom.xml</id>
    <entry xml:lang="en">
        <title>raft-extended</title>
        <published>2021-08-15T23:30:00+00:00</published>
        <updated>2021-08-15T23:30:00+00:00</updated>
        <author>
          <name>Unknown</name>
        </author>
        <link rel="alternate" href="https://wendajiang.github.io/raft-extended/" type="text/html"/>
        <id>https://wendajiang.github.io/raft-extended/</id>
        <content type="html">&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;2021-03-02-raft-extended&#x2F;Raft-extend.png&quot; alt=&quot;Raft-extend&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h1 id=&quot;zhai-yao&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#zhai-yao&quot; aria-label=&quot;Anchor link for: zhai-yao&quot;&gt;摘要&lt;&#x2F;a&gt;&lt;&#x2F;h1&gt;
&lt;p&gt;Raft是管理复制日志的共识算法。它产生相当于Paxos的结果，并且和Paxos效率相当，但是结果与Paxos不同，使得Raft比Paxos更容易理解，提供了对于构建实用系统更好的基础。为了加强可理解性，Raft分离了共识算法的关键要素，比如领导者选举，日志复制和安全性，并且它强调强共识以减少必须考虑的状态数量。一项用户调研显示Raft对于学生来说比Paxos更容易学习。Raft还包括了一个更改集群成员的新机制，该机制用重叠的多数来保证安全性。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;1-jie-shao&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#1-jie-shao&quot; aria-label=&quot;Anchor link for: 1-jie-shao&quot;&gt;1.介绍&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;共识算法允许一组计算机作为一个整体工作，这个整体允许某些成员出现故障。因此，在构建大规模可用软件系统中它扮演了重要的角色。过去的十年中，Paxos主导了共识算法的讨论，大多数共识算法的实现都是基于Paxos或者受其影响，并且Paxos已经成为了向学生传授共识算法的工具。&lt;&#x2F;p&gt;
&lt;p&gt;不幸的是，Paxos相当难理解，尽管有多种尝试使其更加适用于声场系统，但是它的结构为了支持实用系统需要复杂的变化，结果就是，系统构建者和学生都不喜欢Paxos。&lt;&#x2F;p&gt;
&lt;p&gt;在亲自与Paxos争斗之后，我们着手寻找一种新的共识算法，该算法可以为构建实用系统和学习提供更好的基础。。我们的方法目标是易于理解：我们是否能够为实用系统定义共识算法以及它是否比Paxos更容易学习？此外，我们希望该算法能够促进系统构建者的开发直觉。重要的不仅是算法可以工作，而是为什么可以工作。&lt;&#x2F;p&gt;
&lt;p&gt;工作的结论就是名为Raft的算法。在设计Raft时，我们使用各种手段提升可理解性，包括解构（Raft分离了领导者选举，日志复制和安全性），减少状态空间（相对于Paxos，Raft降低了不确定性的程度，并降低了服务器之间的不一致方式）。&lt;&#x2F;p&gt;
&lt;p&gt;Raft在许多方面与现有的共识算法类似（最著名的Oki和Liskov的Viewstamped Replication），但是它也有一些新颖的特性：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;强领导者：Raft使用了比其他共识算法更强力的领导方式。比如，Log entries只能从领导者流向其他节点。这简化了复制日志的管理，使其更容易理解&lt;&#x2F;li&gt;
&lt;li&gt;领导者选举：Raft使用随机定时器来选举领导者。这相对于其他共识算法心跳加入的一点机制，可以简单快速地解决冲突&lt;&#x2F;li&gt;
&lt;li&gt;成员变化：Raft更改集群中服务器组的机制使用了新的联合共识的方法，其中两种不同的配置在转换过程中会重叠。这允许集群在配置更改时可以继续正常用运行&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;我们认为Raft在教育目的和实施基础上优于Paxos和其他共识算法。它更加简单易懂；描述了足够构建实用系统的细节，同时有了几种开源实现，并被多家公司使用。其安全性已经得到保证和证明；效率足以与其他共识算法媲美。&lt;&#x2F;p&gt;
&lt;p&gt;本文的剩余部分介绍了复制状态机问题（第二节——，讨论了Paxos的优缺点（第三节），描述了我们对于可理解性的一般方法（第四节），介绍了Raft共识算法（5-8节），Raft的评估（第九节），讨论了相关工作（第10节）&lt;&#x2F;p&gt;
&lt;h2 id=&quot;2-fu-zhi-zhuang-tai-ji&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#2-fu-zhi-zhuang-tai-ji&quot; aria-label=&quot;Anchor link for: 2-fu-zhi-zhuang-tai-ji&quot;&gt;2. 复制状态机&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;共识算法通常出现在复制状态机的环境中。通过这种方法，服务器集合上的状态机可以计算相同状态的副本，即使某些服务器宕机也可以继续运行。复制状态机用来解决分布式系统中的各种容错问题。例如，具有单个集群领导者的打醒系统，比如GFS，HDFS和RAMCloud，通常使用单独的复制状态机来管理领导者选举和保存配置信息以保证领导者崩溃时的可用性。复制状态机的例子还包括Chubby和ZooKeeper&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;raft-extended&#x2F;image-20200901151351972.png&quot; alt=&quot;图一&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;复制状态机通常如上图使用复制日志来实现&lt;&#x2F;strong&gt;。【译者注：每个独立的的服务个体实现了该状态机，通过Raft算法保证一组raft服务进程维持相同的状态机状态】每个服务器保存包含了一系列按序执行命令的日志。&lt;strong&gt;每份日志包含了同序的相同命令&lt;&#x2F;strong&gt;，所以每个状态机处理了相同的命令序列。因此状态机是确定性的，每个在相同的状态执行了相同的命令得到相同的输出。&lt;&#x2F;p&gt;
&lt;p&gt;保持复制日志一致是共识算法的工作。服务器上的共识模块接收来自客户端的命令加入到日志中。它负责与其他安装有共识模块的服务器通信保证日志以相同的顺序记录了相同的请求，即使有些服务器宕机。一旦命令被正确的复制，每个服务器的状态机以日志中的顺序处理命令，然后将输出返回客户端。结果就是，服务器表现为单个，高可用状态机。&lt;&#x2F;p&gt;
&lt;p&gt;生产系统的共识算法通常具有如下性质：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;确保安全（不会返回一个不正确结果）在非拜占庭环境中，包括网络延迟、分区，数据包丢失、复制和重排序。&lt;&#x2F;li&gt;
&lt;li&gt;只要大多数服务器可以运行并且相互通信并与客户端通信，它们就可以正常运行。因此由5台服务器组成的典型集群可以容忍任何2个服务器的故障。假定服务器因停止而发生故障，它们可以稍后从稳定存储的状态机中恢复并重新加入集群&lt;&#x2F;li&gt;
&lt;li&gt;不依赖时间来保证日志的共识：错误的时钟和极端的消息延迟最坏情况下会导致可用性问题&lt;&#x2F;li&gt;
&lt;li&gt;通常情况下，只要集群的大多数服务器都响应了一次RPC，命令就可以完成，少数响应慢的服务器不影响整体系统的性能&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;3-paxosde-wen-ti-shi-shi-yao&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#3-paxosde-wen-ti-shi-shi-yao&quot; aria-label=&quot;Anchor link for: 3-paxosde-wen-ti-shi-shi-yao&quot;&gt;3. Paxos的问题是什么&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;在过去的十年中，Leslie Lamport的Paxos协议几乎已经成为共识的代名词：这是课程中最常教授的协议，共识的大多数实现都是以他为起点。Paxos首先定义了一种能够在单个决定中达成一致的协议，比如单条复制日志。我们称它为&amp;quot;single-decree Paxos&amp;quot;（单判决Paxos）。Paxos接着合并多个这种协议完成一些列比如日志的决定（&lt;em&gt;multi-Paxos&lt;&#x2F;em&gt;）。Paxos同时保证安全性和活性，支持集群成员的改变。它的正确性已经得到了证明，并且通常情况下是高效的。&lt;&#x2F;p&gt;
&lt;p&gt;不幸的是，Paxos有两个重要缺陷。第一个是Paxos非常难以理解。[15]论文中的完整解释并不透明，很少人能成功理解它。结果就是，有数篇论文试图简单地解释Paxos。这些解释集中于&lt;em&gt;single-decree&lt;&#x2F;em&gt;子集，虽然这仍旧存在挑战性。在NSDI2012与会者的非正式调查中，我们发现即使是经验丰富的研究人员，也很少保持对Paxos的理解共识。我们自己也与Paxos争斗过，我们直到读了大量简单解释性的论文和设计自己的替代系统之后，这花了将近一年时间，才理解了这套协议。&lt;&#x2F;p&gt;
&lt;p&gt;我们假定Paxos的不透明性院子其single-decree子集作为基本元素的设计。Single-decree的Paxos是复杂精细的，导致整个协议分成了两个阶段，使其难以形成简单的直觉性解释而且不能单独来解释。因此，很难形成为什么single-decree协议能够工作的直观理解。multi-Paxos的组成引入了更多的复杂性和微妙性。我们相信能通过其他更为直接和简单的方式分解在多个决策阶段（比如一条日志代替一条entry）达到共识的问题。&lt;&#x2F;p&gt;
&lt;p&gt;第二个问题是Paxos不能给与构建实际系统良好的指导。原因之一是没有针对multi-Paxos的广泛的共识。Lamport的描述更多的是single-decree的Paxos，他只做了multi-Paxos实现方式的大致构想，没有太多细节。有几种具体化和优化Paxos的尝试，比如文献26,39,13，但是这些文献之间互相不同并且不同于Lamport的概述。比如Chubby这种系统实现了类Paxos算法，但是大部分细节没有公开发表。&lt;&#x2F;p&gt;
&lt;p&gt;另外，Paxos的结构不利于实现实际系统。这是single-decree分解的另一个结果。比如，单独选择一组日志条目然后融合为序列化的日志是有点好处的，这只增加了复杂性。围绕日志设计一个系统更加容易和高效，在该系统中以约束顺序添加日志条目即可。另一个问题是Paxos的核心使用对称的点对点方法（尽管它暗示了通过使用弱领导形式来优化性能）。在仅做出一个决定的问题中这是有道理的，但是几乎没有实际系统可以使用这种方法。如果需要做出一系列决策，首先选举出一个领导者更加简单快捷，随后领导者来协调决策。&lt;&#x2F;p&gt;
&lt;p&gt;结果就是，实际系统与Paxos没有什么相似之处。每种开始于Paxos的实现最终以不同的结构来呈现。这是费时而且易错的，Paxos的难以理解性加剧了这个问题。Paxos的形式化可能是证明该理论正确性的良好表达，但是实际的实现跟Paxos的证明完全不同，所以毫无实际价值。下面关于Chubby实现的论述非常经典：&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;Paxos算法的描述与真实系统的需要有着巨大的差异...因此最终的系统将基于一个没有被证明的协议&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;由于这些问题，我们得出的结论是Paxos不能为系统构建或教育提供良好的基础。 考虑到共识在大型软件系统中的重要性，我们决定看看是否可以设计一种性能比Paxos好的替代共识算法。 Raft就是这个实验的结果。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;4-yi-li-jie-xing-she-ji&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#4-yi-li-jie-xing-she-ji&quot; aria-label=&quot;Anchor link for: 4-yi-li-jie-xing-she-ji&quot;&gt;4. 易理解性设计&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;我们设计Raft时，有几个目标：比如提供一个完整，易于构建系统的实际基础，以便减少开发人员的设计工作量；它必须在所有条件下是安全的，典型操作场景是可用的，大多数操作是高效的。但是最重要的目标是，也是最大的挑战 -- 易于理解。对于大多数人来说可以容易地理解该算法。另外必须能够建立该算法的直觉，以便系统构建者可以进行实际实现中不可避免的扩展。&lt;&#x2F;p&gt;
&lt;p&gt;在Raft设计中有很多要点，我们必须在多种方法中进行选择。 在这种情况下，我们根据可理解性评估了替代方案：解释每种替代方案有多难（例如，其状态空间有多复杂，是否有微妙的暗示？），以及对读者来说有多容易完全了解该方法及其含义？&lt;&#x2F;p&gt;
&lt;p&gt;我们意识到这种分析具有相当高的主观性；不过，我们还是用了两种通用技术。第一个是众所周知的问题分解方法：无论如何，我们分解问题更小使得可以解决，解释和理解。例如，我们将Raft分为了&lt;strong&gt;领导者选举，日志复制，安全性和成员改变&lt;&#x2F;strong&gt;几个问题。&lt;&#x2F;p&gt;
&lt;p&gt;我们的第二个方法是通过减少需要考虑的状态简化状态空间，使系统更加协调一致，并在可能的情况下消除不确定性。尤其是，日志不允许有holes，Raft限制了导致互相之间不一致的方式。尽管大多数情况下，我们试图降低不确定性，有些场景引入不确定性可以提升可理解性。尤其是，随机方法引入了不确定性，但是通过相似的处理方法处理所有的可能性减少了状态空间（&amp;quot;随便选一个，无所谓&amp;quot;）。我们使用随机化来简化Raft领导者选举算法。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;5-raftgong-shi-suan-fa&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#5-raftgong-shi-suan-fa&quot; aria-label=&quot;Anchor link for: 5-raftgong-shi-suan-fa&quot;&gt;5. Raft共识算法&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;Raft是一个管理第二节描述的复制日志的算法。图2简介的展示了该算法，图3列出了算法的关键属性。图中剩余的属性会在本节分开阐述&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;raft-extended&#x2F;raft-2.png&quot; alt=&quot;image-20200902005835715&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;raft-extended&#x2F;raft-3.png&quot; alt=&quot;image-20200902005912684&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Raft 通过首先选举一个 leader，然后让这个 leader 完全管理 replicated log 的方式实现共识（consensus）。leader 从客户端接收 log entries，在其他服务器上 replicate log entries ，并告诉其他服务器何时可以安全地将 log entries 应用于它们的状态机。选择一个 leader 简化了管理 replicated log 的工作。比如，leader 可以决定自行决定如何处理新的 log entry，而不需要询问其他服务器，数据流的方向只有从 leader 到 follower。leader 可以挂掉或者与其他服务器断开网络连接，这时新的 leader 会被选出来。&lt;&#x2F;p&gt;
&lt;p&gt;基于 leader 的方法，Raft 将共识问题分解为三个独立的子问题&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Leader election&lt;&#x2F;strong&gt;：当现有的 leader 挂掉，必须选出一个新 leader&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Log replication&lt;&#x2F;strong&gt;：leader 必须接受来自客户端的 log entries，然后将它们复制到整个集群，强制其他服务器使用 leader 的覆盖&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Safety&lt;&#x2F;strong&gt;：安全属性的关键是图3中的 state machine safety 属性：如果任何服务器已经应用了某个 log entry 到状态机，不会有其他服务器在相同的 log index 执行不同的命令。5.4 小节描述 Raft 如何确保这个特性；&lt;strong&gt;解决方案就是加了成为 leader 约束&lt;&#x2F;strong&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;5-1-raft-basics&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#5-1-raft-basics&quot; aria-label=&quot;Anchor link for: 5-1-raft-basics&quot;&gt;5.1 Raft basics&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;Raft 集群包含了一组服务器，5是一个典型的数据，可以容忍两台机器挂掉。在任何给定的事件内，服务器处于三种状态之一：&lt;em&gt;leader, follower, candidate&lt;&#x2F;em&gt;。所谓 normal operation 存在一个 leader ，其他服务器都是 follower。follower 是被动的：不会提出请求只是响应来自 leader 或者 candidate 的请求。leader 来处理所有来自客户端的请求（如果客户端向 follower 发出请求，follower 会将请求重定向到 leader）【译者注：所以TiKV中对这种读请求做了特殊处理，更好的降低leader处理请求的负载，属于case by case 的优化？】。第三种状态， candidate 处于参与选举为 leader 的状态。图4展示了三种状态以及转移条件&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;2021-03-02-raft-extended&#x2F;image-20210815221414705.png&quot; alt=&quot;image-20210815221414705&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Raft 将时间切分成了任意长度的 &lt;em&gt;term&lt;&#x2F;em&gt;，如图5所示。Terms 使用连续整数表示。每个 Term 开始于一次选举，一个或者多个 candidates 试图成为 leader。如果一个 candidate 赢得了选举，这次 term 的剩余时间将作为 leader。有时候，选举不一定只有一个leader【译者注：典型的每个 candidate 同时为自己发起投票，这就出现了冲突】，这种场景，这次 term 就没有 leader， 就会马上进入下一次 term。Raft 保证一个给定的 term 中只有一个 leader。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;2021-03-02-raft-extended&#x2F;image-20210815221905157.png&quot; alt=&quot;image-20210815221905157&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;不同的服务器可以在不同的时间观察到状态的转移，并且某些情况下，服务器可能无法观察到选举甚至整个 term。&lt;strong&gt;Term 在 Raft 是逻辑时钟&lt;&#x2F;strong&gt;，这可以使得 Raft 算法判断比如老的leader是不是过时的信息。每个服务器存储了&lt;em&gt;当前的 termid&lt;&#x2F;em&gt;，随着时间这个值只能增加。服务器通信的时候，&lt;em&gt;current termid&lt;&#x2F;em&gt;的信息会被交换；如果一个服务的 term 数字小于另一个，就会更新成更大的那个。如果 candidate 或者 leader 发现它们的 term 的已经落后，就会马上转移到 follower 的状态。如果一个服务器接受了过时 term 的请求，就会拒绝这次请求&lt;&#x2F;p&gt;
&lt;p&gt;Raft 的服务器使用 RPC 通信【译者注：所以 TiKV 中的 gRPC 是更基础的组件？raft-rs 中的 mpsc 是一个模拟】，基本的一致性算法只需要两个 RPC &lt;strong&gt;RequestVote&lt;&#x2F;strong&gt; 和 &lt;strong&gt;AppendEntries&lt;&#x2F;strong&gt;。RequestVote 在 candidate 选举时使用，AppendEntries 在 leader 复制自己的 log entry 到整个集群时使用，同时内容为空的时候也作为心跳使用。后面还会再加一个 RPC 用来在服务器之间转移 snapshots。服务器没有收到响应会重试，并且可以并发 RPC 提高性能。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;5-2-leader-xuan-ju&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#5-2-leader-xuan-ju&quot; aria-label=&quot;Anchor link for: 5-2-leader-xuan-ju&quot;&gt;5.2 Leader 选举&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;strong&gt;Raft 使用心跳机制触发 leader 选举&lt;&#x2F;strong&gt;，当服务器启动时，都是 follower。服务器会在收到 leader 或者 candidate 的有效 RPC 时保持 follower 的状态。leader 会周期性发出心跳到所有 follower 来保证自己的 “权威”。如果follower 超过一个周期没有收到通信，称为 &lt;strong&gt;election timeout&lt;&#x2F;strong&gt;，意味着没有可用 leader，并且开始选出新 leader&lt;&#x2F;p&gt;
&lt;p&gt;为了开始选举，follower 增加 term 的数字，然后转化为 candidate 的状态，然后为自己发出投票。candidate 会一直保持这个状态直到：（a）它自己赢得选举 （b）另一个服务器赢得选举 （c）一个周期时间过去没有任何服务器称为 leader。下面分开讨论这三种情况&lt;&#x2F;p&gt;
&lt;p&gt;candidate 在一个 term 内赢得了半数以上的投票。每个服务器最多投一张选票，先来发起的先得（&lt;strong&gt;注意后面会为了 saftey 加上更强的约束&lt;&#x2F;strong&gt;）。多数的规则确保了最多只有一个 candidate 能赢得选举。一旦 candidate 赢得一次选举，就成为 leader。然后开始向所有其他的服务器发送心跳请求【译者注：这会重置其他服务器的定时器，避免新的选举开始】&lt;&#x2F;p&gt;
&lt;p&gt;当等待投票时，candidate 可能会收到 AppendEntries 的 RPC。如果 leader 的 term 比 candidate 当前的不小于，那么 candidate 会意识到 leader 是合法的，自己就会退回到 follower 的状态。如果 RPC 中的 term 比自己的小，candidate 会拒绝这次 RPC，继续保持 candidate 状态&lt;&#x2F;p&gt;
&lt;p&gt;第三种可能的情况就是没有 candidate 赢得选举，如同前面提到的如果很多 follower 同时成为 candidate，就会出现冲突。这种情况发生时，每个 candidate 就会增加自己的 term，开始新一轮选举，但是为了避免无限循环的状况发生，这里引入了随机性来规避&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Raft 使用随机 election timeout来确保投票冲突很少发生，并且如果发生可以快速恢复&lt;&#x2F;strong&gt;。固定间隔中随机一个时间（150ms ~ 300ms）【译者注：后面有提到这个时间选择的策略，以及三个时间之间的关系（rpc的通信时间 &amp;lt;&amp;lt; election timeout &amp;lt;&amp;lt; 服务器宕机间隔），并通过证反形式证明 Raft 的正确性】。通常这样做之后只有一台服务器发起投票。&lt;&#x2F;p&gt;
&lt;p&gt;【译者注：原文还有一段最开始并没有使用随机退避的策略，而是引入优先级系统来解决冲突，但是这使得系统复杂性变高，与容易理解的初衷相悖，这里是一个简要说明，翻译略去，有兴趣可以翻阅原文】&lt;&#x2F;p&gt;
&lt;h3 id=&quot;5-3-log-fu-zhi&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#5-3-log-fu-zhi&quot; aria-label=&quot;Anchor link for: 5-3-log-fu-zhi&quot;&gt;5.3 Log 复制&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;一旦 leader 被选出来，开始服务客户端。每个客户端请求包含了状态机需要执行的命令。leader 追加命令到自己的 log 中成为 new log entry。然后通过 AppendEnteries RPC 并行扩散到集群中的其他服务器。当 entry 已经被安全复制之后，leader 将 entry 应用到状态机，然后将结果返回客户端。如果 follower 宕机或者运行较慢，或者网络丢包，leader 会不断重试，直到所有 follower 保存了所有 log entries&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;2021-03-02-raft-extended&#x2F;image-20210815225731424.png&quot; alt=&quot;image-20210815225731424&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;log 如图6这样组织，&lt;strong&gt;每个 log entry 包含一条状态机的命令，和一个 term number&lt;&#x2F;strong&gt;。term number 被用来检查 log 之间的矛盾确保图3中的一些性质。&lt;strong&gt;每个 log entry 还有一个整数 index 表示在 log 中的位置&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;leader 决定是时候将 log entry 应用到状态机时，这样的 entry 被称为 &lt;em&gt;&lt;strong&gt;commited&lt;&#x2F;strong&gt;&lt;&#x2F;em&gt;。Raft 保证提交的 entry 是持久化的，并且被所有的状态机执行过了。一条 log entry 在 leader 获得多数 follower 复制响应后被提交（图6中是 entry 7）。这意味着之前的 log entry 都已经被提交了，包括上一任 leader 提交的。5.4 节中讨论了一些微妙的场景，当在 leader 发生变化之后应用这条规则，也展现了 commitent 的定义是安全的。 leader 追踪着已知最新的被提交的 log entry，这会在以后的 AppendEntries RPC 中包含，所以其他服务器也会知道。一旦 follower 学习到这个信息，就会应用到自己的状态机。&lt;&#x2F;p&gt;
&lt;p&gt;我们设计 Raft log 机制来位置不同服务器之间 log 的高度一致。这不仅简化系统行为，更重要的是保证安全【译者注：安全的定义是什么？】。Raft 建立了以下属性，一起确保了 Log Matching Property（图3中）：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;如果不同的 log 【译者注：不同服务器&#x2F;服务进程上的log】的两条 entry有相同的 index 和 term，命令也是一样的&lt;&#x2F;li&gt;
&lt;li&gt;如果不同的 log 的两条 entry 有相同的 index 和 term，则前面所有的 log entry都是相同的&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;第一条性质基于这样一个事实，leader 在给定的 term 的给定 log index 最多创建一条 log entry，然后 log entry 不会更改位置。第二条性质由 AppendEntries 进行一致性检查得到保证。当发送 AppendEntries RPC， leader 将 entry 的 index 和 term 信息带上。如果 follower 没有在相同的 term 和 index 找到这条 entry，就会拒绝新的 entry。一致性检查的步骤为：空的log 状态机满足 Log Matching Property， 一致性检查维护了 Log Matching Property。结果就是，&lt;strong&gt;leader 的 AppendEntries 返回成功，表示follower 的log在这条 log entry 之前跟自己是保持一致的。&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;2021-03-02-raft-extended&#x2F;image-20210816105214650.png&quot; alt=&quot;image-20210816105214650&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;整个正常操作期间，leader 的 log 和 follower 的保持一致，所以 AppendEntries 一致性检查一般不会失败。但是如果 leader 宕机就会丢失 log 一致性（老 leader 可能没有将自己的全部 entry 复制出去）。这种不一致性会导致 leader 和 follower 的一系列问题。图7表明了 follower 的 log 可能与新 leader 的不同。follower 可能会丢失一些 leader 的信息，也可能有一些 log leader 不知道，或者同时存在这两种情况。&lt;strong&gt;miss 或者 extraneous entry 可能横跨多个 term&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;在 Raft 中，leader 通过强制 follower 使用自己的来处理不一致问题。这意味着，follower 与 leader 不一致的 log 要被 leader 的覆盖。5.4 节会说明，加上一个限制之后这是安全的&lt;&#x2F;p&gt;
&lt;p&gt;为了使 follower 的 log 与自己的保持一致，leader 必须找到两个 log 的最近交汇点，然后将自己之后的发送给 follower 用来覆盖。通过 AppendEntries 的一致性检查来执行这些操作。 leader 建立起每个 follower 的 &lt;em&gt;nextIndex&lt;&#x2F;em&gt; 的认识，这表示 leader 发送给 follower 的下一个 index。当 leader 初始化时，nextIndex 就是自己 log 的最后一个 index（图7中是11）。如果一个 follower 的 log 与 leader 不一致，AppendEntries RPC 的一致性检查会失败，然后 leader 会将 nextIndex 减 1然后重新发起请求，直到 leader 和 follower 的 nextIndex 匹配上，然后 AppendEntries 成功，会移除 follower 该匹配点之后的所有 log ，然后使用 leader 的来覆盖。&lt;&#x2F;p&gt;
&lt;p&gt;如果可以，这里多次 RPC 回退 index 的方式可以优化，比如 follower 可以直接回退到 term 的最开始位置。总之就是加速匹配过程。但是实际上我们怀疑这个优化是不是必要，因为实际情况中这种场景应该很小。&lt;&#x2F;p&gt;
&lt;p&gt;通过这种机制，leader 不需要执行任何特殊操作就可以保持与 follower 的一致性。leader 也不会覆盖自己或者删除自己（图3中的 Leader Append-Only Property）&lt;&#x2F;p&gt;
&lt;p&gt;log 复制机制表现出第2节中描述的理想共识属性：Raft 可以接受，复制，应用新的 log entry；正常情况下，log 复制通过一次 RPC 时间就可以达成；一个慢服务器不会影响性能&lt;&#x2F;p&gt;
&lt;h3 id=&quot;5-4-safety&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#5-4-safety&quot; aria-label=&quot;Anchor link for: 5-4-safety&quot;&gt;5.4 Safety&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;前面的小结描述了 Raft 如何选举 leader ，如何复制 log entry。但**是都没有提到状态机是否按照相同的顺序执行相同的命令。**比如，当 leader 提交几条 log entry 时，一个 follower 不可用了，然后他自己被选举成了 leader， 然后使用新的 entry 覆盖了本该执行的命令，这时不同机器的状态机就执行了不同的命令&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;本节通过加入哪些服务器可以参与选举leader的约束来完成 Raft 算法&lt;&#x2F;strong&gt;。这个约束确保 leader 在给定的 term 包含了所有被提交的 log entry（图3中的 Leader Completeness Property）。给出选举约束之后，提交规则更清晰了。最后，我们给出了 Leader Completeness Property 的证明。&lt;&#x2F;p&gt;
&lt;h4 id=&quot;5-4-1-xuan-ju-yue-shu&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#5-4-1-xuan-ju-yue-shu&quot; aria-label=&quot;Anchor link for: 5-4-1-xuan-ju-yue-shu&quot;&gt;5.4.1 选举约束&lt;&#x2F;a&gt;&lt;&#x2F;h4&gt;
&lt;p&gt;任何基于 leader 的共识算法中，leader 必须存储了所有被提交的 log entry。有些共识算法没有这个要求，但是这些算法存储了额外的信息，确保新 leader 可以补齐或者丢弃一些 log entry。不幸的是，这会需要算法引入额外的机制和复杂度。Raft 使用更简单的方法来保证所有被提交的 entry 都被 leader 知道，而不想引入额外的转换机制。这意味着 log entry 只需要保证一个流动方向，就是从 leader 到 follower，leader 不需要覆盖写已有的 log&lt;&#x2F;p&gt;
&lt;p&gt;Raft 在投票过程中拒绝没有包含所有被提交 log entry 的票来实现这一点。candidate 必须联系集群中的多数服务器来获得投片，意味着提交的 entry 至少存在与集群中的一台机器上。如果 candidate 的 log 在多数机器上是 up-to-date （&lt;strong&gt;Raft 对比两个 log 的最新 log entry 的 index 和 term 来定义 up-to-date，如果最新 log-entry 有不同的 term，term 大的更加 up-to-date， 相同 term，更大的 index 更加 up-to-date）的，表示持有所有被提交的 entry。RequestVote RPC 这样实现：RPC 中包含 candidate log 的信息，投票者对比这些信息与自己的，如果自己的更 up-to-date 就拒绝这个投票&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;h4 id=&quot;5-4-2-zai-xian-qian-de-term-ti-jiao-entry-yi-zhe-zhu-zhe-li-shi-ji-mei-tai-kan-dong-xu-yao-cha-kan-bo-shi-de-yuan-lun-wen&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#5-4-2-zai-xian-qian-de-term-ti-jiao-entry-yi-zhe-zhu-zhe-li-shi-ji-mei-tai-kan-dong-xu-yao-cha-kan-bo-shi-de-yuan-lun-wen&quot; aria-label=&quot;Anchor link for: 5-4-2-zai-xian-qian-de-term-ti-jiao-entry-yi-zhe-zhu-zhe-li-shi-ji-mei-tai-kan-dong-xu-yao-cha-kan-bo-shi-de-yuan-lun-wen&quot;&gt;5.4.2 在先前的 term 提交 entry 【译者注：这里实际没太看懂，需要查看博士的原论文。】&lt;&#x2F;a&gt;&lt;&#x2F;h4&gt;
&lt;p&gt;5.3节提到过，leader 知道当前 term 已经被提交 entry 已经被多数服务器接受。如果 leader 在提交这条 entry 之前宕机，新的 leader 会试图完成这次复制。但是，leader 不能直接得出结论如果一条 entry 是上一个 term 提交的，图3.7【译者注：这里从 Phd 的原论文中截图，比论文中的画法更容易理解】表明了这个场景，老的 log entry 被存储在了多数服务器上，但是可能被以后的 leader 覆盖。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;2021-03-02-raft-extended&#x2F;image-20210816154629358.png&quot; alt=&quot;image-20210816154629358&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;这个问题的避免，Raft 规定计算复制时，绝对不提交先前 term 的 entry。只有 leader 当前 term 的 log entry 可以被提交，一旦当前 term 的 entry提交，所有先前的 log entry 不能再被修改。有些场景可能 leader 可以安全得出哪些老的 log entry 被提交的结论，但是 Raft 使用保守的策略。&lt;&#x2F;p&gt;
&lt;p&gt;Raft 接受这种提交规则的复杂性，因为当 leader 从上一个 term 复制 log entry， 会保存他们原始的 term 数字。在其他共识算法中，如果一个新 leader 复制先前 term 的 log entry，必须使用新的 term 来做。Raft 使其变得简单，因为在 log 保持相同的 term。此外 Raft 的新 leader 会比其他共识算法发送更少的先前 term 的 log entry（其他算法发送冗余 log entry 必须重新计算它们）&lt;&#x2F;p&gt;
&lt;h4 id=&quot;5-4-3-safety-lun-zheng-lue&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#5-4-3-safety-lun-zheng-lue&quot; aria-label=&quot;Anchor link for: 5-4-3-safety-lun-zheng-lue&quot;&gt;5.4.3 Safety 论证（略）&lt;&#x2F;a&gt;&lt;&#x2F;h4&gt;
&lt;h3 id=&quot;5-5-follower-he-candidate-dang-ji&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#5-5-follower-he-candidate-dang-ji&quot; aria-label=&quot;Anchor link for: 5-5-follower-he-candidate-dang-ji&quot;&gt;5.5 Follower 和 candidate 宕机&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;到此为止，我们专注于 leader 失败的情况。Follower 或者 candidate 宕机的处理比 leader 更容易，而且处理方式相同。如果 follower 或者 candidate 宕机，将要到来的 RequestVote ， AppendEntries RPC 会失败。Raft 直接无限重试；如果宕机的服务器重启了，RPC 重试成功。如果服务器在接受了请求但是没有发出响应之间宕机，就会收到重复请求。Raft RPC 是可重入的，所以这没有什么问题。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;5-6-shi-jian-he-ke-yong-xing&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#5-6-shi-jian-he-ke-yong-xing&quot; aria-label=&quot;Anchor link for: 5-6-shi-jian-he-ke-yong-xing&quot;&gt;5.6 时间和可用性&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;Raft 安全的一个要求是不依赖时间：系统不能因为某些事件发生的快些或者慢些就返回错误结果。但是，可用性（系统能够连续提供服务的能力）不可避免要依赖时间。比如，如果消息交换消耗比服务器宕机间隔还长，candidate 不能赢得选举，没有稳定 leader ，整个机制就挂了&lt;&#x2F;p&gt;
&lt;p&gt;Leader 选举是 Raft 中时间起着至关重要的一个方面。Raft 需要满足这个时间条件才能平稳运行：&lt;&#x2F;p&gt;
&lt;p&gt;$$broadcastTime \ll electionTimeout \ll MTBF(average time between failures for a single server)$$&lt;&#x2F;p&gt;
&lt;p&gt;前面的不等式中 $broadcastTime$ 表示并行 RPC 到集群中每个server的平均时间。$electionTimeout$ 前面描述过，$MTBF$ 表示单台server 的宕机间隔【译者注：一般是月计】。&lt;&#x2F;p&gt;
&lt;p&gt;前一个不等号保证了 leader 可以成功发送心跳消息，并且不会使集群发生分裂；第二个不等号是系统平稳运行保证。&lt;&#x2F;p&gt;
&lt;p&gt;$broadcastTime$ 和 $MTBF$ 是底层问题，我们无法控制，但是 $electionTimeout$ 是我们可选的。Raft 一般用于持久化存储的场景，所以可以假定 $broardcastTime$ 在 0.5ms 到 20ms 之间，取决于存储使用的技术。这么看，$electionTimeout$ 应该在 10ms 和 500ms 之间。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;6-ji-qun-cheng-yuan-bian-hua&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#6-ji-qun-cheng-yuan-bian-hua&quot; aria-label=&quot;Anchor link for: 6-ji-qun-cheng-yuan-bian-hua&quot;&gt;6. 集群成员变化&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;【译者注：TiKV 2019-10 才支持论文中提到的 joint consensus，最开始只有一次变动一个成员，所谓的 one point chang at a time】&lt;&#x2F;p&gt;
&lt;p&gt;之前所有的讨论都是一个集群的配置是固定的。在实际系统中，不可避免会更改配置，比如替换机器。最简单的就是停机，然后更改配置，然后重启集群。这回导致集群有一个不可用时间段。并且如果有操作失误，不可用时间段会更长。为了避免这个问题，决定将配置变更合并到 Raft 共识算法中&lt;&#x2F;p&gt;
&lt;p&gt;为了使配置变更也安全，在配置迁移过程中不能有点的变化，这可能导致同一个 term 被选举出两个 leader。不幸的是，任何直接切换机器配置的方法都不能避免这个问题。不能直接切换，那么就需要搞个两阶段。直接切换会引起分裂问题，如图10所示&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;2021-03-02-raft-extended&#x2F;image-20210816124806914.png&quot; alt=&quot;image-20210816124806914&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;为了保证安全性，&lt;strong&gt;配置变更是一个两阶段方法&lt;&#x2F;strong&gt;。有多种手段实现两阶段方法。比如有些系统使用第一个阶段来关闭老的配置，这时候不能处理客户端请求；然后第二阶段切换到新配置。【译者注：这只是将上面停机该配置自动化处理了。还是存在不能提供服务的问题】。Raft 中集群首先切换到联合配置，称为 &lt;em&gt;&lt;strong&gt;join consensus&lt;&#x2F;strong&gt;&lt;&#x2F;em&gt;，一旦 joint sonsensus 被提交，系统就可以继续切换到新配置。Joint consunsus 既包含了就配置，也包含了新配置：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;log entry 被复制到新老配置中所有服务器中&lt;&#x2F;li&gt;
&lt;li&gt;任何一台服务器可以作为 leader&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;选举和 entry 提交需要旧配置和新配置中不同的多数才行&lt;&#x2F;strong&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;joint consensus 允许单独的服务器在不同时间在配置之间转移，而且不违反安全性。同时，joint consensus 还支持不停机服务客户端，在配置更换期间&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;2021-03-02-raft-extended&#x2F;image-20210816002558380.png&quot; alt=&quot;image-20210816002558380&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;集群配置的通信和存储在复制 log 中是特殊的 entry&lt;&#x2F;strong&gt;；图11表明了配置更新过程。当leader 收到 切换配置的请求（从 $C_{old}到 C_{new}$），存储 joint consensus 的配置 $C_{old,new}$ 为一条 log entry，然后复制到整个集群。一旦集群都加了这条 log entry，使用最新的配置在将来的决策中。这意味着 leader 将使用 $C_{old,new}$ 的规则来决定 log entry 被提交。如果 leader 宕机，新 leader 是从$C_{old}$或者 $C_{old,new}$ 中选择，取决于 candidate 是否已经收到 $C_{old,new}$。这时，$C_{new}$不能单方面做出决策。&lt;&#x2F;p&gt;
&lt;p&gt;一旦 $C_{old,new}$ 被提交，就可以继续下一个阶段，leader 可以创建一个 $C_{new}$ 的 log entry，然后扩散到集群。当 $C_{new}$ 被提交时，$C_{old}$ 就失效了，不再新配置的机器就可以关机了。图11中表示，没有任何时间 $C_{old}$ 和 $C_{new}$ 同时分别做出决策，这保证了安全。&lt;&#x2F;p&gt;
&lt;p&gt;重新配置也提出了三个问题：&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;新服务器可能没有存储 log 。如果新加入集群，需要一定时间初始化，这个时间内不能提交新的 log entry。为了避免可用性间隔，Raft 引入了一个额外的阶段在更改配置之前，加入集群的服务器没有投票权（leader 会复制 log 给它们，但是在多数选择时不被考虑）。一旦新服务器已经跟上了其他服务器，配置变更过程才会被触发&lt;&#x2F;li&gt;
&lt;li&gt;集群 leader 可能不在新配置中。这种情况，leader 一旦要提交 log entry 在 $C_{new}$ 就回退到 follower 状态。这表示当 leader 管理本身不在其中的集群时，有一定时间，复制 log entry 但是不能在多数计算时，计算自己。当 $C_{new}$ 生效时，会发生领导者转换。在这之前，可能有来自 $C_{old}$ 的机器称为 leader&lt;&#x2F;li&gt;
&lt;li&gt;被新配置移除的机器可能会破坏集群。这些机器不能收到心跳，所以会 timeout然后开始新选举。然后使用新的 term 发起 RequestVotes RPC，会造成当前的 leader 回退到 follower 的状态，新leader被选举，但是被移除的机器会不断超时发起新一轮选举。为了避免这个问题，服务器会丢弃 RequestVotes 请求，如果服务器收到请求在来自当前 leader 告知的最小 election timeout 之内。这不会影响正常选举，每个服务器会等待至少 minimum election timeout 在开始下一次选举之前。&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;h2 id=&quot;7-log-ya-suo&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#7-log-ya-suo&quot; aria-label=&quot;Anchor link for: 7-log-ya-suo&quot;&gt;7. Log 压缩&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;Raft 的 log 随着不断地 normal operation【译者注：normal operation 指的是正常请求，confchange 应该不属于 normal operation】，实际系统中，这个大小是无界的。随着 log 的增长，占用更多的空间，需要更多的时间重放。如果没有机制来丢弃 log 中累积的过时信息，就会造成可用性问题。&lt;&#x2F;p&gt;
&lt;p&gt;Snapshotting 是最简单的压缩方法。当前整个系统的状态被写入到硬盘的 snapshot 文件中，然后这个时间之前的 log 都可以废弃。Chubby 和 Zookeeper 中使用了 snapshotting，本节接下来就会阐述 Raft 中如何使用 snapshot&lt;&#x2F;p&gt;
&lt;p&gt;增量压缩，比如 log clean 和 LSM-tree，也是可能的。这些操作一次作用于部分数据，所以可以更快的压缩。首先选择数据的 region，然后重写活动的数据，然后释放 region。这需要额外的机制，并且相比 snapshotting 更加复杂。虽然 log clean 需要修改 Raft 算法，但是状态机可以实现 LSM-tree 使用与 snapshotting 相同的接口&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;2021-03-02-raft-extended&#x2F;image-20210815234203909.png&quot; alt=&quot;image-20210815234203909&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;图12 展示了 Raft 中 snapshotting 的基本思想，每个服务器独立 snapshot，覆盖已经提交的 log。包括：状态机将当前状态写入 snapshot。Raft 好包括了一部分 snapshot 的 metadata ：snapshot 中的 &lt;em&gt;last included index&lt;&#x2F;em&gt;（最新的状态机提交的 index），&lt;em&gt;last included term&lt;&#x2F;em&gt;是这个 entry 的term。要存这些信息是为了支持 AppendEntries 连贯性检查在 snapshot 之后的第一条新 log entry。为了支持第6节描述的成员变更，snapshot 还要包含最新 log 的配置信息。一旦服务器完成 snapshot，可以删除 &lt;em&gt;last included entry&lt;&#x2F;em&gt;之前的所有 log 和之前的所有 snapshot&lt;&#x2F;p&gt;
&lt;p&gt;尽管服务器可以独立的 snapshot，leader 也需要偶尔发送 snapshot 给 follower。当 leader 丢弃了 next log entry 时，需要通知 follower。幸运的是，通常不会发生这种场景，一般 follower 追随 leader 很好。但是一个非常慢的 follower 或者新加入集群的服务器没有最新信息，需要 leader 发送 snapshot 。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;2021-03-02-raft-extended&#x2F;image-20210816000824514.png&quot; alt=&quot;image-20210816000824514&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;leader 使用 RPC InstallSnapshot 来向 follower 发送 snapshot，图13描述了这个 RPC。当 follower 收到一个 snapshot，必须决定如何处理已有的存在的 log entry。通常 snapshot 包含的就是全部最新信息。这时，follower 丢弃全部自己的 log 全部由 snapshot 替代。如果 follower 收到的 snapshot 是自己 log 的前缀（错误？），快照覆盖的部分使用 snapshot 的信息，后面的自己要保留&lt;&#x2F;p&gt;
&lt;p&gt;snapshot 方法从 Raft 的强 leader 原则中分离出来，因为 follower 可以不需要 leader 的信息自行 snapshot。所以，分离也是合理的，同时有一个 leader 帮助在达成共识时避免冲突，在 snapshot 时已经达成了共识，所以没有决策上的冲突。数据流还是从 leader 到 follower ，只是 follower 可以自行组织自己的数据。&lt;&#x2F;p&gt;
&lt;p&gt;【译者注：这里如果使用基于 leader 的 snapshot，将浪费巨大的网络带宽，并且 snaphot 会很慢。而且，leader 实现更复杂，比如， leader 需要并行处理 snapshot 到 follower 以及 new log entry 到 follower】&lt;&#x2F;p&gt;
&lt;p&gt;这里 snapshot 有两个主要问题：&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;服务器决定什么时候 snapshot。如果过于频繁 snapshot，浪费硬盘带宽和功耗，如果频率太低，会撑爆存储，而且会增加重放 log 的时间。一个简单的策略就是当 log 到达一个固定大小的时候进行 snapshot。如果此大小设置明显大于 snapshot 的预期大小，则 snapshot 的磁盘带宽开销将很小&lt;&#x2F;li&gt;
&lt;li&gt;第二个性能问题就是 snapshot 的写入会消耗时间，我们不能延迟正常操作。解决方案是使用 copy-on-write 技术，所以新的 log entry 可以被接受而不会影响 snapshot 的写入。操作系统的 copy-on-write 支持可以创造整个状态机的的 in-memory snapshot&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;h2 id=&quot;8-ke-hu-duan-xie-zuo&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#8-ke-hu-duan-xie-zuo&quot; aria-label=&quot;Anchor link for: 8-ke-hu-duan-xie-zuo&quot;&gt;8. 客户端协作&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;本节描述客户端如何与 Raft 交互，包括客户端如何与集群 leader 交互和 Raft 如何保证线性化语义。这些问题适用于所有共识系统，Raft 的解决方案是类似的&lt;&#x2F;p&gt;
&lt;p&gt;Raft 的客户端发送所有请求到 leader，当客户端启动时，随机连接一个服务器。如果客户端第一次选择不是 leader，服务器会拒绝这次请求并返回 leader 的地址。如果 leader 宕机，客户端会超时，然后随机重试一台服务器。&lt;&#x2F;p&gt;
&lt;p&gt;Raft 的目标是实现线性化语义（每个操作连续执行，并且执行一次）。但是 &lt;strong&gt;Raft 可能会执行一条命令多次&lt;&#x2F;strong&gt;：比如，如果 leader 在提交了 log entry 但是返回客户端响应之间宕机，客户端会重试这条命令，造成一条命令执行多次。&lt;strong&gt;解决方法就是客户端在每条命令中增加一个唯一的序列号，然后状态机跟踪每个客户端执行的最新的序列号。如果收到过时的序列号，不会执行这次请求中的命令&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;只读操作不写入 log，但是，如果&lt;strong&gt;没有额外信息，这会冒着返回过时数据的风险&lt;&#x2F;strong&gt;，因为响应请求的 leader 可能已经被新的 leader 取代。不能返回过时数据，所以 Raft 采用两个措施来避免这个问题（a）leader 必须有哪条 entry 是最新被提交的信息。Leader Completeness Property 保证了 leader 有所有的提交 entry，但是term的开始，可能不知道，&lt;strong&gt;所以每次 term 开始马上提交一次 entry，Raft 会使 leader 在新的 term 提交一个空的 entry 来保证这一点&lt;&#x2F;strong&gt;（b）leader 必须在处理只读请求时检查是否是过时请求（如果更新的 leader 被选举出来，这次请求就是过时的），Raft 在处理请求前与集群交换心跳信息来处理这个问题。或者，&lt;strong&gt;leader 可以通过心跳机制来提供租约，但是这对系统的时间要求比较高（系统不能存在严重的时间不一致）&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;9-10-11-12&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#9-10-11-12&quot; aria-label=&quot;Anchor link for: 9-10-11-12&quot;&gt;9，10，11，12&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;为实现的代码，实验的性能数据与对比&lt;&#x2F;p&gt;
&lt;p&gt;相关工作&lt;&#x2F;p&gt;
&lt;p&gt;总结结论&lt;&#x2F;p&gt;
&lt;p&gt;致谢&lt;&#x2F;p&gt;
</content>
    </entry>
    <entry xml:lang="en">
        <title>A Fast Minimal Memory, Consistent Hash Algorithm</title>
        <published>2021-05-11T19:30:38+00:00</published>
        <updated>2021-05-11T19:30:38+00:00</updated>
        <author>
          <name>Unknown</name>
        </author>
        <link rel="alternate" href="https://wendajiang.github.io/jump-consistent-hash/" type="text/html"/>
        <id>https://wendajiang.github.io/jump-consistent-hash/</id>
        <content type="html">&lt;!--
mermaid example:
&lt;div class=&quot;mermaid&quot;&gt;
    mermaid program
&lt;&#x2F;div&gt;
--&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1406.2294.pdf&quot;&gt;原文&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h1 id=&quot;jian-yi-can-kao&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#jian-yi-can-kao&quot; aria-label=&quot;Anchor link for: jian-yi-can-kao&quot;&gt;建议参考&lt;&#x2F;a&gt;&lt;&#x2F;h1&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;zhuanlan.zhihu.com&#x2F;p&#x2F;104124045&quot;&gt;更丰富的解释&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h1 id=&quot;abstract&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#abstract&quot; aria-label=&quot;Anchor link for: abstract&quot;&gt;Abstract&lt;&#x2F;a&gt;&lt;&#x2F;h1&gt;
&lt;p&gt;我们提出了 jump consistent hash,一种快速，内存占用小，一致性哈希算法，可以用 5 行代码实现。相比于 Karger 提出的算法，jump consistent hash 不需要内存，更快，在桶的数量变化时，可以将 key 的空间划分的更加均匀。主要局限性是必须对存储桶进行顺序编号，这使其更适用于数据存储应用而不是分布式 web 缓存&lt;&#x2F;p&gt;
&lt;h1 id=&quot;introduction&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#introduction&quot; aria-label=&quot;Anchor link for: introduction&quot;&gt;Introduction&lt;&#x2F;a&gt;&lt;&#x2F;h1&gt;
&lt;p&gt;Karger 在&lt;a href=&quot;https:&#x2F;&#x2F;www.akamai.com&#x2F;it&#x2F;it&#x2F;multimedia&#x2F;documents&#x2F;technical-publication&#x2F;consistent-hashing-and-random-trees-distributed-caching-protocols-for-relieving-hot-spots-on-the-world-wide-web-technical-publication.pdf&quot;&gt;文章&lt;&#x2F;a&gt;中提出一致性哈希的概念，并给出了一个算法实现。一致性哈希确保数据这样分布在服务器上，当服务器增加或者删除时，不会重排数据。最开始提出来是为了缓存互联网的 Web 缓存，为了解决客户端可能不知道所有缓存服务器的问题。&lt;&#x2F;p&gt;
&lt;p&gt;从那时起，一致性哈希广泛应用于数据存储应用。这里，描述问题为，将数据拆分到 shard 的集合上，典型的每个 shard 就是一个服务器。当数据量变化时，我们对机器进行增减。这要求将数据从老的 shard 集合移动到新的 shard 集合时，移动的数据量尽可能小&lt;&#x2F;p&gt;
&lt;p&gt;假设，比如，kv 数据被分散到 10 个 shard。简单的方法就是计算一个 key 的 hash 函数，&lt;code&gt;h(key)&lt;&#x2F;code&gt;，将 kv 数据存储到 &lt;code&gt;h(key) mod 10&lt;&#x2F;code&gt; 的 shard 上。但是如果数据规模增大，现在需要12个 shard 来存储，最简单的方法就是计算改为 &lt;code&gt;h(key) mod 12&lt;&#x2F;code&gt;，但是相同 key 计算出不同的结果，所以数据需要重新排布。&lt;&#x2F;p&gt;
&lt;p&gt;但是如果只需要移动存储在 10 shard 中的 $1&#x2F;6$ 的数据，以便在 12 个 shard 中平衡，一致性哈希可以做到。我们的 jump consistent hash 函数需要两个参数，key 和桶的数量，返回一个桶的编号。这函数满足两个性质&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;每个桶的 key 个数相等&lt;&#x2F;li&gt;
&lt;li&gt;当桶的个数发生变化时，需要重映射的 key 的数量尽可能少&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;相比 Karger 提出的算法，jump consistent hash 算法非常快并且内存占用具有很大优势。Karger 的算法每个候选 shard 需要数千个字节的存储，以便获得 key 的分配。在大数据存储应用中，可能有数千个 shard，那意味着每个 client 需要 MB 内存来存储这个结构，并且要长期存储保证算法有效。相反，jump consistent hash 几乎不需要内存，并且分配 key 更均匀。另一方面，jump consistent hash 不支持服务器名称，只能返回服务器编号，因此主要适用于数据存储案例。&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;cpp&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-cpp &quot;&gt;&lt;code class=&quot;language-cpp&quot; data-lang=&quot;cpp&quot;&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;int32_t &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;JumpConsistentHash&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;uint64_t &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;key&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;int32_t &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;num_buckets&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;int64_t&lt;&#x2F;span&gt;&lt;span&gt; b &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= -&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;, j &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;while &lt;&#x2F;span&gt;&lt;span&gt;(j &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span&gt; num_buckets) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;        b &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; j;
&lt;&#x2F;span&gt;&lt;span&gt;        key &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; key &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;* &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2862933555777941757&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;ULL &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;;     
&lt;&#x2F;span&gt;&lt;span&gt;        j &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span&gt;(b &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;* &lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;double&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;LL &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;lt;&amp;lt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;31&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&#x2F; &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;double&lt;&#x2F;span&gt;&lt;span&gt;((key &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;gt;&amp;gt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;33&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;));
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;return&lt;&#x2F;span&gt;&lt;span&gt; b;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;这就是实现。输入 64 位的整数 key，和桶的数量。输出一个 [0, num_buckets) 之间的数。本文的剩余部分就是解释代码意义，并给出理论证明和性能结果&lt;&#x2F;p&gt;
&lt;p&gt;性能分析对比和相关工作请参考&lt;a href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1406.2294.pdf&quot;&gt;原文&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h1 id=&quot;explanation-of-the-algorithm&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#explanation-of-the-algorithm&quot; aria-label=&quot;Anchor link for: explanation-of-the-algorithm&quot;&gt;Explanation of the algorithm&lt;&#x2F;a&gt;&lt;&#x2F;h1&gt;
&lt;p&gt;jump consistent hash 当桶数量增加时，计算输出。当 num_buckets 个桶时， &lt;code&gt;ch(key, num_buckets)&lt;&#x2F;code&gt; 为 key 的桶号。而且&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;对任何 key -&amp;gt; k, ch(k, 1) 是 0，因为仅有一个桶。&lt;&#x2F;li&gt;
&lt;li&gt;ch(k, 2) 需要将一半 key 移动到新桶 1 中。&lt;&#x2F;li&gt;
&lt;li&gt;...&lt;&#x2F;li&gt;
&lt;li&gt;ch(k, n + 1) 需要保持 ch(k, n) 中 $n&#x2F;(n + 1)$ 的 key，然后移动 $1&#x2F;(n + 1)$ 的 key 到桶 n 中&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;所以每次需要对 $1&#x2F;(n+1)$重新映射，才能使得映射均匀，那么接下来的问题就是：哪些 key 需要被重新映射？就是说增加新桶时，让哪些 key 到新桶中，哪些 key 保持不动？&lt;&#x2F;p&gt;
&lt;p&gt;可以使用伪随机数（意味着，只要种子不变，随机序列就不变）来决定 k 每次是不是需要跳到新桶中，所以使用 k 作为随机数种子，就可以得到一个 k 的随机序列。为了保证桶数量从 $j$ 变到 $j + 1$时，有 $1&#x2F;(j+1)$占比的数据跳到新桶 $j+1$。可以使用伪随机数归一化之后与 $1&#x2F;(j+1)$比较决定 k 是不是需要跳到新桶，代码为：&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;cpp&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-cpp &quot;&gt;&lt;code class=&quot;language-cpp&quot; data-lang=&quot;cpp&quot;&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;ch&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;key&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;num_buckets&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;    random&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;seed&lt;&#x2F;span&gt;&lt;span&gt;(key);
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int&lt;&#x2F;span&gt;&lt;span&gt; b &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F; this will track ch(key, j + 1)
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int&lt;&#x2F;span&gt;&lt;span&gt; j &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;; j &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span&gt; num_buckets; j&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;++&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span&gt;(random&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;next&lt;&#x2F;span&gt;&lt;span&gt;() &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;lt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1.0 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&#x2F; &lt;&#x2F;span&gt;&lt;span&gt;(j &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;)) b &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; j;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;return&lt;&#x2F;span&gt;&lt;span&gt; b;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;ddia&#x2F;jump_consistent_hash&#x2F;image-20210512113501760.png&quot; alt=&quot;image-20210512113501760&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;本图是对这个函数的演绎。n 从1变化到5的过程中，$k_1$ 和 $k_2$ 每次都要根据随机序列与目标分布 $1&#x2F;n$比较，来决定是留在原来桶还是移动到新桶。需要注意的是，一旦 k 确定，随机序列就确定。每次计算 ch 函数，for 循环就是在遍历一个确定的序列。所以，k 给定，n 确定，ch 的结果唯一确定，就可以保持 “一致”。&lt;&#x2F;p&gt;
&lt;p&gt;举例，有三个 key：k1, k2, k3 ，随着桶数量增长的表格：&lt;&#x2F;p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;&lt;&#x2F;th&gt;&lt;th&gt;1&lt;&#x2F;th&gt;&lt;th&gt;2&lt;&#x2F;th&gt;&lt;th&gt;3&lt;&#x2F;th&gt;&lt;th&gt;4&lt;&#x2F;th&gt;&lt;th&gt;5&lt;&#x2F;th&gt;&lt;th&gt;6&lt;&#x2F;th&gt;&lt;th&gt;7&lt;&#x2F;th&gt;&lt;th&gt;8&lt;&#x2F;th&gt;&lt;th&gt;9&lt;&#x2F;th&gt;&lt;th&gt;10&lt;&#x2F;th&gt;&lt;th&gt;11&lt;&#x2F;th&gt;&lt;th&gt;12&lt;&#x2F;th&gt;&lt;th&gt;13&lt;&#x2F;th&gt;&lt;th&gt;14&lt;&#x2F;th&gt;&lt;&#x2F;tr&gt;&lt;&#x2F;thead&gt;&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;k1&lt;&#x2F;td&gt;&lt;td&gt;0&lt;&#x2F;td&gt;&lt;td&gt;0&lt;&#x2F;td&gt;&lt;td&gt;2&lt;&#x2F;td&gt;&lt;td&gt;2&lt;&#x2F;td&gt;&lt;td&gt;4&lt;&#x2F;td&gt;&lt;td&gt;4&lt;&#x2F;td&gt;&lt;td&gt;4&lt;&#x2F;td&gt;&lt;td&gt;4&lt;&#x2F;td&gt;&lt;td&gt;4&lt;&#x2F;td&gt;&lt;td&gt;4&lt;&#x2F;td&gt;&lt;td&gt;4&lt;&#x2F;td&gt;&lt;td&gt;4&lt;&#x2F;td&gt;&lt;td&gt;4&lt;&#x2F;td&gt;&lt;td&gt;4&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;k2&lt;&#x2F;td&gt;&lt;td&gt;0&lt;&#x2F;td&gt;&lt;td&gt;1&lt;&#x2F;td&gt;&lt;td&gt;1&lt;&#x2F;td&gt;&lt;td&gt;1&lt;&#x2F;td&gt;&lt;td&gt;1&lt;&#x2F;td&gt;&lt;td&gt;1&lt;&#x2F;td&gt;&lt;td&gt;1&lt;&#x2F;td&gt;&lt;td&gt;7&lt;&#x2F;td&gt;&lt;td&gt;7&lt;&#x2F;td&gt;&lt;td&gt;7&lt;&#x2F;td&gt;&lt;td&gt;7&lt;&#x2F;td&gt;&lt;td&gt;7&lt;&#x2F;td&gt;&lt;td&gt;7&lt;&#x2F;td&gt;&lt;td&gt;7&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;k3&lt;&#x2F;td&gt;&lt;td&gt;0&lt;&#x2F;td&gt;&lt;td&gt;1&lt;&#x2F;td&gt;&lt;td&gt;1&lt;&#x2F;td&gt;&lt;td&gt;1&lt;&#x2F;td&gt;&lt;td&gt;1&lt;&#x2F;td&gt;&lt;td&gt;5&lt;&#x2F;td&gt;&lt;td&gt;5&lt;&#x2F;td&gt;&lt;td&gt;7&lt;&#x2F;td&gt;&lt;td&gt;7&lt;&#x2F;td&gt;&lt;td&gt;7&lt;&#x2F;td&gt;&lt;td&gt;10&lt;&#x2F;td&gt;&lt;td&gt;10&lt;&#x2F;td&gt;&lt;td&gt;10&lt;&#x2F;td&gt;&lt;td&gt;10&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;&#x2F;tbody&gt;&lt;&#x2F;table&gt;
&lt;p&gt;可以看到，对于确定 k 来说，随着桶数量增大，并不是每次都要跳到新桶中，这是算法的优化点。&lt;&#x2F;p&gt;
&lt;p&gt;对于 ch 函数，$b$是记录 $k$的最后一次跳入的桶的编号。加入我们现在处于 $k$ 刚刚跳入$b$的时刻，一定有 $b + 1$个桶。接下来，我们要新增一个桶，变为 $b+2$时，易得 $k$不换桶的概率是 $(b+1)&#x2F;(b+2)$。假设要找的下一个 $b$是 $j$，就是说，假设桶数量到了 $j+1$时，$k$跳入新桶，那么此期间，$k$保持不换桶的概率是&lt;&#x2F;p&gt;
&lt;p&gt;$$P(stay_until_j) = \frac{b+1}{b+2} \times \frac{b+2}{b+3} \times ... \times \frac{j-1}{j} = \frac{b+1}{j}$$&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;ddia&#x2F;jump_consistent_hash&#x2F;image-20210512114358163.png&quot; alt=&quot;image-20210512114358163&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;虚线框表示不变桶，概率就是乘积。&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;原文翻译：
假设这个算法跟踪的是对于键 k 的桶序号的跳跃，假设 b 是最后一个 jump 的目标，表示 ch(k, b) != ch(k, b + 1)，并且 ch(k, b + 1) = b。现在，我们想要发现下一跳。最小的 j，使得 ch(k, j + 1) != ch(k, b + 1)，或者等效的，最大的 j 使得 ch(k, j) = ch(k, b + 1)。我们使用随机变量来分析 j。为了得到 j 的概率约束，注意到对于任意桶数量 i，我们有 j &amp;gt;= i，当且仅当一致性哈希值不随 i 变化，等效为当且仅当 ch(k, i) = ch(k, b + 1)，因此 j 的分布满足
$$P(j \ge i) = P(ch(k,i) = ch(k, b + 1))$$
幸运的是，这个分布很容易计算。因为 $P(ch(k,10)) = ch(k,11)$ 是 $10&#x2F;11$，$P(ch(k,11)) = ch(k,12)$ 是 $11&#x2F;12$，所以 $P(ch(k,10) = ch(k, 11))$ 是 $10&#x2F;11 \times 11&#x2F;12 = 10&#x2F;11$，推广，如果 $n \ge m, P(ch(k,n) = ch(k,m)) = m &#x2F; n$，因此对于任意 $i \gt b$,
$$P(j \ge i) = P(ch(k,i) = ch(k, b + 1)) = (b + 1)&#x2F;i$$
现在，我们生成一个伪随机数，$r$， (依赖 k 和 j)，归一化到 0 到 1 之间。因为我们想要 $P(j \ge i) = (b + 1)&#x2F;i$，我们假设 $P(j \ge i) iff r \ge (b + 1)&#x2F;i$。解决 $i$ 的不等式 $i &#x2F; P(j \ge i) iff i \ge (b + 1)&#x2F;r$，因为 $i \ge j$，那么 j 等于 最大的 i ， 因此最大的 i 满足 $i \ge (b+1)&#x2F;r$，因此通过 floor 方法，$j = floor((b + 1)&#x2F;r)。$
使用这个公式，jump consistent hash 通过直到发现一个正数等于或者大于 num_buckets 来选择下一跳得到 ch(key, num_buckets)。然后我们知道上一跳就是结果&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;改写 ch 函数：&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;cpp&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-cpp &quot;&gt;&lt;code class=&quot;language-cpp&quot; data-lang=&quot;cpp&quot;&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;ch&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;k&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;n&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;  random&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;seed&lt;&#x2F;span&gt;&lt;span&gt;(k);
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int&lt;&#x2F;span&gt;&lt;span&gt; b &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;, j &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;;
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;while &lt;&#x2F;span&gt;&lt;span&gt;(j &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span&gt; n) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;if &lt;&#x2F;span&gt;&lt;span&gt;(random&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;next&lt;&#x2F;span&gt;&lt;span&gt;() &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;lt; &lt;&#x2F;span&gt;&lt;span&gt;(b&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1.0&lt;&#x2F;span&gt;&lt;span&gt;)&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&#x2F;&lt;&#x2F;span&gt;&lt;span&gt;j) b &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; j;
&lt;&#x2F;span&gt;&lt;span&gt;    j &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+=&lt;&#x2F;span&gt;&lt;span&gt; continuous_stays;
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;return&lt;&#x2F;span&gt;&lt;span&gt; b;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;} &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F; 当符合连续不换桶的概率时，j 直接跳过
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;假设 $r = random.next()$，要满足 $r \lt (b+1)&#x2F;j$，就必须 $j \lt (b+1)&#x2F;r$，就是说 $j$ 不能大于 $(b+1)&#x2F;r$才不至于漏掉迭代，所以$j \le (b+1)&#x2F;r$，通过向下取整得到 j，进一步改写&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;cpp&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-cpp &quot;&gt;&lt;code class=&quot;language-cpp&quot; data-lang=&quot;cpp&quot;&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;ch&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;key&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#ffb86c;&quot;&gt;num_buckets&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;    random&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;seed&lt;&#x2F;span&gt;&lt;span&gt;(key);
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int&lt;&#x2F;span&gt;&lt;span&gt; b &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= -&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F; bucket number before the previous jump
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#8be9fd;&quot;&gt;int&lt;&#x2F;span&gt;&lt;span&gt; j &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;0&lt;&#x2F;span&gt;&lt;span&gt;; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#6272a4;&quot;&gt;&#x2F;&#x2F; bucket number before the current jump
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;while &lt;&#x2F;span&gt;&lt;span&gt;(j &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span&gt; num_buckets) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;        b &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; j;
&lt;&#x2F;span&gt;&lt;span&gt;        r &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; random&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;next&lt;&#x2F;span&gt;&lt;span&gt;();
&lt;&#x2F;span&gt;&lt;span&gt;        j &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8be9fd;&quot;&gt;floor&lt;&#x2F;span&gt;&lt;span&gt;((b &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;+ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;&#x2F;&lt;&#x2F;span&gt;&lt;span&gt; r);
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;return&lt;&#x2F;span&gt;&lt;span&gt; b;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ffffff;&quot;&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;分析下复杂度，因为 $r$ 发布均匀，在桶数量变化为 $i$ 的时候跳桶的概率为 $1&#x2F;i$ ，那么期望跳桶次数为 $1&#x2F;2 + .. + 1&#x2F;i + .. + 1&#x2F;n$，调和级数和自然对数的差收敛到一个小数，复杂度为 $O(ln(n))$&lt;&#x2F;p&gt;
&lt;p&gt;同最上面的代码相比，已经很像了，下面需要实现随机部分，想要最快，还有良好的连续值。使用 64 位线性同余随机数生成器，&lt;a href=&quot;https:&#x2F;&#x2F;www.ams.org&#x2F;journals&#x2F;mcom&#x2F;1999-68-225&#x2F;S0025-5718-99-00996-5&#x2F;S0025-5718-99-00996-5.pdf&quot;&gt;此文章&lt;&#x2F;a&gt;有详细讲解。当使用的 key 不满足 64 位时，需要使用 hash 函数将其转化为 64 位。&lt;&#x2F;p&gt;
&lt;p&gt;值得注意的是，不像 Karger 的算法，如果 key 已经是个整数，不需要哈希一次，因为算法每次迭代，已经重新哈希过 key。这个 hash 不是很好（线性余数），但是因为重复执行，对于 key 的额外哈希也就不是特别必要。&lt;&#x2F;p&gt;
</content>
    </entry>
    <entry xml:lang="en">
        <title>【考古】【必读】分布式理论奠基 paper</title>
        <published>2021-04-06T21:31:59+00:00</published>
        <updated>2021-04-06T21:31:59+00:00</updated>
        <author>
          <name>Unknown</name>
        </author>
        <link rel="alternate" href="https://wendajiang.github.io/time-clock-the-orderingeventdistrisytem/" type="text/html"/>
        <id>https://wendajiang.github.io/time-clock-the-orderingeventdistrisytem/</id>
        <content type="html">&lt;!--
mermaid example:
&lt;div class=&quot;mermaid&quot;&gt;
    mermaid program
&lt;&#x2F;div&gt;
--&gt;
&lt;p&gt;原文标题：Time, Clocks, and the Ordering of Events in a Distributed System
原文作者：Leslie Lamport
&lt;a href=&quot;https:&#x2F;&#x2F;lamport.azurewebsites.net&#x2F;pubs&#x2F;time-clocks.pdf&quot;&gt;原文链接&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;译者声明：&lt;&#x2F;p&gt;
&lt;p&gt;本文中的进程（process）表示过程，不是典型意义上计算机的进程&lt;&#x2F;p&gt;
&lt;p&gt;偏序、局部顺序 partial ordering&lt;&#x2F;p&gt;
&lt;h2 id=&quot;abstract&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#abstract&quot; aria-label=&quot;Anchor link for: abstract&quot;&gt;Abstract&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;在分布式系统中一个事件发生于另一个事件之前的概念需要被确定，定义为这两个事件的偏序 (partial ordering)。给出一个分布式算法来同步系统的逻辑时钟，时钟可以用来全排序所有的事件。全序可以被用来解决事件同步问题。这个算法还被特化为解决同步物理时钟问题，可以容忍多长的时钟同步延迟。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;introduction&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#introduction&quot; aria-label=&quot;Anchor link for: introduction&quot;&gt;Introduction&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;时间是一个基本的概念。可以表示事件发生的顺序。我们说事件发生在 3:15 在时钟表示 3:15，以及 3:16 之前。事件时间顺序的思考无处不在。比如，在航空公司预留系统中，我们声明在票买完之前，可以提供预留服务。与此同时，在考虑分布式系统中的事件时，我们必须慎重审视这个概念。&lt;&#x2F;p&gt;
&lt;p&gt;分布式系统中包含了一系列分离的进程，通过消息互通。网络连接起来的互联网（译者注：此处的互联网不是现在概念上的互联网，本文写于计算机组网早期，比如 ARPA 网络系统）就是一个分布式系统。单独的一台计算也可以被看做分布式系统，其中中控单元，内存单元，I&#x2F;O 都是分离的进程。&lt;strong&gt;如果消息的传递延迟相比于单个进程中的事件之间的事件是不能忽略的，我们就说系统是分布式的。&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;我们主要考虑空间上分隔的计算机。然而，很多结论可以延伸到更广泛的其他系统中。尤其是，计算机上的多进程系统跟多个计算机组成的分布式系统本质上是相同的，因为都具备&lt;strong&gt;事件发生顺序不可预测的特征。&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;在分布式系统中，有时是说不清楚两个事件的哪个先发生的（译者注：物理时间意义的先）。因此&amp;quot;happened before&amp;quot;的关系实际上应该是两个事件局部顺序。这个问题经常被提出因为人们并没有仔细考虑其背后的意义。&lt;&#x2F;p&gt;
&lt;p&gt;本文中，我们就来讨论如何通过&amp;quot;happened before&amp;quot;关系定义局部顺序，然后给出一个算法来计算所有事件的全部顺序（全序）。这个算法可以提供一个有效的实现分布式系统的机制。我们可以看到通过这个算法的简单应用可以解决同步问题。如果通过该算法获得的排序与用户感知的排序不同，则可能发生非预期的动作。这可以通过引入一个真实的物理时钟来避免。我们同样提出了一个简单的方法来同步这些时钟，并且给出容忍的时钟漂移上限。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-partial-ordering&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#the-partial-ordering&quot; aria-label=&quot;Anchor link for: the-partial-ordering&quot;&gt;The Partial Ordering&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;大多数人可能这样描述事件 a 在事件 b 之前发生，如果 a 发生的时间早于 b。这就是物理意义上的早于的定义。但是，如果系统有规范说明，应该通过规范说明来定义，如果规范中说明了根据物理时钟，系统必须包括物理时钟，然而，即使系统包含了物理时钟，也可能没有保持与真实事件的时间同步而发生错误。所以，&amp;quot;happened before&amp;quot;关系我们不用物理时钟来定义。&lt;&#x2F;p&gt;
&lt;p&gt;我们首先要将系统定义的更加精确。我们假定系统是由一系列进程构成。每个进程中包含了事件的序列。依赖于具体场景，一个进程中某个子函数的的执行可能是一个事件，或者一条机器指令的执行是一个事件。我们假定这些进程内的事件构成了一个序列，在进程内 a 发生于 b 之前。换句话说，一个进程定义了一个序列事件的全序。看起来事情已经解决了，甚至可以扩展定义将进程分离为子进程，但是我们不这样做。&lt;&#x2F;p&gt;
&lt;p&gt;我们假定发送或者接收消息是一个事件。通过&amp;quot;$\rightarrow$&amp;quot;定义&amp;quot;happened before&amp;quot;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;定义&lt;&#x2F;em&gt;. &#x27;$\rightarrow$&#x27; 是系统中事件的最小关系，满足以下三个条件：&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;如果$a$和$b$是同一个进程中的事件，而且$a$发生于$b$之前，那么$a \rightarrow b$&lt;&#x2F;li&gt;
&lt;li&gt;如果$a$是一个进程中发送消息，$b$是另一个进程中接收消息，那么$a \rightarrow b$&lt;&#x2F;li&gt;
&lt;li&gt;如果$a \rightarrow b$并且$b \rightarrow c$，那么$a \rightarrow c$&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;两个事件$a$和 $b$，如果$a \nrightarrow b$，而且$b \nrightarrow a$，就说$a$和$b$是并发的。&lt;&#x2F;p&gt;
&lt;p&gt;对于任意事件$a$，$a \nrightarrow a$。这意味着$\rightarrow$就可以表示系统中所有事件的局部顺序。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;time_clock_the_orderingEventDistriSytem&#x2F;image-20210409111648200.png&quot; alt=&quot;image-20210409111648200&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;center&gt;图一&lt;&#x2F;center&gt;
&lt;p&gt;上图对于理解这个定义很有帮助。水平方向表示空间，垂直线表示时间---越高时间越靠后。点表示事件，垂直线表示进程，波浪线表示消息。很容易看出$a \rightarrow b$在图中意味着$a$可以将消息传递给$b$，比如 $q_1 \rightarrow r_4$&lt;&#x2F;p&gt;
&lt;p&gt;$a \rightarrow b$另一个定义是事件$a$可以影响到$b$。两个事件如果不能互相影响就是并发的。即使我们在图中看出$q_3$在物理时间上早于$p_3$，进程 P 不知道进程 Q 上发生了$q_3$事件，直到$p_4$收到消息（在$p_4$之前，P 进程最多直到 Q 进程将要发生事件$q_3$）&lt;&#x2F;p&gt;
&lt;p&gt;This definition will appear quit natural to the reader familiar with the invariant space-time formulation of special relativity, as described for example in [1] or the first chapter of [2]. In relativity, the ordering of events is defined in terms of messages that could be sent. However, we have taken the more pragmatic approach of only considering messages that actually are sent. We should be able to determine if a system performed correctly by knowing only those events which did occur, without knowing which events could have occurred.【这一段不知道怎么翻译。】&lt;&#x2F;p&gt;
&lt;h2 id=&quot;logical-clocks&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#logical-clocks&quot; aria-label=&quot;Anchor link for: logical-clocks&quot;&gt;Logical Clocks&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;现在我们来将时钟引入系统。我们开始于很抽象的时钟概念，只用来对一个事件赋值一个数值，这个数值被用来表示事件发生的时间。数学的，我们为每个进程$P_i$定义一个时钟$C_i$，函数$C_i \langle a \rangle$表示进程中事件$a$的数值。整个系统的时钟通过$C$表示，对于其中的事件$b$的数值使用$C \langle b \rangle$表示，当事件$b$属于进程$P_j$，$C\langle b \rangle = C_j\langle b \rangle$。现在，我们没有将$C_i \langle a \rangle$与物理时间绑定起来，所以我们可以将其看做是逻辑时钟而不是物理时钟。他可以使用计数器实现而不需要是时间机制。&lt;&#x2F;p&gt;
&lt;p&gt;现在我们考虑的意味着系统时钟是正确的。但是我们的定义不能基于物理时间，那样我们必须保证物理时钟。我们的目的是根据事件发生的顺序来定义。最强的合理条件是，如果事件$a$发生于事件$b$之前，我们使用下面的形式表示这种关系：&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Clock Condition&lt;&#x2F;em&gt;：对于任意事件$a, b$，如果 $a \rightarrow b$，则$C\langle a \rangle \lt C\langle b \rangle$。&lt;&#x2F;p&gt;
&lt;p&gt;现在这个条件不可逆，因为那意味着并发事件必须同时发生。在图一中我们看到$p_2,p_3$与$q_3$是并发的，但是这并不表示它们是同时发生的。&lt;&#x2F;p&gt;
&lt;p&gt;Clock Condtion（$\rightarrow$）满足如下条件：&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;如果事件$a,b$都是进程$P_i$的，$a$早于$b$，那么$C_i\langle a \rangle \lt C_i\langle b \rangle$。&lt;&#x2F;li&gt;
&lt;li&gt;如果事件$a$是进程$P_i$发送消息，$b$是进程$P_j$接收消息，那么$C_i\langle a \rangle \lt C_j\langle b \rangle$&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;通过 tick 可以将图一划线为图二，&lt;strong&gt;条件一&lt;&#x2F;strong&gt;意味着同一个进程的两个事件之间要有一条 tick 的线，&lt;strong&gt;条件二&lt;&#x2F;strong&gt;意味着消息传递线必然与一条 tick 线相交。我们可以调整图二，让 tick 线平行，重画为图三&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;time_clock_the_orderingEventDistriSytem&#x2F;image-20210411010454500.png&quot; alt=&quot;image-20210411010454500&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;center&gt;图二&lt;&#x2F;center&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;time_clock_the_orderingEventDistriSytem&#x2F;image-20210411010818485.png&quot; alt=&quot;image-20210411010818485&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;center&gt;图三&lt;&#x2F;center&gt;
&lt;p&gt;读者可以发现，重画后的图三更清晰表明了各进程之间的事件先后关系。&lt;&#x2F;p&gt;
&lt;p&gt;让我们假定进程就是算法，每个事件是算法的执行命令。我们将阐述如何将时钟引入进程并且满足&lt;em&gt;Clock Condition&lt;&#x2F;em&gt;。进程$P_i$通过$C_i$来表示时钟。&lt;&#x2F;p&gt;
&lt;p&gt;为了满足&lt;em&gt;Clock Conditon&lt;&#x2F;em&gt;，条件一很容易，只需要满足以下规则&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;IR1. 进程$P_i$在两个连续事件之间的$C_i$增长&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;为了满足条件二，我们要求消息$m$包含一个时间戳$T_m$，其等于消息发出的时间。在收到包含时间戳$T_m$的消息时，进程必须保证它的时钟大于$T_m$，数学描述为下面的规则&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;IR2. 1. 如果事件$a$是进程$P_i$发送消息$m$，消息$m$包含时间戳$T_m = C_i\langle a \rangle$
2. 收到消息$m$的进程$P_j$设置$C_j$大于等于$T_m$&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;这样就可以确保系统的逻辑时钟是正确的。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;ordering-the-events-totally&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#ordering-the-events-totally&quot; aria-label=&quot;Anchor link for: ordering-the-events-totally&quot;&gt;Ordering the Events Totally&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;现在我们可以使用满足&lt;em&gt;Cloud Conditon&lt;&#x2F;em&gt;的系统时钟来对系统的所有事件进行全排序。可以简单通过发生时间进行排序。为了避免混淆，我们使用符号$\prec$表示进程的顺序。为了数学的定义，使用符号$\Rightarrow$表示：如果事件$a$在进程$P_i$中，事件$b$在进程$P_j$中，$a \Rightarrow b$当且仅当 (i) $C_i\langle a \rangle &amp;lt; C_j\langle b \rangle$或者 (ii) $C_i\langle a \rangle = C_j\langle b \rangle$ 并且 $P_i \prec P_j$。可以看出如果$a \rightarrow b$那么$a \Rightarrow b$。换句话说，符号$\Rightarrow$是偏序关系$\rightarrow$在全序中的表示。&lt;&#x2F;p&gt;
&lt;p&gt;$\Rightarrow$依赖于系统时钟，不是唯一的，不同的时钟选择会导致不同的$\Rightarrow$，而偏序关系$\rightarrow$由系统的事件唯一确定。&lt;&#x2F;p&gt;
&lt;p&gt;知道事件的全序关系对于实现分布式系统非常重要。事实上，实现系统正确的逻辑时钟就是为了获得这样事件的全序关系。全序关系可以解决下面的问题。&lt;strong&gt;一个具有多进程的系统，单一的资源，同一时间只能有一个进程使用这单一资源，必须同步信息以免冲突&lt;&#x2F;strong&gt;。我们希望找到一个算法分配这个资源满足三个条件&lt;&#x2F;p&gt;
&lt;p&gt;I. 一个已经获取这一资源的进程在另一进程获取前释放该资源
II. 不同进程的资源授权必须按照申请资源的顺序授权
III. 如果每个被授权的进程都释放了资源，那么每个请求都被处理了&lt;&#x2F;p&gt;
&lt;p&gt;我们假定开始该资源被授权给了一个进程。&lt;&#x2F;p&gt;
&lt;p&gt;这是很自然的条件，并且描述了方案的正确性定义。但是条件二无法说明，并发的两个进程谁先获取资源。&lt;&#x2F;p&gt;
&lt;p&gt;要意识到这并非一个简单的问题。使用中心进程来按照接收顺序来授权资源是行不通的，除非有一些额外的假设。比如这种情况，$P_0$是调度进程，$P_1$向$P_0$发送了请求，然后向$P_2$发送了消息，$P_2$在没有收到的消息时，$P_2$也发送了请求到$P_0$。$P_2$的请求可以先到达$P_0$，如果先授权资源给了$P_2$，那么条件二不满足了。&lt;&#x2F;p&gt;
&lt;p&gt;为了解决这个问题，我们实现了规则 IR1 和 IR2 的系统时钟，然后使用这种时钟来对事件进行全排序。这就可以排序资源所有的请求和释放。有了全序，事情就迎刃而解。&lt;&#x2F;p&gt;
&lt;p&gt;为了简化系统，我们做了一些假设。这些并不是必须的，但是可以避免为了实现细节而分心。我们首先假设任何两个进程$P_i, P_j$，从$P_i$到$P_j$的消息会以发送的顺序被收到。并且，每个消息都能被收到（这两个假设可以避免引入消息序列号和消息协议）。我们还假定一个进程可以向其他所有进程发消息。&lt;&#x2F;p&gt;
&lt;p&gt;每个进程维护自己的请求队列，这个请求队列并不会被其他进程看到。我们假定请求队列初始化时包含一个消息$T_0$：$P_0$请求资源，$P_0$是初始化被授权资源的进程，$T_0$比任何时钟都小。&lt;&#x2F;p&gt;
&lt;p&gt;算法可以通过下面的五条规则定义。为了方便，每条规则定义的动作只能构成一个事件。&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;为了请求资源，进程$P_i$发送消息$T_m$：$P_i$向其他所有进程请求资源，将消息放入自己的请求队列，$T_m$是消息的时间戳&lt;&#x2F;li&gt;
&lt;li&gt;当进程$P_j$收到消息$T_m$，也将其放入自己的消息队列，回$P_i$一个 ack&lt;&#x2F;li&gt;
&lt;li&gt;为了释放资源，进程$P_i$从消息队列删除消息$T_m$，然后发送一个$P_i$释放资源的消息给其他所有进程&lt;&#x2F;li&gt;
&lt;li&gt;当进程$P_j$收到$P_i$释放资源的消息，也将其$T_m$从自己的消息队列删除&lt;&#x2F;li&gt;
&lt;li&gt;进程$P_i$满足下面两个条件时被授权资源：(1). 消息队列中有$T_m$ (2) 收到了其他所有的进程的消息晚于$T_m$（注意到这两个条件只需要$P_i$自己就可以确定）&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;证明满足了条件 I~III 还是比价容易。首先，规则 5 的第二点，结合先前消息按序收到的假设，保证了$P_i$在发出请求前已经收到了其他的所有消息。因为规则 3 和 4 只是从请求队列删除消息，容易看出满足了条件 I。条件 II 可以从全序中得出。规则 2 保证了$P_i$请求资源之后，规则 5 的第二点能达到。规则 3 和 4 表明如果一个被授权资源的进程释放了，规则 5 的第一点能达到，所以证明了条件 III&lt;&#x2F;p&gt;
&lt;p&gt;这是一个分布式算法。每个进程都按照这些规则动作，没有中心进程来协调它们。这个方法可以被扩展为任何多进程中的同步方案。这个同步方案可以被称为&lt;em&gt;State Machine&lt;&#x2F;em&gt;，包含了一系列可能的命令$C$，一系列可能的状态$S$，和一个函数$e：C \times S \rightarrow S$。关系$e(C,S)=S&#x27;$在状态$S$表示执行命令$C$状态转移为$S&#x27;$。我们的例子中，命令$C$包含了$P_i$的所有请求资源和释放资源的命令，状态包含了一个等待请求命令的队列，队列头的请求就是当前被授权的进程。执行一个请求命令在队列尾部入队请求，执行释放命令在头部出队请求。&lt;&#x2F;p&gt;
&lt;p&gt;每个进程分离的使用所有进程的请求仿真状态机的转移。因为所有进程通过时间戳排序命令，所有进程有相同顺序的命令，所以最终会达成同步状态。一个进程在执行完所有进程小于$T$的命令才会执行$T$的命令。这个算法很清楚，我们不会再解释它。&lt;&#x2F;p&gt;
&lt;p&gt;但是，这个方案要求所有进程参与进来，一个进程必须获得其他所有进程的命令，任意一个进程出问题，整个系统就会跟着出问题，无法维护状态机。&lt;&#x2F;p&gt;
&lt;p&gt;这个问题很难解决，这就是本文下面要讨论的。我们要建立在物理时间上下文时的错误概念。没有物理时间，就无法区分一个进程是挂了还是只是偶尔暂停。用户可以在系统只是响应比较慢的时候说系统&amp;quot;crashed&amp;quot;了。当单个进程或者消息通信出问题，有方法规避。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;anomalous-behavior&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#anomalous-behavior&quot; aria-label=&quot;Anchor link for: anomalous-behavior&quot;&gt;Anomalous Behavior&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;我们的资源规划算法通过请求的全序$\Rightarrow$来解决。这会导致下面的错误行为。考虑一个全国联网的计算机系统，假设一个人在计算机 A 上发出请求 A，然后给另一个城市的朋友打电话让他在计算机 B 上发出请求 B。很有可能请求 B 的时间戳更小，从而排序在 A 之前。系统不知道请求 A 应该在 B 之前，因为排序消息依赖于系统的消息传递。&lt;&#x2F;p&gt;
&lt;p&gt;让我们剖析这个系统的问题。使用符号$\varphi$表示系统中的所有事件。让我们引入一个事件集合，包含$\varphi$中的事件和与其相关联的外部事件，比如上面例子的电话呼叫。仍然使用$\rightarrow$表示事件集合$\varphi$中的偏序关系。我们例子中，我们有$A \rightarrow B$，但是$A \nrightarrow B$。显然没有算法可以只根据$\varphi$中的事件来确定$A,B$之间的偏序关系。&lt;&#x2F;p&gt;
&lt;p&gt;有两种可能的方法来避免这个问题。第一个是在系统中引入确定$\rightarrow$关系的一些必要信息，在上面的例子中，发出的请求$A$打上时间戳$T_A$，请求$B$的时间戳$T_B$要大于$T_A$。&lt;&#x2F;p&gt;
&lt;p&gt;第二个是构造一个满足下面条件的系统时钟。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Strong Clock Condition&lt;&#x2F;em&gt;。对于$\varphi$中的任意事件$a,b$，如果$a \rightarrow b$, 则 $C\langle a \rangle &amp;lt; C\langle b \rangle$&lt;&#x2F;p&gt;
&lt;p&gt;这个比&lt;em&gt;Clock Condition&lt;&#x2F;em&gt;条件更强。&lt;&#x2F;p&gt;
&lt;p&gt;宇宙的秘密之一就是，可以构造这种物理时钟，彼此分离的运行，但是却可以满足&lt;em&gt;Strong Clock Condition&lt;&#x2F;em&gt;。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;physical-clocks&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#physical-clocks&quot; aria-label=&quot;Anchor link for: physical-clocks&quot;&gt;Physical Clocks&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;让我们将物理时钟与上面的理论结合，让$C_i(t)$表示在物理时间$t$看到的时钟$C_i$，为了数学上的方便，我们假设时钟是连续的而不是按照离散的 tick。数学的描述就是，$C_i(t)$是连续的，这个函数关于$t$的微分$dC_i(t)&#x2F;dt$表示了在时间$t$时钟的快慢程度。&lt;&#x2F;p&gt;
&lt;p&gt;为了使得时钟$C_i(t)$与物理时钟尽可能一致，要让其微分尽可能为 1. 数学描述为下面的条件&lt;&#x2F;p&gt;
&lt;p&gt;PC1. 存在一个常数 $\kappa \ll 1$，对于所有的$i$: $|dC_i(t)&#x2F;dt - 1| \lt \kappa$。$\kappa$的典型值为$10^{-6}$&lt;&#x2F;p&gt;
&lt;p&gt;然而让所有分离的时钟以正确近似的速率运行是不够的的。它们还必须尽可能同步，对于所有$i,j$来说$C_i(t) \approx C_j(t)$，同样可以使用小常数来表示&lt;&#x2F;p&gt;
&lt;p&gt;PC2. 对于所有的$i,j$，$|C_i(t) - C_j(t)| &amp;lt; \epsilon$&lt;&#x2F;p&gt;
&lt;p&gt;让我们来使用图二来表征物理时间，图三的画法中，水平线对应的每条进程的值是要小于$\epsilon$&lt;&#x2F;p&gt;
&lt;p&gt;因为不可能存在两个完全一致速率运行的时钟，总会发生漂移，我们必须有一个算法使得 PC2 的条件得以满足。首先，我们必须确定两个小常数$\kappa, \epsilon$多小才能避免 Anomalous Behavior。我们必须使得系统中的相关物理事件$\varphi$满足&lt;em&gt;Strong Clock Condition&lt;&#x2F;em&gt;。首先假定进程内的顺序不会有问题，那么我们只用考虑不同进程事件的关系即可。&lt;&#x2F;p&gt;
&lt;p&gt;一个进程中的事件$a$发生在时间$t$，然后另一个进程中的事件$b$，两个事件满足$a \rightarrow b$，则$b$发生的时间在$t + \mu$之后。换句话说，$\mu$小于进程间通信的时间。我们可以选择$\mu$等于光速传播最短距离的事件。当然，这取决于系统中的消息如何传递。&lt;&#x2F;p&gt;
&lt;p&gt;为了规避 Anomalous Behavior，我们必须保证对于任意$i,j,t$，$C_i(t+\mu) - C_j(t) &amp;gt; 0$。综上，我们可以得出，当时钟被重置的时候，只能往前而不能倒退（倒退会导致 PC1 不满足），PC1 需要 $C_i(t+\mu) - C_i(t) &amp;gt; (1 - \kappa)\mu$，根据 PC2，如果不等式$\epsilon&#x2F;(1-\kappa) \le \mu$成立，可以推导出$C_i(t+\mu) - C_j(t) &amp;gt; 0$。&lt;&#x2F;p&gt;
&lt;p&gt;不等式和 PC1，2 得到 Anomalous Behavior 不可能发生。&lt;&#x2F;p&gt;
&lt;p&gt;现在我们描述算法。使用$m$表示在物理时间$t$发送时间$t&#x27;$被接收的消息。定义$v_m = t&#x27; -t $为消息$m$的&lt;em&gt;延迟&lt;&#x2F;em&gt;。接收消息的进程不知道这个延迟。但是我们假定接收进程知道最小延迟$\mu_m \ge 0, \mu_m \le v_m$。使用$\xi_m=v_m - \mu_m$表示消息的不可预知延迟。&lt;&#x2F;p&gt;
&lt;p&gt;将 IR1 和 IR2 与物理时钟结合后扩展为 IR1&#x27; IR2&#x27;&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;IR1&#x27;  对于每个$i$，如果$P_i$在物理时间$t$没有收到消息，则$C_i$在$t$是可微的，并且$dC_i(t)&#x2F;dt &amp;gt; 0$&lt;&#x2F;p&gt;
&lt;p&gt;IR2&#x27; (a) 如果$P_i$在时间$t$发送了消息$m$，$m$中包含了时间戳$T_m = C_i(t)$ (b) 在进程$P_j$在物理时间$t&#x27;$收到消息$m$，将$C_j(t&#x27;)$设置为$max(C_j(t&#x27; - 0), T_m + \mu_m)$&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;尽管规则中有物理时间的参数，但是每个进程只需要知道自己的物理时钟读数，以及消息中的时间戳。为了方便数学表述，我们假设了同一进程中的事件不会在同一物理时间发生。&lt;&#x2F;p&gt;
&lt;p&gt;【译者注：】通过一个数理公式证明了满足 PC2，这里省去翻译，数理公式的证明在 &lt;a href=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;time-clock-the-orderingeventdistrisytem&#x2F;#appendix&quot;&gt;Appendix&lt;&#x2F;a&gt;，同样略去&lt;&#x2F;p&gt;
&lt;h2 id=&quot;conslusion&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#conslusion&quot; aria-label=&quot;Anchor link for: conslusion&quot;&gt;Conslusion&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;定义了&amp;quot;happened before&amp;quot;的概念，偏序关系和全序关系。并且阐述了全序关系对于分布式系统的重要性，提出了逻辑时钟的算法&lt;&#x2F;p&gt;
&lt;p&gt;逻辑时钟有时是有问题的，可以通过引入物理时钟解决，并且物理时钟是可能漂移的&lt;&#x2F;p&gt;
&lt;p&gt;在分布式系统中，认识到事件之间的偏序关系是非常重要的。我们也认为这个 idea 在多进程系统同样重要。可以帮助人们理解多进程设计的基本问题，以及如何解决。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;span id=&quot;appendix&quot;&gt;&lt;&#x2F;span&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;appendix&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#appendix&quot; aria-label=&quot;Anchor link for: appendix&quot;&gt;Appendix&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;略&lt;&#x2F;p&gt;
&lt;h2 id=&quot;can-kao-wen-zhang&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#can-kao-wen-zhang&quot; aria-label=&quot;Anchor link for: can-kao-wen-zhang&quot;&gt;参考文章：&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;ol&gt;
&lt;li&gt;https:&#x2F;&#x2F;lrita.github.io&#x2F;2018&#x2F;10&#x2F;24&#x2F;lamport-logical-clocks-vector-lock&#x2F;&lt;&#x2F;li&gt;
&lt;li&gt;狭义相对论与分布式系统中的时间  https:&#x2F;&#x2F;www.jianshu.com&#x2F;p&#x2F;0c79d650d13f
&lt;ol&gt;
&lt;li&gt;阐述了分布式系统中时间的本质，探索了分布式理论的本质&lt;&#x2F;li&gt;
&lt;li&gt;提出了 Logical Clock 算法，是后续 Vector Clock，HLC（混合逻辑时钟，包含了 logic clock, physical clock) 等的基础&lt;&#x2F;li&gt;
&lt;li&gt;提出了 Replicated State Machine 的理念，是后续 Paxos 及其应用的基础&lt;&#x2F;li&gt;
&lt;li&gt;设计了无中心的分布式临界资源算法，是后续多种无中心分布式算法的鼻祖&lt;&#x2F;li&gt;
&lt;li&gt;设计了时间同步的雏形算法，后续 NTP 等的基础&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;阿里数据库的 HLC https:&#x2F;&#x2F;database.51cto.com&#x2F;art&#x2F;201911&#x2F;606198.htm&lt;&#x2F;li&gt;
&lt;li&gt;https:&#x2F;&#x2F;lrita.github.io&#x2F;2018&#x2F;10&#x2F;19&#x2F;communication-model-in-distribution&#x2F;&lt;&#x2F;li&gt;
&lt;li&gt;http:&#x2F;&#x2F;zhangtielei.com&#x2F;posts&#x2F;blog-distributed-causal-consistency.html 【推荐】&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;ericfu.me&#x2F;timestamp-in-distributed-trans&quot;&gt;分布式事务中的时间戳&lt;&#x2F;a&gt; 【推荐】&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;h2 id=&quot;geng-xin-ji-lu&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#geng-xin-ji-lu&quot; aria-label=&quot;Anchor link for: geng-xin-ji-lu&quot;&gt;更新记录&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;2020-4-21 更新，加入参考文章【分布式事务中的时间戳】&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
    </entry>
    <entry xml:lang="en">
        <title>PaxosStore: High-availability Storage Made Practical in WeChat</title>
        <published>2021-03-17T00:00:00+00:00</published>
        <updated>2021-03-17T00:00:00+00:00</updated>
        <author>
          <name>Unknown</name>
        </author>
        <link rel="alternate" href="https://wendajiang.github.io/paxosstore/" type="text/html"/>
        <id>https://wendajiang.github.io/paxosstore/</id>
        <content type="html">&lt;h1 id=&quot;zhai-yao&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#zhai-yao&quot; aria-label=&quot;Anchor link for: zhai-yao&quot;&gt;摘要&lt;&#x2F;a&gt;&lt;&#x2F;h1&gt;
&lt;p&gt;本文中，我们推出了 PaxosStore，一种支持微信综合业务的高可用存储系统。在存储层使用了组合设计利用多种存储引擎来适配不通的存储模型。PaxosStore 使用 Paxos 共识协议作为中间层，统一了对于底层多个存储引擎的访问。这有助于调整、维护，以及对于存储系统的扩缩容。根据我们在工程实践中的经验，在实际中实现一套可用的一致性读写协议比理论上要复杂很多。为了克服工程的复杂性，我们提出了 Paxos-based 存储的多层协议栈，其中 PaxosLog，协议中的关键数据结构，被设计为桥接从面向程序的一致性读写到面向存储的 Paxos 过程。此外，我们还提供了基于 Paxos 的优化，可以更有效的具备容错能力。本文讨论主要侧重务实的解决方案，这可能是构建分布式存储系统的关键。&lt;&#x2F;p&gt;
&lt;h1 id=&quot;1-jie-shao-introduction&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#1-jie-shao-introduction&quot; aria-label=&quot;Anchor link for: 1-jie-shao-introduction&quot;&gt;1. 介绍 (Introduction)&lt;&#x2F;a&gt;&lt;&#x2F;h1&gt;
&lt;p&gt;微信是最受欢迎的移动应用之一，每天拥有 7 亿活跃用户。由微信提供的服务包括 IM，社交网络，移动支付，第三方授权等。各种微信的后端服务由不同的团队开发。尽管业务逻辑的多样性，大多数后端组件需要可靠的存储来支撑。最开始每个开发团队随机选择现成的存储方案来实现原型。然而，在生产系统中，各种碎片化的存储系统维护成本极高，而且难以扩展。这种现状呼吁着一个通用的存储系统提供个各种微信业务使用，而 PaxosStore 就是微信的第二代存储系统&lt;&#x2F;p&gt;
&lt;p&gt;这个存储服务需要满足以下要求。首先，大数据的 3 大 V（volume，velocity，variety）是存在的。每天平均产生 1.5TB 的数据，其中包含各种类型的内容，包括文本消息，图像，音频，视频，财务交易，社交网站帖子等。白天的应用的查询速率达到每秒万条。尤其是，单记录访问占主要使用情况。其次，高可用在存储服务中必须是一等公民。大多数服务依赖 PaxosStore（比如，点对点消息，群消息，浏览社交网络帖子等）。可用性对于用户体验是至关重要的。微信的大多数应用要求 PaxosStore 的延迟小于 20ms。而且跨城市的访问也要有这种延迟要求。&lt;&#x2F;p&gt;
&lt;p&gt;除了建设 PaxosStore 提供高可用服务，还面临以下挑战:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;有效性和高效的共识保证。&lt;&#x2F;strong&gt;   PaxosStore 核心上使用 Paxos 算法达成共识。尽管理论上的 Paxos 算法提供了共识保证，但是实现的复杂性（例如需要维护复杂的状态机）以及运行时的开销（例如同步的带宽）使其不足以全面支持微信的服务&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;弹性以及低延迟。&lt;&#x2F;strong&gt;   PaxosStore 要求在城市规模提供低延迟的读写。在运行时需要支撑巨大的负载&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;自动跨数据中心的容错能力。&lt;&#x2F;strong&gt;   在微信的生产环境，PaxosStore 全球跨数据中心部署了成千上百的服务器。在这种大规模系统中，硬件故障和网络中断并不罕见。容错能力要求快速的故障检测和不影响系统的恢复。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;PaxosStore 设计并实施为微信后端高可用性存储的解决方案。在存储层中采用组合设计，接入了不同的存储引擎来适应不同的存储模型。PaxosStore 使用 Paxos 共识协议作为中间层统一了对于底层存储引擎的访问。Paxos-based 的存储协议可扩展支持各种暴露于应用程序的数据结构。此外，PaxosStore 采用 leaseless design（译者注:无租约），这有利于改善系统的可用性以及容错能力。&lt;&#x2F;p&gt;
&lt;p&gt;论文的主要贡献如下:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;我们介绍了 PaxosStore 的设计，&lt;strong&gt;重点阐述了一致性读写协议的构建及其运作方式&lt;&#x2F;strong&gt;。通过从存储层中解耦出一致性协议，PaxosStore 拥有很好的可扩展性，可以给为不同存储模型构建的多种存储引擎提供支持。&lt;&#x2F;li&gt;
&lt;li&gt;根据 PaxosStore 的设计，&lt;strong&gt;我们进一步论述了容错系统以及关于数据恢复的细节。&lt;&#x2F;strong&gt;   文中描述的技术已在大型生产环境中实现了全面应用，它们使 PaxosStore 在微信所有的生产应用中达到了 99.9999% 的可用性（此结果是通过对 6 个月的运行数据进行统计得出的）。&lt;&#x2F;li&gt;
&lt;li&gt;在日益成长的微信业务背后， PaxosStore 已经为其提供了两年多的支持。基于这些实践经验，&lt;strong&gt;我们探讨了 PaxosStore 设计上的取舍，并给出了我们的应用实践所得到的实验评估结果。&lt;&#x2F;strong&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;文章剩余的内容组织如下。首先在第二节详细阐述了设计细节和 PaxosStore 的架构，然后在第三节描述了容错系统和数据恢复技术。在第四节讨论 PaxosStore 的实现关键点。在第五节，对 PaxosStore 进行了性能测试并收集了运行系统中的数据来展示。在第六节讨论了相关研究，最后第七节总结了本文以及在构建 PaxosSore 系统的得到的经验。&lt;&#x2F;p&gt;
&lt;h1 id=&quot;2-she-ji-design&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#2-she-ji-design&quot; aria-label=&quot;Anchor link for: 2-she-ji-design&quot;&gt;2. 设计 (Design)&lt;&#x2F;a&gt;&lt;&#x2F;h1&gt;
&lt;h2 id=&quot;2-1-jia-gou-overall-architecture&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#2-1-jia-gou-overall-architecture&quot; aria-label=&quot;Anchor link for: 2-1-jia-gou-overall-architecture&quot;&gt;2.1 架构 (Overall Architecture)&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;2021-03-03-paxosstore&#x2F;image-20210317155231443.png&quot; alt=&quot;image-20210317155231443&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;图 1 说明了 PaxosStore 的总体体系结构，该架构包含了三层。编程模型层提供了暴露给应用的各种数据结构，共识层实现了 Paxos-based 存储协议，存储层包含了基于不同存储模型的不同存储引擎，以使不同数据结构的性能最大化。PaxosStore 不同于传统存储系统主要在于将中间层的共识协议解耦出来，为底层多种数据引擎提供共识保证。&lt;&#x2F;p&gt;
&lt;p&gt;传统的分布式存储系统通常为了一种数据模型单独构建，并调整设计和实现以满足各种应用需求。然而，这就需要不同组件的各种复杂权衡。尽管组装多个现成的存储系统来满足存储要求的多样性也可以，但是这通常使整个系统难以维护而且不容易扩展。此外，每个存储系统将共识模型与存储模型耦合在一起，然后拼凑起来的组合系统分而治之结果可能使共识结果是错误的，因为每个单独的存储子系统各自保持共识。此外，使用多种数据模型的应用（会使用多个存储子系统）很难利用底层的子系统的共识保证，从而不得不自己单独实现一套自己的共识协议。&lt;&#x2F;p&gt;
&lt;p&gt;因为编程模型层的设计和实现在工程上并不难，所以主要表述了 PaxosStore 共识层和存储层设计&lt;&#x2F;p&gt;
&lt;h2 id=&quot;2-2-gong-shi-ceng-consensus-layer&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#2-2-gong-shi-ceng-consensus-layer&quot; aria-label=&quot;Anchor link for: 2-2-gong-shi-ceng-consensus-layer&quot;&gt;2.2 共识层 (Consensus Layer)&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;2021-03-03-paxosstore&#x2F;image-20210317160824556.png&quot; alt=&quot;image-20210317160824556&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;协议栈三层如图 2 所示&lt;&#x2F;p&gt;
&lt;h3 id=&quot;2-2-1-paxos&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#2-2-1-paxos&quot; aria-label=&quot;Anchor link for: 2-2-1-paxos&quot;&gt;2.2.1 Paxos&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;存储协议基于 Paxos 算法使数据在多个 node 之间同步。理论上，Paxos 包含了两个阶段:准备阶段来达成准备工作的一致，接受阶段来达成最终的一致。按照惯例，Paxos 使用状态机表述。但是过度的状态设计以及复杂的状态转移会使得运行时很低的性能。&lt;&#x2F;p&gt;
&lt;p&gt;在 PaxosStore 中，我们摒弃了状态机的方式，而是使用半对称消息传递来解释 Paxos 过程。为此，我们首先定义一些符号&lt;&#x2F;p&gt;
&lt;p&gt;此节先略&lt;&#x2F;p&gt;
&lt;h3 id=&quot;2-2-2-paxoslog&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#2-2-2-paxoslog&quot; aria-label=&quot;Anchor link for: 2-2-2-paxoslog&quot;&gt;2.2.2 PaxosLog&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;PaxosLog 在 PaxosStore 中作为数据更新的 write-ahead log。图 3 展现了数据结构，每个 log entry 由 Paxos 算法决定，可以被一个不变的序列号索引--entry ID，唯一递增。最大的 entry ID 表示版本。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;2021-03-03-paxosstore&#x2F;image-20210317163451037.png&quot; alt=&quot;image-20210317163451037&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;概念上，PaxosLog 实例可以被无限生成。实际上，通过 LRU 策略，异步删除过时的 log entries。除了数据 value 之外，每个 PaxosLog 包含 Paxos 关联的元数据，promise number &lt;em&gt;m&lt;&#x2F;em&gt; 和 proposal number &lt;em&gt;n&lt;&#x2F;em&gt;, 在 2.2.1 节中的 Paxos 算法使用，但是一旦 log entry 完成就会被丢弃（蓝色线框标记出）。此外，由于同一数据的多个副本主机可能同时发出写入请求，但是只有一个请求会被接受，proposer ID 附加到被选中的 value 上表明 value 的 proposer。Proposer ID 是 32 位的机器 ID，数据中心中唯一表征一个 node。用于预准备阶段的优化，如果当前写入可以跳过 pre-pare&#x2F;promise 阶段，如果与上次写入的相同请求的原点，则符合写请求的局部性。此外，request ID 唯一标志与 value 相关联的写请求。用于防止重复写入（详细讨论在 3.3）。特别的，request ID 包含了三个部分:32 位的 client ID（比如 IPv4 地址）表明提出写请求的客户端，16 位的时间戳表明客户端本地时间，16 位的序列号表明客户端请求序列区分同一秒的请求&lt;&#x2F;p&gt;
&lt;p&gt;根据 write-ahead log 对于数据更新的机制，PaxosLog entry 在将值写入到存储引擎中时必须被处理。通常，PaxosLog 存储和数据对象存储是分离的，如图 4 所示，一次数据更新，两次有序的写 I&#x2F;O :一次写 PaxosLog entry，接下来更新数据对象&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;2021-03-03-paxosstore&#x2F;image-20210317165229646.png&quot; alt=&quot;image-20210317165229646&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;PaxosLog 对于 Key-Value 数据的使用。&lt;&#x2F;strong&gt;  考虑下 k-v 存储，我们有两种优化，简化了 paxoslog 的构建和操作。&lt;&#x2F;p&gt;
&lt;p&gt;首先，取消了 data value 的存储，key-value 直接通过 paxoslog 存储，称为 paxoslog-as-value。在 Paxos-based 的 key-value 存储中，一对 k-v 与一个 paxoslog 关联。这样可以少一次 I&#x2F;O，节省硬盘带宽。&lt;&#x2F;p&gt;
&lt;p&gt;其次，裁剪了 paxoslog 存储，只存储最新的两个数据历史，如图 5 所示，早于最新的数据被视为过时的，可以被删除，所以对于 k-v data 的 PaxosLog 长度恒定为 2。由于 PaxosLog 不会增大，所以可以消除对于数据更新对于内存和硬盘的影响，节省存储和计算计算。此外，简化了 k-v 数据的恢复。最新的 PaxosLog 包含了最新 k-v 数据的快照，可以在出问题时直接恢复数据。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;2021-03-03-paxosstore&#x2F;image-20210317165959798.png&quot; alt=&quot;image-20210317165959798&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;相比之下，正常数据的恢复需要对于 PaxosLog 在 last checkpoint 开始重放所有历史 log entry（如图 4 中表示），尤其是面向集合的数据结构，例如 list, queue,set&lt;&#x2F;p&gt;
&lt;h3 id=&quot;2-2-3-yi-zhi-xing-du-xie-consistent-scheme&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#2-2-3-yi-zhi-xing-du-xie-consistent-scheme&quot; aria-label=&quot;Anchor link for: 2-2-3-yi-zhi-xing-du-xie-consistent-scheme&quot;&gt;2.2.3 一致性读写 (Consistent Scheme)&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;PaxosStore 被设计为多地系统，在多个数据中心之上运行，同时采用 Paxos 协议以 leaseless 方式保证操作的共识，即每个节点可以同等处理数据。具体而言，通过所有副本节点的写作处理每个数据访问（读&#x2F;写），并依赖 PaxosLog 实现数据的一致性保证。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;一致性读。&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;一致性写。&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;2-3-cun-chu-ceng-storage-layer&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#2-3-cun-chu-ceng-storage-layer&quot; aria-label=&quot;Anchor link for: 2-3-cun-chu-ceng-storage-layer&quot;&gt;2.3 存储层 (Storage Layer)&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;微信生产系统中的应用提出了多种数据访问的要求以及性能问题。在重组上一代存储系统之后，我们意识到在存储层支持多种存储模型是必要的。这启发了 PaxosStore 存储层的设计，基于不同的存储模型构建多个存储引擎。具体来说，&lt;a href=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;awesomepaper&#x2F;translate&#x2F;2021&#x2F;03&#x2F;02&#x2F;bitcask.html&quot;&gt;BitCask&lt;&#x2F;a&gt; 和 LSM-tree 是在 PaxosStore 中使用的两种主要模型，都是为了 key-value 存储设计:Bitcask 模型在单点查询更优，LSM-tree 在范围查询上更优。我们在存储层中实现了两种存储引擎，主要设计可用性，效率和可扩展性，不包括共识问题。将共识协议从存储层解耦出来称为中间层，使 PaxosStore 存储层的开发，调优和维护容易很多。存储引擎不仅可以单独调优，还可以协作一起工作，所以支持更加灵活的选项来支持应用特定的需求。&lt;&#x2F;p&gt;
&lt;p&gt;在 PaxosStore 中最常用的物理数据结构就是 key-value 和关系表。Key-value 原生被 Bitcask 和 LSM-tree 支持。根本上，PaxosStore 的关系表也被存储为 key-value 对，每个表是 value，被唯一 key 索引。但是，简单将表作为普通 key-value 会导致性能问题，因为大多数表都是频繁读取的，而且通常每张表包含成千上百个行，但是微信应用一次大多只访问其中一两行。因此，磁盘&#x2F;SSD 和内存之间频繁的读写严重影响系统性能。为了解决这个问题，PaxosStore 采用了 differentail update 技术降低表更新的开销。为此，将表分解为两个元表:读优化的 main-table 管理表的主要数据，写优化的 delta-table 管理表的变化（比如更新，插入，删除）。因此表的访问是通过 main-table 的 view 结合 delta-table 管理的增量数据。更深一步，为了保持 delta-table 最小化（保留写友好的属性），会定时将增量数据合并回 main-table&lt;&#x2F;p&gt;
&lt;h1 id=&quot;3-rong-cuo-xing-yu-ke-yong-xing-fault-tolerance-and-availability&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#3-rong-cuo-xing-yu-ke-yong-xing-fault-tolerance-and-availability&quot; aria-label=&quot;Anchor link for: 3-rong-cuo-xing-yu-ke-yong-xing-fault-tolerance-and-availability&quot;&gt;3. 容错性与可用性 (Fault Tolerance and Availability)&lt;&#x2F;a&gt;&lt;&#x2F;h1&gt;
&lt;h2 id=&quot;3-1-rong-cuo-fault-tolerant-scheme&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#3-1-rong-cuo-fault-tolerant-scheme&quot; aria-label=&quot;Anchor link for: 3-1-rong-cuo-fault-tolerant-scheme&quot;&gt;3.1 容错 (Fault-tolerant Scheme)&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;h2 id=&quot;3-2-shu-ju-hui-fu-data-recovery&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#3-2-shu-ju-hui-fu-data-recovery&quot; aria-label=&quot;Anchor link for: 3-2-shu-ju-hui-fu-data-recovery&quot;&gt;3.2 数据恢复 (Data Recovery)&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;h2 id=&quot;3-3-you-hua-optimizations&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#3-3-you-hua-optimizations&quot; aria-label=&quot;Anchor link for: 3-3-you-hua-optimizations&quot;&gt;3.3 优化 (Optimizations)&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;h1 id=&quot;4-shi-xian-implementation&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#4-shi-xian-implementation&quot; aria-label=&quot;Anchor link for: 4-shi-xian-implementation&quot;&gt;4. 实现 (Implementation）&lt;&#x2F;a&gt;&lt;&#x2F;h1&gt;
&lt;p&gt;总结:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;线程多导致同步状态负载，所以实现了 libco 协程，以同步的方式实现异步性能，除了 Paxos 算法本身显式异步编程&lt;&#x2F;li&gt;
&lt;li&gt;节点间通信，每台服务器以批量方式发送数据包，节省网络带宽。每个服务器还维护多个 socket 连接着同一机器，每个套接字轮流运行发送批处理的数据包，这样可以将数据的批处理分散到多个 socket 上&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;5-ping-gu-evaluation&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#5-ping-gu-evaluation&quot; aria-label=&quot;Anchor link for: 5-ping-gu-evaluation&quot;&gt;5. 评估 (Evaluation)&lt;&#x2F;a&gt;&lt;&#x2F;h1&gt;
&lt;h2 id=&quot;5-1-shi-yan-bu-zou&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#5-1-shi-yan-bu-zou&quot; aria-label=&quot;Anchor link for: 5-1-shi-yan-bu-zou&quot;&gt;5.1 实验步骤&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;h2 id=&quot;5-2-yan-chi&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#5-2-yan-chi&quot; aria-label=&quot;Anchor link for: 5-2-yan-chi&quot;&gt;5.2 延迟&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;h2 id=&quot;5-3-rong-cuo-xing&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#5-3-rong-cuo-xing&quot; aria-label=&quot;Anchor link for: 5-3-rong-cuo-xing&quot;&gt;5.3 容错性&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;h2 id=&quot;5-4-cuo-wu-hui-fu&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#5-4-cuo-wu-hui-fu&quot; aria-label=&quot;Anchor link for: 5-4-cuo-wu-hui-fu&quot;&gt;5.4 错误恢复&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;h2 id=&quot;5-5-effectiveness-of-paxoslog-entry-batched-applying&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#5-5-effectiveness-of-paxoslog-entry-batched-applying&quot; aria-label=&quot;Anchor link for: 5-5-effectiveness-of-paxoslog-entry-batched-applying&quot;&gt;5.5 Effectiveness of PaxosLog-Entry Batched Applying&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;h2 id=&quot;5-6-paxosstore-zai-wei-xin-zhong-de-ying-yong&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#5-6-paxosstore-zai-wei-xin-zhong-de-ying-yong&quot; aria-label=&quot;Anchor link for: 5-6-paxosstore-zai-wei-xin-zhong-de-ying-yong&quot;&gt;5.6 PaxosStore 在微信中的应用&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;5-6-1-fu-wu-ji-shi-xiao-xi-serving-instant-messaging&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#5-6-1-fu-wu-ji-shi-xiao-xi-serving-instant-messaging&quot; aria-label=&quot;Anchor link for: 5-6-1-fu-wu-ji-shi-xiao-xi-serving-instant-messaging&quot;&gt;5.6.1 服务即时消息 (Serving Instant Messaging)&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;h3 id=&quot;5-6-2-fu-wu-she-jiao-wang-luo-serving-social-networking&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#5-6-2-fu-wu-she-jiao-wang-luo-serving-social-networking&quot; aria-label=&quot;Anchor link for: 5-6-2-fu-wu-she-jiao-wang-luo-serving-social-networking&quot;&gt;5.6.2 服务社交网络 (Serving Social Networking)&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;h1 id=&quot;6-related-work&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#6-related-work&quot; aria-label=&quot;Anchor link for: 6-related-work&quot;&gt;6. Related Work&lt;&#x2F;a&gt;&lt;&#x2F;h1&gt;
&lt;p&gt;略&lt;&#x2F;p&gt;
&lt;p&gt;与 raft 不同的是，本文的 paxos 采用无租约设计，没有换主的不可用问题，可以不停机快速故障恢复&lt;&#x2F;p&gt;
&lt;h1 id=&quot;7-conslusion&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#7-conslusion&quot; aria-label=&quot;Anchor link for: 7-conslusion&quot;&gt;7. Conslusion&lt;&#x2F;a&gt;&lt;&#x2F;h1&gt;
&lt;p&gt;在本文中，我们详细解读了 PaxosStore，它是一个高可用性的存储系统，每秒可以承受数千万次的一致性读&#x2F;写操作。PaxosStore 中的存储协议基于 Paxos 算法达成分布式共识，并在实际应用中对其进行了进一步优化，包括用于 key-value 存储的 PaxosLog-as-value 和 裁剪 PaxosLog 结构。基于细粒度数据检查点的容错方案使 PaxosStore 能够在故障时支持快速数据恢复，而不会导致系统停机。PaxosStore 已经在微信中实施和部署，为微信集成服务（如即时消息和社交网络）提供存储支持。&lt;&#x2F;p&gt;
&lt;p&gt;在 PaxosStore 的开发过程中，我们总结了几个设计原则和经验教训:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;建议不要通过妥协的单一存储引擎支持存储多样性，而是设计这样的存储层，让它能够支持为不同存储模型构建的多个存储引擎。这种方法有助于开发者在操作维护的动态方面进行有针对性的性能调整。&lt;&#x2F;li&gt;
&lt;li&gt;除错误和故障外，系统过载也是影响系统可用性的关键因素。特别是在设计系统容错方案时，我们必须对过载引起的潜在雪崩效应给予足够的重视。 一个具体的例子是在 PaxosStore 中使用迷你集群组 (mini-cluster group)。&lt;&#x2F;li&gt;
&lt;li&gt;PaxosStore 的设计大幅借鉴了基于消息传递的事件驱动机制，这可能会涉及逻辑实现方面的大量异步状态机转换。 在构建 PaxosStore 的工程实践中，我们开发了一个基于协程和 socket hook 的框架，以便于以  pseudo-synchronous 方式对异步过程进行编程。这有助于消除容易出错的函数回调，并简化了异步逻辑的实现过程。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;8-references&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#8-references&quot; aria-label=&quot;Anchor link for: 8-references&quot;&gt;8. References&lt;&#x2F;a&gt;&lt;&#x2F;h1&gt;
&lt;p&gt;略&lt;&#x2F;p&gt;
</content>
    </entry>
    <entry xml:lang="en">
        <title>The Chubby lock service for loosely-coupled distributed systems</title>
        <published>2021-03-07T14:15:27+00:00</published>
        <updated>2021-03-07T14:15:27+00:00</updated>
        <author>
          <name>Unknown</name>
        </author>
        <link rel="alternate" href="https://wendajiang.github.io/chubby/" type="text/html"/>
        <id>https://wendajiang.github.io/chubby/</id>
        <content type="html">&lt;h2 id=&quot;can-kao-wen-zhang&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#can-kao-wen-zhang&quot; aria-label=&quot;Anchor link for: can-kao-wen-zhang&quot;&gt;参考文章&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;catkang.github.io&#x2F;2017&#x2F;10&#x2F;10&#x2F;zookeeper-vs-chubby.html&quot;&gt;chubby vs zookeeper&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h1 id=&quot;yuan-wen-fan-yi&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#yuan-wen-fan-yi&quot; aria-label=&quot;Anchor link for: yuan-wen-fan-yi&quot;&gt;原文翻译&lt;&#x2F;a&gt;&lt;&#x2F;h1&gt;
&lt;h2 id=&quot;zhai-yao&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#zhai-yao&quot; aria-label=&quot;Anchor link for: zhai-yao&quot;&gt;摘要&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;Chubby 提供了一个粗粒度的，用于松耦合分布式系统的锁。Chubby 提供了类似分布式文件系统的接口，设计更强调可用性和可靠性，而不是高性能。很多实例已经用了一些年头，每个服务实例可以处理成千上百万的并发请求。本文章描述初始设计以及使用预期，并与适应实际使用作出的修改作对比。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;1-jie-shao&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#1-jie-shao&quot; aria-label=&quot;Anchor link for: 1-jie-shao&quot;&gt;1. 介绍&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;a lock service called Chubby&lt;&#x2F;p&gt;
&lt;p&gt;lock service 的目的是，可以使能 client 同步它们的逻辑，以及分享它们环境的基本信息。主要设计目标包括，可用性、可靠性以及易于使用，吞吐和存储容量在第二位被考虑。Chubby 的 client 接口就像系统提供的 read 和 write 一样，以及尝试锁和例如文件修改的时间通知。&lt;&#x2F;p&gt;
&lt;p&gt;我们期望 Chubby 帮助开发者更容易处理分布式系统中的同步事件，尤其是处理类似从多个服务器中选 leader 这种场景，比如 Google File System 使用 Chubby lock 选出一个 GFS 的主服务器，Bigtable 在多个地方使用 Chubby：选主，主服务器的控制指令分发，client 找主。需要额外提到是，GFS 和 Bittable 都使用 Chubby 来存储少量的 meta 数据；实际上，它们使用 Chubby 分布式数据结构的 root。有些服务使用 Chubby lock 来为多个服务器分发任务。&lt;&#x2F;p&gt;
&lt;p&gt;在 Chubby 被部署之前，多数 Google 的分布式系统使用 ad hoc 方法进行选主（如果任务重复执行没有危害），或者需要操作者进行干预（正确性至关重要）。在前一种情况，Chubby 可以节省计算资源，后一种情况，Chubby 使系统更干净，容易使用。&lt;&#x2F;p&gt;
&lt;p&gt;熟悉分布式计算的读者知道分布式一致性问题 (&lt;em&gt;distributed consensus&lt;&#x2F;em&gt;) 的选主，并且需要一个异步通信机制 (&lt;em&gt;asynchronous&lt;&#x2F;em&gt; communication)。这个术语描述了真实的网络环境（随时可能发生丢包，延迟或者包乱序）。asynchronous consensus 通过 &lt;em&gt;Paxos&lt;&#x2F;em&gt; 协议解决，实际上，我们见到的所有需要异步一致性的系统核心都有 Paxos 的身影。Paxos 无需时间假设就达到安全性，但是必须引入时钟来保证。&lt;&#x2F;p&gt;
&lt;p&gt;构建 Chubby 是填补上述需求的工程努力，这不是 research。我们没有声明什么新算法或者新技术。本文的目的是描述我们做了什么，以及为什么要做。后面的章节中，我们描述 Chubby 的设计和实现，以及改变了什么使用体验。描述了使用 Chubby 的意外方式，以及被证明是错误的方式。我们省略了一些细节，比如共识协议或者 RPC 系统的细节。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;2-she-ji&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#2-she-ji&quot; aria-label=&quot;Anchor link for: 2-she-ji&quot;&gt;2. 设计&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;2-1-retional&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#2-1-retional&quot; aria-label=&quot;Anchor link for: 2-1-retional&quot;&gt;2.1 Retional&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;有些人可能会说我们应该建立一个 Paxos 的库，而不是一个集中的锁服务。一个 client paxos library 不依赖其他服务（包括名字服务），可以为开发者提供一个标准框架，假设他们的服务可以被实现为状态机。事实上，我们确实提供了独立与 Chubby 的一个 client library.&lt;&#x2F;p&gt;
&lt;p&gt;然而，lock service 相比 client library 有几点优势：&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;首先，我们开发者并不会预期一样考虑高可用性，通常系统以原型启动，使用较少的负载并且没有过多的可用性保证，代码的结构也不方便使用共识协议。当服务开始真正的服务客户端时，可用性变得很重要，复制，选主就要被加到设计中。当然这些可以使用提供了分布式一致性的库做到，但是 lock 服务使得这些变得更容易，不用改变现有的代码结构和通信方式。比如，选主然后写到文件服务需要添加两个状态和一个 RPC 参数到现有系统：一个请求 lock 称为主，传递一个额外的整数（lock acquisition count）到 write RPC，加一个 if 状态来拒绝如果 acquisition count 小于当前值的请求（防止包延迟导致问题）。我们发现这种技术方案比在服务中引入共识协议更简单，尤其是还要在过渡期间维护兼容性&lt;&#x2F;li&gt;
&lt;li&gt;我们的一些服务，比如选主或者在组件之间分割数据需要一个机制来发布结果。所有我们需要 client 可以存储，拉取少量数据--就是读写小文件。这可以使用名字服务完成，但是我们的经验告诉我们 lock service 本身就适合完成这个任务，不仅可以减少服务依赖，还因为共识协议的共享特性。 Chubby 成功作为名字服务由于使用一致性的 client 缓存，而不是基于时间的缓存。尤其是，我们发现开发者非常喜欢这种不基于时间的缓存设计，比如基于时间的 DNS 缓存，如果选择不当，可能会导致 DNS 负载过大或者客户端延迟严重。&lt;&#x2F;li&gt;
&lt;li&gt;开发者更熟悉 lock-based 的接口设计。Paxos 的复制状态机和排它锁可以为开发者提供顺序编程的错觉。但是，很多开发者使用锁，讽刺的是，这样的开发者通常会错误，尤其是在分布式系统中，很少人能考虑独立计算机故障对于异步通信系统中的锁的影响。尽管如此，锁的熟悉说服了开发者利用分布式的可靠机制【译者注：对于分布式系统中的锁服务，也必须使用共识协议，单机的锁，比如简单的 redis 作为分布式锁，如果单机 redis 挂了，对系统的影响是很严重的，比如 redis 作者也意识到了这一点，设计分布式锁给出了 redlock 的方案，关于 redis 分布式锁，可以前往 &lt;a href=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;redis-distribute-lock&#x2F;&quot;&gt;Redis 分布式锁以及相关讨论&lt;&#x2F;a&gt;】&lt;&#x2F;li&gt;
&lt;li&gt;最后，分布共识算法使用 Quorums 来决策，所以它们使用多个副本来达到高可用性。比如 Chubby 本身每个 cell 有 5 个副本，至少 3 个运行这个 cell 才可用。相比之下，如果客户端使用 lock service， 即使单个 client 也可以获取 lock。因此 lock service 减少了一个 client 系统所需的服务器数量。&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;这些讨论引出了两个核心设计决策：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;做一个 lock service，而不是提供一个库&lt;&#x2F;li&gt;
&lt;li&gt;适用小文件，而不是二级服务&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;根据我们的经验，环境和需求的一些决策：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Chubby 有很多客户端，所以要允许成千个 client 看到这个文件，而不需要很多服务器&lt;&#x2F;li&gt;
&lt;li&gt;客户端和服务的副本需要知道何时发生了切换主节点。这需要事件通知，而不是轮询问&lt;&#x2F;li&gt;
&lt;li&gt;即使有些客户端不需要周期轮询文件，有些还要需要，所以需要缓存&lt;&#x2F;li&gt;
&lt;li&gt;很多开发者存在不符合直觉的缓存语义的困惑，我们提供一致性缓存&lt;&#x2F;li&gt;
&lt;li&gt;为了避免财务损失和监禁，我们提供了安全机制，包括访问控制&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;一个让读者惊讶的选择是我们没有提供细粒度锁，比如 hold 秒级或者更短时间。比如应用使用 lock 作为选主，将要在接下来的几个小时或者几天，处理所有的数据。这两种使用方式表明了 lock service 的不同要求&lt;&#x2F;p&gt;
&lt;p&gt;粗粒度锁对锁服务器的负载要小得多。特别是，锁的获取频率通常与客户端应用系统的事务频率只有很微弱的关联。粗粒度的锁很少被获取，所以临时性的锁服务器的不可用给客户端造成的延时会更少。另一方面，锁在客户端间的转移可能需要高昂的恢复处理，所以人们不希望锁服务器的故障恢复导致锁丢失。因此，粗粒度的锁可以很好地应对锁服务器故障，几乎不需要考虑这样做的开销，而且这样的锁允许少量的锁服务器以较低的可用性为许多客户端提供足够的服务。&lt;&#x2F;p&gt;
&lt;p&gt;细粒度的锁会有不同的结论。即使锁服务器短暂地不可用，也可能导致许多客户端被挂起。因为锁服务的事务频率随着客户端的事务频率之和一起增长，所以性能和随意增加新服务器的能力非常重要。通过不维护跨锁服务器故障的锁来减少锁的开销是有优势的，而且由于锁只会被持有很短的时间，所以偶尔丢弃锁的时间损失并不严重。（客户端必须准备好在网络分区期间丢失锁，所以锁服务器故障恢复造成的锁的丢失不会引入新的恢复路径。)&lt;&#x2F;p&gt;
&lt;p&gt;Chubby 只提供粗粒度的锁定。幸运的是，客户端可以直接实现针对其应用程序定制的细粒度锁。应用程序可以将其锁划分为组，并使用 Chubby 的粗粒度锁将这些锁组分配给应用程序特定的锁服务器。维护这些细粒度的锁只需要很少的状态；服务器只需要保持一个稳定的、单调递增的且很少更新的请求计数器，客户端能够在解锁时发现丢失了的锁，如果使用简单的定长租期 (lease)，协议会变得简单而有效。此方案最重要的好处是，我们的客户端开发人员负责提供支持其负载所需要的服务器，而不必自己去实现共识机制。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;2-2-system-structures&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#2-2-system-structures&quot; aria-label=&quot;Anchor link for: 2-2-system-structures&quot;&gt;2.2 System structures&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;Chubby 有两个通过 RPC 通信的主要组件：服务器和客户端应用程序链接的库；如下图。Chubby 客户端和服务器之间的所有通信都由客户端库进行中介。第 3.1 节讨论了可选的第三个组件，即代理服务器&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;chubby&#x2F;image-20210508181756052.png&quot; alt=&quot;image-20210508181756052&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;一个 Chubby cell 由一组称为副本 (replicas) 的服务器（通常是 5 个）组成，放置这些服务器是为了减少相关故障的可能性（例如，放在不同的机架上）。副本使用一个分布式共识协议来选举一个 Master ；Master 必须从大多数副本中获得选票，并保证这些副本在 Master 租用的几秒钟内不会选择其他的 Master。主租赁由副本定期更新，前提是主租赁继续赢得多数选票。&lt;&#x2F;p&gt;
&lt;p&gt;副本维护一个简单数据库的副本集，但是只有 Master 才会发起对数据库的读写。其他所有副本只是复制来自 Master 的更新，使用一致性协议发送。&lt;&#x2F;p&gt;
&lt;p&gt;客户端通过向 DNS 中列出的副本集发送 Master 位置请求来找到 Master。非主副本通过返回主副本的身份来响应此类请求。一旦客户端找到了 Master，客户端就会将所有请求定向到它，直到它停止响应，或者直到它指出它不再是 Master。写请求通过协商一致性协议传播到所有副本；当写操作到达计算 cell 中的大多数副本时，将确认这些请求。读请求仅由 Master 来满足；这是安全的，只要主租赁没有到期，因为没有其他的 Master 存在。如果 Master 失败，其他副本在其 Master 租约到期时运行选举协议；新的 Master 通常会在几秒钟内选出。例如，最近的两次选举分别花了 6s 和 4s，但我们也见过长达 30s 的情况。&lt;&#x2F;p&gt;
&lt;p&gt;如果一个副本发生故障，并且几个小时内无法恢复，则简单的替换，系统将从空闲池中选择一台新机器，并启动其上的锁服务器的二进制文件。然后更新 DNS 表，将失败副本的 IP 地址替换为新副本的 IP 地址。当前的 Master 定期轮询 DNS，并最终注意到变化。然后更新 cell 数据库中 cell 成员的列表；这个列表通过正常的复制协议在所有成员之间保持一致。与此同时，新副本从存储在文件服务器上的备份和活动副本的更新组合中获取数据库的最新副本。一旦新副本处理了当前 Master 等待提交的请求，就允许该副本在新 Master 的选举中投票。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;2-3-files-directories-and-handles&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#2-3-files-directories-and-handles&quot; aria-label=&quot;Anchor link for: 2-3-files-directories-and-handles&quot;&gt;2.3 Files, Directories and handles&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;Chubby 开放的文件系统接口与 UNIX 类似，但比后者更简单。它通常按照的方式由严格的文件和目录树组成，名称组成部分由斜杠分隔。一个典型的名字是：   &lt;code&gt;&#x2F;ls&#x2F;foo&#x2F;wombat&#x2F;pouch&lt;&#x2F;code&gt;&lt;&#x2F;p&gt;
&lt;p&gt;ls 前缀对所有 Chubby 的名字都相同，代表锁服务 (lock service)。第二部分 (foo) 是一个 Chubby cell 的名称；它通过 DNS 查询解析为一个或多个 Chubby 服务器。一个特殊的 cell 名称 local，表示应该使用客户端的本地 Chubby cell；这个 Chubby cell 通常在同一栋楼里，因此这个 cell 最有可能能访问到。名字的剩余部分，&#x2F;wombat&#x2F;pouch，是在 Chubby cell 内解析的。同样，在 UNIX 下，每个目录包含子文件和子目录的列表，而每个文件包含未解析的字节序列。&lt;&#x2F;p&gt;
&lt;p&gt;因为 Chubby 的命名结构类似于一个文件系统，所以我们既可以通过专门的 API 将它开放给应用系统，也可以通过我们其他文件系统，例如 GFS 使用的接口。这显著地减少了编写基本的浏览和名字空间操作工具所需的工作，也减少了培训那些偶然使用 Chubby 的用户的需求。&lt;&#x2F;p&gt;
&lt;p&gt;这种设计使得 Chubby 接口不同于 UNIX 文件系统，它使得分布更容易 (The design differs from UNIX in a ways that easy distribution)。为允许不同目录下的文件由不同的 Chubby master 来服务，我们没有放出那些将文件从一个目录移动到另一个目录的操作，我们不维护目录修改时间，也避开路径相关的权限语义（也就是文件的访问由其本身的权限控制，而不由它上层路径上的目录控制）。 为使缓存文件元数据更容易，系统不公开最后访问时间。&lt;&#x2F;p&gt;
&lt;p&gt;名称空间只包含文件和目录，统称为节点。每个这样的节点在其 Chubby cell 内只有一个名称；没有符号链接和硬链接。&lt;&#x2F;p&gt;
&lt;p&gt;节点可以是永久的 (permanent)，也可以是短暂的 (ephemeral)。任意节点都可以被显示地 (explicitly) 删除，但是瞬时节点也会在没有客户端打开它时被删除 （另外，对目录而言，在它们为空时被删除）。短暂的文件被用作临时文件，并作为其他客户端存活的指示器。任意节点都能作为一个意向性 (advisory) 的读写锁；这些锁将在 2.4 节更详细地描述。&lt;&#x2F;p&gt;
&lt;p&gt;每个节点都有多种元数据，包括访问控制列表 (access control lists，ACLs) 的三个名字，分别用于控制读、写和修改其 ACL。除非被覆盖，否则节点在创建时将继承其父目录的 ACL 名称。ACLs 本身是位于一个 ACL 目录中的文件， 这个 ACL 目录是 Chubby cell 的一个为人熟知的本地名字空间。这些 ACL 文件的内容由简单的访问名字 (principals) 列表组成；读者可能会想起 Plan 9 的 groups 。因此，如果文件 F 的写 ACL 名称是 foo，并且 ACL 目录中包含一个 foo 文件，foo 文件中包含 bar 这个条目，那么用户 bar 就可以写文件 F。用户由内嵌在 RPC 系统里的机制鉴权。因为 Chubby 的 ACLs 是平常的文件，它们自动地就可以由其他想使用类似的访问控制机制的服务访问。&lt;&#x2F;p&gt;
&lt;p&gt;每个节点的元数据包括四个单调增加的 64 位编号，有利于客户端很容易地检测变化：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;实例编号：大于任意先前的同名节点的实例编号。&lt;&#x2F;li&gt;
&lt;li&gt;内容生成编号（仅限文件）：当写入文件的内容时，这个值会增加。&lt;&#x2F;li&gt;
&lt;li&gt;锁生成编号：当节点的锁从空闲状态转换到被持有状态时，这个值会增加。&lt;&#x2F;li&gt;
&lt;li&gt;ACL 生成编号：当写入节点的 ACL 名称时，这种情况会增加。&lt;&#x2F;li&gt;
&lt;li&gt;Chubby 还开放了一个 64 位的文件内容校验和，以便客户端可以判断文件是否有变化。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;客户端通过打开节点以获得类似于 UNIX 文件描述符的句柄。句柄包括：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;校验位：阻止客户端自行创建或猜测句柄，所以完整的访问控制检查只需要在句柄创建时执行（对比 UNIX，UNIX 在打开时检查权限位但在每次读写时不检查，因为文件描述符不能伪造）。&lt;&#x2F;li&gt;
&lt;li&gt;一个序列号：这个序列号允许 Master 分辨一个句柄是由它或前面的 Master 生成。&lt;&#x2F;li&gt;
&lt;li&gt;模式信息：在句柄打开时设定的是否允许新 Master 在遇见一个由前面的 Master 创建的旧句柄时重建该句柄的状态。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;2-4-locks-and-sequencers&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#2-4-locks-and-sequencers&quot; aria-label=&quot;Anchor link for: 2-4-locks-and-sequencers&quot;&gt;2.4 Locks and sequencers&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;每个 Chubby 文件和目录都可以充当读&#x2F;写锁：一个客户端句柄可以在独占（写）模式下持有锁，或者任意数量的客户端句柄可以在共享（读）模式下持有锁。就像大多数程序员所知道的互斥锁 (mutexes) 一样，锁是协同锁 (advisory lock)。也就是说，它们只与获取相同锁的其他请求冲突：持有锁 F 既不是访问文件 F 的必要条件，也不会阻止其他客户端访问文件 F。我们舍弃强制锁 (mandatory lock)，因为它使得其他没有持有锁的客户端不能访问被锁定的对象：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Chubby 锁通常保护由其他服务实现的资源，而不仅仅是与锁相关的文件。要以一种有意义的方式强制实施强制锁定，我们需要对这些服务进行更广泛的修改。&lt;&#x2F;li&gt;
&lt;li&gt;我们不希望强制用户在出于调试或管理目的需要访问锁定的文件时关闭应用程序。在复杂的系统中，使用大多数个人计算机上使用的方法比较困难，在这种情况下，管理软件可以通过指示用户关闭其应用程序或重新启动来打破强制锁。&lt;&#x2F;li&gt;
&lt;li&gt;我们的开发人员以传统的方式执行错误检查，编写诸如 &amp;quot;持有锁 X&amp;quot; 之类的断言，因此他们从强制检查中获益甚微。当不持有锁时，有 bug 的或恶意的进程有很多机会破坏数据，所以我们发现强制锁提供的额外保护没有多大价值。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;在 Chubby 中，请求任意模式的锁都需要写权限，因而一个无权限的读者不能阻止一个写者的操作。&lt;&#x2F;p&gt;
&lt;p&gt;在分布式系统中，锁是复杂的，因为通信经常是不确定的，并且进程可能会独立地失败。因此可能会出现这种情况，持有锁 L 的进程可能会发出请求 R，但随后就会失败了。另一个进程可能在 R 获取之前就获得了 L，并执行了一些操作。如果 R 稍后到达，它可能在没有 L 保护的情况下被执行，并且可能对不一致的数据进行操作。接收消息顺序紊乱的问题已经被研究得很彻底：解决方案包括虚拟时间 (virtual time) 和虚拟同步 (virtual synchrony) 后者通过确保与每个参与者的观察一致的顺序处理消息，从而避免了这个问题。&lt;&#x2F;p&gt;
&lt;p&gt;在现有的复杂系统中，将序列号引入到所有的交互中的成本是很高的。相反，Chubby 提供了一种方法，通过这种方法，序列号只被引入到那些使用锁的交互中。在任何时候，锁的持有者都可以请求一个 &lt;em&gt;sequencer&lt;&#x2F;em&gt;，这是一个不透明的字节串，描述锁在刚获取后的状态。它包含锁的名称、获取锁的模式（独占或共享）以及锁的生成号 ( generation number)。如果客户端希望它的操作受到锁的保护，那么它就会将 &lt;em&gt;sequencer&lt;&#x2F;em&gt; 传递给服务器（例如文件服务器）。接收服务器要做的工作是检测 &lt;em&gt;sequencer&lt;&#x2F;em&gt; 是否仍然有效并具有适当的模式；如果不是，则应拒绝请求。可以根据服务器的 Chubby 缓存来检查 &lt;em&gt;sequencer&lt;&#x2F;em&gt; 的有效性，如果服务器不希望维护与 Chubby 的会话，也可以根据服务器观察到的最近的 &lt;em&gt;sequencer&lt;&#x2F;em&gt; 来检查。&lt;em&gt;sequencer&lt;&#x2F;em&gt; 机制只需要向受影响的消息添加一个字符串，并且很容易向我们的开发人员解释。&lt;&#x2F;p&gt;
&lt;p&gt;虽然我们发现 &lt;em&gt;sequencer&lt;&#x2F;em&gt; 使用简单，但重要的协议发展缓慢。因此，Chubby 提供了一种不完美但更简单的机制，以减少向不支持 &lt;em&gt;sequencer&lt;&#x2F;em&gt; 的服务器发送延迟或重新排序请求的风险。如果一个客户端以正常的方式释放了一个锁，那么其他客户端就可以立即使用这个锁。但是，如果锁因为持有者停止工作或不可访问而变为空闲状态，则锁服务器将在一段被称为锁延迟 (lock-delay) 的时间段内阻止其他客户端请求锁。客户端可以指定任何锁延迟（目前上限是一分钟）；这个限制可以防止错误的客户端使锁（以及一些资源）在长时间内不可用。虽然不完美，但锁延迟保护未修改的服务器和客户端免受消息延迟和重启造成的日常问题。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;2-5-events&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#2-5-events&quot; aria-label=&quot;Anchor link for: 2-5-events&quot;&gt;2.5 Events&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;Chubby 客户端在创建句柄时可能订阅一系列事件。这些事件通过来自 Chubby 库的向上调用被异步传递到客户端。活动包括：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;文件内容修改——通常用于监视通过文件发布的服务。&lt;&#x2F;li&gt;
&lt;li&gt;子节点 added， removed， 或 modified——用于实现镜像。（除了允许发现新文件之外，为子节点返回事件还可以监视临时文件而不影响它们的引用计数。)&lt;&#x2F;li&gt;
&lt;li&gt;Chubby master 故障恢复——警告客户端其他事件可能已经丢失，因此必须重新检查数据。&lt;&#x2F;li&gt;
&lt;li&gt;句柄（及其锁）已经失效——这通常意味着通信问题。&lt;&#x2F;li&gt;
&lt;li&gt;锁定获取——可用于判断什么时候 Primary 被选出来了。&lt;&#x2F;li&gt;
&lt;li&gt;来自另一个客户端的冲突锁请求允许缓存锁。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;事件是在相应的操作发生之后被传递的。因此，如果客户端被告知文件内容已经更改，那么它随后读取文件时，保证能看到新数据（或最近的数据）。&lt;&#x2F;p&gt;
&lt;p&gt;上面提到的最后两种事件很少用到，事后想来，可以忽略不计。例如，在 Primary 选举之后，客户端通常需要与新的 Primary 进行通信，而不是简单地知道 Primary 的存在；因此，它们会等待 Primary 将地址写入文件的文件修改事件。锁冲突事件在理论上允许客户端缓存其他服务器上的数据，使用 Chubby 锁来维护缓存一致性。一个冲突的锁请求将会告诉客户端结束使用与锁相关的数据：它将结束进行等待的操作、将修改刷新到原来的位置 (home location)、丢弃缓存的数据并释放锁。到目前为止，还没有人采用这种方式。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;2-6-api&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#2-6-api&quot; aria-label=&quot;Anchor link for: 2-6-api&quot;&gt;2.6 API&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;客户端将一个 Chubby 的句柄视为一个指向支持各种操作的不透明结构的指针。句柄仅由 Open() 创建，Close() 销毁。&lt;&#x2F;p&gt;
&lt;p&gt;Open() 打开指定的文件或目录以生成句柄，类似于 UNIX 文件描述符。只有这个调用使用节点名；其他的调用都在句柄上操作。&lt;&#x2F;p&gt;
&lt;p&gt;相对于现有的目录句柄计算名称；库提供了一个始终有效的 &amp;quot;&#x2F;&amp;quot; 句柄。目录句柄避免了在包含许多抽象层的多线程程序中使用程序范围内的当前目录的困难 (Directory handles avoid the difficulties of using a program-wide current directory in a multi-threaded program that contains many layers of abstraction)。&lt;&#x2F;p&gt;
&lt;p&gt;客户端提供多种选项：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;句柄将如何使用 (reading, writing and locking；改变 ACL )；只有当客户端具有适当的权限时，才会创建句柄。&lt;&#x2F;li&gt;
&lt;li&gt;应该传递的事件 （参见 2.5)。&lt;&#x2F;li&gt;
&lt;li&gt;锁延迟 （参见 2.4)。&lt;&#x2F;li&gt;
&lt;li&gt;是否应该（或必须）创建新文件或目录。如果创建了一个文件，调用者可以提供初始内容和初始的 ACL 名称。其返回值表明这个文件实际上是否已经创建。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Close() 关闭打开的句柄。不允许进一步使用该句柄。这个调用不会失败。一个相关的调用 Poison() 会导致句柄上的未完成操作和后续操作失败，而不关闭它；这允许客户端取消其他线程发出的 Chubby 调用，而不必担心释放它们访问的内存。&lt;&#x2F;p&gt;
&lt;p&gt;作用于句柄的主要调用有：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;GetContentsAndStat() 返回文件的内容和元数据。文件的内容被原子地、完整地读取。我们避免了部分读和写来阻止大文件。一个相关的调用 GetStat() 只返回元数据，而 ReadDir 返回子目录的名称和元数据。&lt;&#x2F;li&gt;
&lt;li&gt;SetContents() 写一个文件的内容。可选地，客户端可以提供内容生成编号 (generation number)，以允许客户端模拟文件上的 compare-and-swap；只有在生成编号是当前值时，内容才被改变。文件的内容总是以原子地、完整地写入。一个相关的调用 SetACL() 在节点关联的 ACL 名称执行类似的操作。&lt;&#x2F;li&gt;
&lt;li&gt;Delete() 如果节点没有孩子删除该节点。&lt;&#x2F;li&gt;
&lt;li&gt;Acquire()，TryAcquire()， Release() 获取和释放锁。&lt;&#x2F;li&gt;
&lt;li&gt;GetSequencer() 返回一个序号（参见 2.4)，它描述这个句柄持有的任何锁。&lt;&#x2F;li&gt;
&lt;li&gt;SetSequalizer() 将一个序号与一个句柄相关联。如果序号不再有效，则句柄上的后续操作将失败。&lt;&#x2F;li&gt;
&lt;li&gt;CheckSequencer() 检查序号是否有效（参见 2.4)。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;如果在创建句柄之后删除了节点，即使随后重新创建了文件，调用也会失败。也就是说，句柄与文件实例相关联，而不是与文件名相关联。Chubby 可能在任意的调用上使用访问控制，但总是检查 Open() 调用（参见 2.3)。&lt;&#x2F;p&gt;
&lt;p&gt;除了调用本身所需的任何其他参数外，上面的所有调用都使用一个操作参数。这个操作参数保存可能与任何调用相关联的数据和控制信息。特别是通过操作参数，客户可以：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;提供一个回调，使调用异步，&lt;&#x2F;li&gt;
&lt;li&gt;等待此类呼叫的完成，和&#x2F;或&lt;&#x2F;li&gt;
&lt;li&gt;获取扩展的错误和诊断信息。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;客户端可以使用此 API 执行以下 Primary 选举：所有潜在的 Primary 选举都打开锁文件并尝试获取锁。其中一个成功并成为 Primary ，而其他的作为复制品。Primary 使用 SetContents() 将其标识写入锁文件，以便客户端和副本能够找到它，这些副本使用 GetContentsAndStat() 读取文件，可能是响应文件修改事件。理想情况下，Primary 通过 GetSequencer() 取得一个序号，然后将其传递给与之通信的服务器；它们应该用 CheckSequencer() 确认它仍然是 Primary。锁延迟可用于无法检查序号的服务。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;2-7-cache&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#2-7-cache&quot; aria-label=&quot;Anchor link for: 2-7-cache&quot;&gt;2.7 Cache&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;为了减少读流量，Chubby 客户端将文件数据和节点元数据（包括文件缺失）缓存在内存中的一个一致的写缓存中。缓存由下面描述的租约机制维护，并通过 Master 发送的失效操作维护一致性，Master 保存每个客户端可能缓存的数据的列表。该协议确保客户端要么看到一致的 Chubby 状态，要么看到错误。&lt;&#x2F;p&gt;
&lt;p&gt;当要更改文件数据或元数据时，修改将被阻塞，而 Master 将数据的失效通知发送给可能已缓存数据的每个客户端；这个机制位于 KeepAlive RPC 之上，下一节将对此进行更详细的讨论。在收到无效通知时，客户端刷新无效状态并通过发出下一个 KeepAlive 调用进行确认。只有在服务器知道每个客户端都将这些缓存失效之后，修改才会继续进行，这可能是因为客户端确认了失效，也可能是因为客户端允许其缓存租约过期。&lt;&#x2F;p&gt;
&lt;p&gt;只需要进行一轮失效操作，因为 Master 在缓存过期信号没有确认期间将这个节点视为不可缓存的。这种方法允许读取总是被无延迟地处理；这很有用，因为读的数量远远超过写的数量。另一种方法是在失效期间阻止访问节点的调用；这将减少过度渴望的客户端在失效期间用未完成的访问轰炸 Master 的可能性，代价是偶尔的延迟。如果这是一个问题，人们可能会想采用一种混合方案，在检测到过载时切换处理策略。&lt;&#x2F;p&gt;
&lt;p&gt;缓存协议很简单：它在更改时使缓存的数据失效，并且永远不会更新它。它只是简单的更新而不是失效，但是只更新的协议可能会无理由地低效；访问文件的客户端可能会无限期地接收更新，从而导致大量不必要的更新。&lt;&#x2F;p&gt;
&lt;p&gt;尽管提供严格一致性的开销很大，我们还是拒绝了较弱的模型，因为我们觉得程序员会发现它们更难使用。类似地，像虚拟同步 (virtual synchrony) 这种要求客户端在所有的消息中交换序号的机制，在一个有多种已经存在的通信协议的环境中也被认为是不合适的。&lt;&#x2F;p&gt;
&lt;p&gt;除了缓存数据和元数据之外，Chubby 客户端还缓存打开的句柄。因此，如果客户端打开了它之前打开的文件，那么只有第一个 Open() 调用必然会导致 RPC 到达主机。这种缓存在一些次要的方面受到限制，因此它不会影响客户端观察到的语义：临时文件上的句柄在被应用程序关闭后，不能再保留在打开状态；而容许锁定的句柄则可被重用，但是不能由多个应用程序句柄并发使用。最后的这个限制是因为客户端可能利用 Close() 或者 Poison() 的边际效应：取消正在进行的向 Master 请求的 Accquire() 调用。&lt;&#x2F;p&gt;
&lt;p&gt;Chubby 的协议允许客户端缓存锁——也就是说，持有锁的时间比严格要求的长，希望它们可以被同一个客户端再次使用。如果另一个客户端请求了一个冲突锁，则事件通知锁持有者，这允许锁持有者只在别的地方需要这个锁时才释放锁。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;2-8-sessions-and-keepalives&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#2-8-sessions-and-keepalives&quot; aria-label=&quot;Anchor link for: 2-8-sessions-and-keepalives&quot;&gt;2.8 Sessions and KeepAlives&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;Chubby 会话是 Chubby cell 和 Chubby 的客户端之间的一种关系；它存在一段时间，由定期的握手来维持，这种握手被称为 KeepAlive。除非 Chubby 客户端通知 Master ，否则客户端的句柄、锁和缓存的数据都是有效的，前提是它的会话仍然有效。（然而，会话维持的协议可能要求客户端确认一个缓存过期信号以维持它的会话，请看下文）。&lt;&#x2F;p&gt;
&lt;p&gt;一个客户端在第一次联系一个 Chubby cell 的 Master 时请求一个新的会话。它显式地结束会话，或者在它终止时，或者在会话处于空闲状态时（一分钟内没有打开句柄和调用）。&lt;&#x2F;p&gt;
&lt;p&gt;每个会话都有一个相关的租期——一段延伸到将来的时间，在此期间， Master 保证不会单方面终止会话。间隔的结束被称作租期到期时间 (lease timeout)。 Master 可以自由地向未来延长租期到期时间，但可能不会在时间上往回移动。&lt;&#x2F;p&gt;
&lt;p&gt;在三种情形下， Master 延长租期到期时间：在创建会话时、 Master 故障恢复时（见下面）以及响应来自客户端的 KeepAlive RPC 时。在接收到 KeepAlive 时， Master 通常会阻塞这个 RPC（不允许它返回），直到客户端之前的租期接近到期。 Master 稍后允许 RPC 返回客户端，并将新的租约超时通知客户端。 Master 可以将超时时间延长任意数量。默认的延伸是 12s，但是一个过载的 Master 可能使用更高的值来减少它必须处理的 KeepAlive 调用的数量。在收到之前的回复后，客户端立即启动一个新的 KeepAlive。这样，客户端确保在 Master 上几乎总是阻塞一个 KeepAlive 调用。&lt;&#x2F;p&gt;
&lt;p&gt;除了扩展客户端的租期外，KeepAlive 的回复还用于将事件和缓存失效发送回客户端。 Master 允许一个 KeepAlive 在有事件或者缓存过期需要递送时提前返回。在 KeepAlive 应答上搭载事件可以确保客户端在不确认缓存失效的情况下无法维护会话，并导致所有 Chubby 的 RPC 从客户端流向 Master 。这样既简化了客户端，也使得协议可以通过只允许单向发起连接的防火墙。&lt;&#x2F;p&gt;
&lt;p&gt;客户端维护一个本地租约超时，这是 Master 租约超时的保守的近似值。它跟 Master 的租期过期不一样，是因为客户端必须在两方面做保守的假设。一是 KeepAlive 花在传输上的时间，一是 Master 的时钟超前的度；为了保持一致性，我们要求服务器的时钟频率相对于客户端的时钟频率，不会快于某个常数量。&lt;&#x2F;p&gt;
&lt;p&gt;如果客户端的本地租约超时过期，它将不确定 Master 是否已终止了它的会话。客户端清空并禁用其缓存，我们称它的会话处于危险之中。客户端等待一个称为宽限期的间隔，默认为 45 秒。如果客户端和 Master 在客户端的宽限期结束之前成功 KeepAlive，则客户端将再次启用其缓存。否则，客户端假定会话已经过期。这样做是为了使 Chubby API 调用不会在一个 Chubby cell 变得不可访问时无限期阻塞；如果在通讯重新建立之前宽限期结束了，调用返回一个错误。&lt;&#x2F;p&gt;
&lt;p&gt;当宽限期开始时，Chubby 库可以通过危险事件通知应用程序。当会话在通信问题中幸存下来时，安全事件告诉客户端继续；如果会话超时，则发送一个过期事件。此信息允许应用程序在不确定其会话状态时暂停自身，并在问题被证明是暂时的情况下无需重新启动即可恢复。在启动开销很高的服务中，这在避免服务不可用方面可能是很重要的。&lt;&#x2F;p&gt;
&lt;p&gt;如果客户端持有节点上的句柄 H，而 H 上的任何操作由于关联的会话过期而失败，则 H 上的所有后续操作 ( Close() 和 Poison() 除外 ) 都将以相同的方式失败。客户端可以使用它来保证网络和服务器不可用时只导致操作序列的一个后缀丢失，而不是一个任意的子序列，从而允许使用最终写入将复杂的更改标记为已提交。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;2-9-fail-overs&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#2-9-fail-overs&quot; aria-label=&quot;Anchor link for: 2-9-fail-overs&quot;&gt;2.9 Fail-overs&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;当 Master 失败或丢失 Master 身份时，它将丢弃关于会话、句柄和锁的内存状态。会话租约的权威计时器在 Master 上运行，因此，在选出新的 Master 之前，会话租约计时器将停止；这是合法的，因为它相当于延长客户的租约。如果 Master 选举发生得很快，客户端可以在本地（近似）租约到期之前联系新 Master 。如果选举需要很长时间，客户端就会清空他们的缓存，等待宽限期 (grace period)，同时试图找到新的 Master 。因此，宽限期允许在超过正常租约超时的故障恢复间维护会话。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;chubby&#x2F;image-20210508182616486.png&quot; alt=&quot;image-20210508182616486&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;上图显示了一个漫长的故障恢复事件中的事件序列，在这个事件中，客户端必须使用其宽限期来保存其会话。时间从左到右递增，但时间不是按比例递增的。客户端会话租约以粗箭头显示，新旧 Master （上面的 M1-3) 和客户端（下面的 C13) 都是这样看的。向上的箭头表示 KeepAlive 请求，向下的箭头表示应答。原始的 Master 为客户端提供了会话租赁 M1，而客户端则有一个保守的近似 C1。 Master 承诺在通过 KeepAlive reply 2 通知客户前租赁 M2；客户端能够扩展其对租约 C2 的视图。原 Master 在应答下一个 KeepAlive 之前死掉了，过了一段时间后另一个 Master 被选出。最终客户端的近似租约 (C2) 到期。然后客户端刷新它的缓存并为宽限期启动一个计时器。&lt;&#x2F;p&gt;
&lt;p&gt;在此期间，客户端无法确定其租约在 Master 处是否已经到期。它不会破坏它的会话，但它会阻止所有应用程序对其 API 的调用，以防止应用程序观察到不一致的数据。在宽限期开始时，Chubby 库向应用程序发送一个危险事件，允许它暂停自己，直到确定其会话的状态。&lt;&#x2F;p&gt;
&lt;p&gt;最终，新的 Master 选举成功了。 Master 最初使用的是一个保守的近似 M3 的会话租约，它的前身可能已经为客户端提供了这个租约。从客户端到新 Master 的第一个 KeepAlive 请求 (4) 被拒绝，因为它的 Master 代数不正确（下面详细描述）。重试请求 (6) 成功，但通常不会进一步扩展主租约，因为 M3 是保守的。但是，应答 (7) 允许客户端再次延长其租约 (C3)，并可选地通知应用程序其会话不再处于危险中。因为宽限期足够长，可以覆盖租赁 C2 结束到租赁 C3 开始的这段时间，客户端看到的只是延迟。如果宽限期小于这个间隔，客户端将放弃会话并向应用程序报告失败。&lt;&#x2F;p&gt;
&lt;p&gt;一旦客户端联系了新 Master ，客户端库和 Master 就会合作向应用程序提供没有发生故障的假象。为了实现这一点，新 Master 必须重构前一个 Master 在内存中的状态的保守近似值 (conservative approximation)。这部分是通过读取磁盘上稳定存储的数据（通过普通的数据库复制协议进行复制），部分是通过从客户端获取状态，部分是通过保守的假设 (conservative assumptions) 实现的。数据库记录每个会话、持有的锁和临时文件。&lt;&#x2F;p&gt;
&lt;p&gt;新选出的 Master 过程如下：&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;它首先选择一个新的代编号（epoch number），客户端需要在每次调用时显示它。 Master 拒绝使用旧的 epoch number 的客户端调用，并提供新的 epoch number。这可以确保新 ster 不会响应发送给前一个 Master 的旧包，即使是在同一台机器上运行的包。&lt;&#x2F;li&gt;
&lt;li&gt;新 Master 可以响应 Master 位置请求，但不首先处理与会话相关的传入操作。&lt;&#x2F;li&gt;
&lt;li&gt;它为记录在数据库中的会话和锁构建内存中的数据结构。会话租期被扩展到前一个 Master 可能使用的最大限度。&lt;&#x2F;li&gt;
&lt;li&gt;Master 现在允许客户端执行 KeepAlives，但不允许执行其他与会话相关的操作。&lt;&#x2F;li&gt;
&lt;li&gt;它向每个会话发出故障恢复事件；这将导致客户端刷新它们的缓存（因为它们可能错过了失效），并警告应用程序其他事件可能已经丢失。&lt;&#x2F;li&gt;
&lt;li&gt;Master 一直等待，直到每个会话确认故障恢复事件或让其会话过期。&lt;&#x2F;li&gt;
&lt;li&gt;Master 允许所有操作继续进行。&lt;&#x2F;li&gt;
&lt;li&gt;如果客户端使用在故障恢复之前创建的句柄（根据句柄中序列号的值确定），则 Master 将在内存中重新创建句柄的表示，并执行调用。如果重新创建的句柄关闭，主句柄将把它记录在内存中，这样就不能在 Master epoch 中重新创建它；这确保延迟的或重复的网络包不会意外地重新创建一个关闭的句柄。一个有问题的客户端能在未来的时间中重建一个已关闭的句柄，但倘若该客户端已经有问题的话，则这样不会有什么危害。&lt;&#x2F;li&gt;
&lt;li&gt;在一段时间之后（比如一分钟）， Master 删除没有打开的文件句柄的临时文件。在故障恢复后的这段时间内，客户端应该刷新临时文件的句柄。这种机制有一个不幸的后果，如果文件上的最后一个客户端在故障恢复间丢失了会话，临时文件可能不会立即消失。&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;与系统的其他部分相比，故障恢复代码的执行频率要低得多，因此读者会毫不惊讶地发现，故障恢复代码是有趣 bug 的丰富来源。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;2-10-database-implementation&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#2-10-database-implementation&quot; aria-label=&quot;Anchor link for: 2-10-database-implementation&quot;&gt;2.10 Database implementation&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;Chubby 第一版使用带复制的 Berkeley DB 版本作为它的数据库。Berkeley DB 提供了 B-tree，它可以将字节字符串键映射到任意的字节字符串值。我们设置了一个按照路径名称中的节数排序的键比较函数，这样就允许节点用它们的路径名作为键，同时保证兄弟节点在排序顺序中相邻。因为 Chubby 不使用基于路径的权限，所以只需在数据库中进行一次查询，就可以对每个文件进行访问。&lt;&#x2F;p&gt;
&lt;p&gt;Berkeley DB 使用分布式一致性协议在一组服务器上复制其数据库日志。一旦 Master 租约被添加，这就与 Chubby 的设计相匹配，使得实现变得简单。&lt;&#x2F;p&gt;
&lt;p&gt;虽然 Berkeley DB 的 B-tree 代码使用广泛且成熟，但是复制代码是最近添加的，并且用户较少。维护者必须优先维护和改进他们的最受欢迎的产品特性。虽然 Berkeley DB 的维护者解决了我们遇到的问题，但是我们觉得使用复制代码会使我们承担更多的风险。因此，我们使用类似于 Birrell 等人的设计的提前写日志和快照来编写一个简单的数据库。与前面一样，数据库日志使用分布式一致性协议在副本之间分布。Chubby 很少使用 Berkeley DB 的特性，所以这次重写使得整个系统变得非常简单；例如，虽然我们需要原子操作，但是我们不需要通用事务。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;2-11-backup&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#2-11-backup&quot; aria-label=&quot;Anchor link for: 2-11-backup&quot;&gt;2.11 Backup&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;每几个小时，Chubby cell 的主节点将快照写到不同大楼的 GFS 文件服务的数据库中。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;2-12-mirroring&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#2-12-mirroring&quot; aria-label=&quot;Anchor link for: 2-12-mirroring&quot;&gt;2.12 Mirroring&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;Chubby 允许将文件集合从一个 cell 镜像到另一个 cell。镜像非常快，因为文件很小，而且如果文件被添加、删除或修改，事件机制会立即通知镜像处理相关代码。如果没有网络问题，变化会一秒之内便在世界范围内的很多个镜像中反映出来。如果无法访问镜像，则镜像将保持不变，直到恢复连接为止。然后通过比较校验和来识别更新的文件。&lt;&#x2F;p&gt;
&lt;p&gt;镜像最常用来将配置文件复制到分布在世界各地的各种计算集群。一个名为 global 的特殊 cell 包含一个子树 &#x2F;ls&#x2F;global&#x2F;master，该子树 &#x2F;ls&#x2F;cell&#x2F;slave 被镜像到其他每个 Chubby 的 cell 中。global cell 是特殊的，因为它的五个副本位于世界上分布广泛的地方，所以它几乎总是可以从从大部分国家&#x2F;地区访问。&lt;&#x2F;p&gt;
&lt;p&gt;从 global cell 中镜像出的文件中包括 Chubby 自己的访问控制列表、各种文件（其中 Chubby cell 和其他系统向我们的监控服务显示它们的存在）、允许客户端定位大数据集（如 Bigtable cell）的指针以及其他系统的许多配置文件。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;3-mechanisms-for-scaling-lue&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#3-mechanisms-for-scaling-lue&quot; aria-label=&quot;Anchor link for: 3-mechanisms-for-scaling-lue&quot;&gt;3. Mechanisms for scaling（略）&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;3-1-proxies&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#3-1-proxies&quot; aria-label=&quot;Anchor link for: 3-1-proxies&quot;&gt;3.1 Proxies&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;h3 id=&quot;3-2-partitioning&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#3-2-partitioning&quot; aria-label=&quot;Anchor link for: 3-2-partitioning&quot;&gt;3.2 Partitioning&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;h2 id=&quot;4-use-surprises-and-design-errors&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#4-use-surprises-and-design-errors&quot; aria-label=&quot;Anchor link for: 4-use-surprises-and-design-errors&quot;&gt;4. Use, surprises and design errors&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;4-1-use-and-behavior&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#4-1-use-and-behavior&quot; aria-label=&quot;Anchor link for: 4-1-use-and-behavior&quot;&gt;4.1 Use and behavior&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;h3 id=&quot;4-2-java-clients&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#4-2-java-clients&quot; aria-label=&quot;Anchor link for: 4-2-java-clients&quot;&gt;4.2 Java Clients&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;略&lt;&#x2F;p&gt;
&lt;h3 id=&quot;4-3-use-as-a-name-service&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#4-3-use-as-a-name-service&quot; aria-label=&quot;Anchor link for: 4-3-use-as-a-name-service&quot;&gt;4.3 Use as a name Service&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;尽管 Chubby 被设计为一个锁服务，但我们发现它最流行的用法是作为名称服务器。&lt;&#x2F;p&gt;
&lt;p&gt;在常规的 Internet 命名系统 (DNS) 中，缓存是基于时间的。DNS 条目有生存时间 (TTL)，如果在此期间没有刷新 DNS 数据，则将丢弃这些数据。通常，选择一个合适的 TTL 值是很简单的，但是如果需要立即替换失败的服务，TTL 会变得很小，以至于使 DNS 服务器超载。&lt;&#x2F;p&gt;
&lt;p&gt;例如，我们的开发人员经常运行涉及数千个进程的任务，并且每个进程之间相互通信，这导致了二次级的 DNS 查询。我们可能希望使用 60 秒的 TTL；这将允许行为不端的客户端被替换，而不会有过多的延迟，并且在我们的环境中不会被认为是一个不合理的短替换时间。在这种情况下，要维护单个任务的 DNS 缓存（最小为 3000 个客户端），需要每秒 15 万个查询（相比之下，一个 2-CPU 2.6GHz 的 Xeon DNS 服务器每秒可以处理 5 万个请求）。更大的任务产生更恶劣的问题，并且多个任务可能同时执行。在引入 Chubby 之前，我们的 DNS 负载的波动性是 Google 面临的一个严重问题。&lt;&#x2F;p&gt;
&lt;p&gt;相比之下，Chubby 的缓存使用显示地失效 (invalidations)，因此恒定速率的会话 KeepAlive 请求可以在没有更改的情况下在客户端上无限期地维护任意数量的缓存条目。一个 2-CPU 2.6GHz 的 Xeon Chubby Master 可以处理与它直接通信的 9 万个客户端（没有代理）；这些客户端包括了具有上文描述过的那种通讯模式的庞大任务。在不逐个轮询每个名称的情况下提供快速名称更新的功能非常有吸引力，以至于现在 Google 的大部分系统都由 Chubby 提供名字服务。&lt;&#x2F;p&gt;
&lt;p&gt;尽管 Chubby 的缓存允许一个单独的 cell 能承受大量的客户端，但负载峰值仍然是一个问题。当我们第一次部署基于 Chubby 的名称服务时，启动一个 3000 个进程任务（从而产生 900 万个请求）可能会让 Chubby Master 崩溃。为了解决这个问题，我们选择将名称条目分组成批，这样一次查询就可以返回并缓存作业中大量相关进程（通常为 100 个）的名称映射。&lt;&#x2F;p&gt;
&lt;p&gt;Chubby 提供的缓存语义要比名字服务需要的缓存语义更加精确；名称解析只需要及时通知，而不需要完全一致。因而，这里有一个时机，可以通过引入特别地为名字查找设计的简单协议转换服务器，来降低 Chubby 的负载。假如我们预见到将 Chubby 用作名字服务的用法，我们可能选择实现完整的代理，而不是提供这种简单但没有必要的额外的服务器。&lt;&#x2F;p&gt;
&lt;p&gt;还有一个协议转换服务器：Chubby 的 DNS 服务器。这使得存储在 Chubby 中的命名数据对 DNS 客户端可用。这种服务器很重要，它既能减少了 DNS 名字到 Chubby 名字之间的转换，也能适应已经存在的不能轻易转换的应用程序，例如浏览器。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;4-4-problems-with-fail-over&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#4-4-problems-with-fail-over&quot; aria-label=&quot;Anchor link for: 4-4-problems-with-fail-over&quot;&gt;4.4 Problems with fail-over&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;h3 id=&quot;4-5-abusive-clients&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#4-5-abusive-clients&quot; aria-label=&quot;Anchor link for: 4-5-abusive-clients&quot;&gt;4.5 Abusive clients&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;h3 id=&quot;4-6-lessons-learned-jing-yan-jiao-xun&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#4-6-lessons-learned-jing-yan-jiao-xun&quot; aria-label=&quot;Anchor link for: 4-6-lessons-learned-jing-yan-jiao-xun&quot;&gt;4.6 lessons learned（经验教训）&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;在这里，我们列出了经验教训，以及如果有机会，我们可能会做的各种设计更改：&lt;&#x2F;p&gt;
&lt;p&gt;开发者极少考虑可用性。 我们发现开发者极少考虑失败的可能性，并倾向于认为像 Chubby 这样的服务好像总是可用的。例如，我们的开发人员曾经构建了一个系统，该系统使用了数百台机器，在 Chubby 选出新 Master 时，启动恢复过程需要几十分钟。这将单个故障的后果在时间和受影响的机器数量上都放大了 100 倍。我们希望开发人员为短时间的中断做好计划，以便这样的事件对他们的应用程序影响很小或没有影响。这是第 2.1 节讨论的粗粒度锁的参数之一。&lt;&#x2F;p&gt;
&lt;p&gt;开发人员也没有意识到服务启动与应用程序可用之间的区别。例如，global Chubby cell 几乎总是处于上升状态，因为同时处于下降状态的数据中心很少超过两个。但是，对于给定的客户端，其观察到的可用性通常低于客户端的局部 Chubby cell 的观察到的可用性。首先，本地 cell 不太可能与客户端分区，其次，虽然本地 cell 可能经常由于维护而停机，但是相同的维护直接影响客户端，所以客户端不会观察到 Chubby 的不可用性。&lt;&#x2F;p&gt;
&lt;p&gt;我们的 API 选择也会影响开发人员处理 Chubby 停机的方式。例如，Chubby 提供了一个事件，允许客户端检测 Master 故障恢复何时发生。目的是让客户端检查可能的更改，因为其他事件可能已经丢失。不幸的是，许多开发人员选择在收到这个事件时关闭他们的应用程序，从而大大降低了系统的可用性。我们可以更好地发送冗余的&amp;quot;文件更改&amp;quot;事件，甚至确保在故障恢复间没有丢失事件。&lt;&#x2F;p&gt;
&lt;p&gt;目前，我们使用三种机制来防止开发人员对 Chubby 的可用性过于乐观，特别是 global cell 的可用性。首先，正如前面提到的，我们审查了项目团队计划如何使用 Chubby ，并建议他们不要使用那些将其可用性与 Chubby 紧密联系在一起的技术。&lt;&#x2F;p&gt;
&lt;p&gt;其次，我们现在提供执行一些高级任务的库，这样开发人员就可以自动地从中断中隔离出来。第三，我们使用每次 Chubby 停机的事后分析作为一种方法，不仅可以消除 Chubby 和我们的操作过程中的 bug，而且还可以降低应用程序对 Chubby 可用性的敏感性——这两种方法都可以提高系统的整体可用性。&lt;&#x2F;p&gt;
&lt;p&gt;可以忽略细粒度锁定的内容在 2.1 节的末尾，我们概述了一个服务器的设计，客户端可以运行该服务器来提供细粒度锁定。到目前为止，我们还不需要编写这样的服务器，这可能令人感到惊讶；我们的开发人员通常发现，为了优化他们的应用程序，他们必须删除不必要的通信，这通常意味着找到一种使用粗粒度锁定的方法。&lt;&#x2F;p&gt;
&lt;p&gt;糟糕的 API 选择通常会带来意想不到的影响，我们的 API 发展得很好，但有一个错误很明显。我们取消长时间运行的调用的方法是 Close() 和 Poison() RPC，它们也会丢弃句柄的服务器状态。这可以防止获取锁的句柄被共享，例如被多个线程共享。我们可以添加一个 Cancel() RPC 来允许更多地共享打开的句柄。&lt;&#x2F;p&gt;
&lt;p&gt;RPC 的使用影响传输协议 KeepAlives 被用于刷新客户端的会话租约，也用于将事件和缓存失效从 Master 传递给客户端。这个设计有自动的符合预期的效应：一个客户端不能在没有应答缓存过期的情况下刷新会话状态。&lt;&#x2F;p&gt;
&lt;p&gt;这似乎很理想，除了这样会在传输协议的选择中引入紧张情形以外。TCP 的拥塞时回退 (back off) 策略不关心更高层的超时，例如 Chubby 的租期，因此基于 TCP 的 KeepAlive 在发生高网络拥塞时导致许多丢失的会话。我们被迫通过 UDP 而不是 TCP 发送 KeepAlive RPC；UDP 没有拥塞避免机制，因此我们只有当高层的时间界限必须满足时才使用 UDP 协议。&lt;&#x2F;p&gt;
&lt;p&gt;我们可以使用一个附加的基于 TCP 的 GetEvent() RPC 来扩展协议，它将用于在正常情况下通信事件和失效，使用的方式与 KeepAlives 相同。KeepAlive 回复仍然包含未确认事件的列表，因而事件最终都将被应答。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;5-comparision-with-related-work&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#5-comparision-with-related-work&quot; aria-label=&quot;Anchor link for: 5-comparision-with-related-work&quot;&gt;5. Comparision with related work&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;Chubby 基于很多优秀的 idea，cache 设计受到分布式文件系统的启发。session 和 cache 的 token 类似于 Echo 系统中的行为；session 减少了租约的开销。提供一个通用的 lock services 可以在 &lt;a href=&quot;https:&#x2F;&#x2F;wiki.vmssoftware.com&#x2F;Distributed_Lock_Manager&quot;&gt;VMS&lt;&#x2F;a&gt; &lt;a href=&quot;http:&#x2F;&#x2F;www.bitsavers.org&#x2F;pdf&#x2F;dec&#x2F;dtj&#x2F;dtj_v01-05_sep1987.pdf&quot;&gt;期刊&lt;&#x2F;a&gt; 中被发现。像 cache 模型，Chubby 的 API 基于文件系统模型，包括文件系统类似的名字空间的 idea&lt;&#x2F;p&gt;
&lt;p&gt;Chubby 与 Echo 或 AFS 等分布式文件系统在性能和存储方面有所不同：客户端不会读取、写入或存储大量数据，除非数据被缓存，否则它们不会期望高吞吐量甚至低延迟。他们确实期望一致性、可用性和可靠性，但是当性能不那么重要时，这些属性更容易实现。因为 Chubby 的数据库很小，我们可以在线存储它的许多副本（通常是五个副本和少数备份）。我们每天进行多次完全备份，通过数据库状态的校验和，我们每隔几个小时就相互比较副本。正常的文件系统性能和存储需求的弱化使我们能够用一个 Chubby  Master 为成千上万的客户端提供服务。我们通过提供一个中心点，许多客户端在这个中心点共享信息和协同活动，解决了一类我们的系统开发人员面对的问题。&lt;&#x2F;p&gt;
&lt;p&gt;各种文献描述了大量的文件系统和锁服务器，所以不可能做一个彻底的比较。所以我们提供细节：我们选择与 Boxwood 的锁服务器比较，因为它是最近设计的，它也旨在在松耦合的环境中运行，但其设计在很多方面不同于 Chubby，一些设计是有趣的，一些设计是因为系统的差异所决定的。&lt;&#x2F;p&gt;
&lt;p&gt;Chubby 在单个服务中实现锁、可靠的小文件存储系统以及会话&#x2F;租赁机制。相反，Boxwood 将它们分为三个：锁服务、Paxos 服务（状态的可靠存储库）和故障检测服务。Boxwood 系统本身使用这三个组件，但另一个系统可以独立使用这些构件。我们怀疑这种设计上的差异源于目标受众的不同。Chubby 的目标受众和应用程序是多样化的；它的用户范围从创建新分布式系统的专家到编写管理脚本的新手。对于我们的环境，使用熟悉的 API 的大型共享服务似乎很有吸引力。相比之下，Boxwood 提供了一个工具包（至少在我们看来是这样），它适用于少数更成熟的开发人员，他们从事的项目可能共享代码，但不需要一起使用。&lt;&#x2F;p&gt;
&lt;p&gt;在许多情况下，Chubby 提供了比 Boxwood 更高级别的接口。例如，Chubby 组合了锁和文件名空间，而 Boxwood 的锁名称是简单的字节序列。Chubby 客户端默认缓存文件状态；Boxwood 的 Paxos 服务的客户端可以通过锁服务实现缓存，但是很可能会使用 Boxwood 本身提供的缓存。&lt;&#x2F;p&gt;
&lt;p&gt;这两个系统有明显不同的默认参数，为不同的期望而选择：每个客户端每 200 毫秒与每个 Boxwood 故障检测器联系一次，超时为 1； Chubby 的默认租赁时间是 12 秒，每隔 7 秒交换一次 KeepAlives。Boxwood 的子组件使用两个或三个副本来实现可用性，而我们通常每个 cell 使用五个副本。然而，这些选择本身并没有表明深层次的设计差异，而是指出了这些系统中的参数必须如何调整以适应更多的客户端机器，或者机架与其他项目共享的不确定性。&lt;&#x2F;p&gt;
&lt;p&gt;一个更有趣的区别是引入了 Chubby 的宽限期，这是 Boxwood 所缺乏的。（回忆一下，宽限期允许客户在长时间的 Master 宕机期间不丢失会话或锁。Boxwood 的 &amp;quot;宽限期&amp;quot; 相当于 Chubby 的 &amp;quot;会话租赁&amp;quot;，是一个不同的概念。) 同样，这种差异是由于对两个系统的规模和失败概率的期望不同造成的。虽然 Master 故障恢复很少见，但是丢失的 Chubby 锁对客户来说代价是很昂贵的。&lt;&#x2F;p&gt;
&lt;p&gt;最后，这两个系统中的锁用于不同的目的。Chubby 的锁重量更重，需要记序器来保证外部资源的安全，而 Boxwood 锁重量更轻，主要用于 Boxwood 内部。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;6-summary&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#6-summary&quot; aria-label=&quot;Anchor link for: 6-summary&quot;&gt;6. Summary&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;Chubby 是一个分布式锁服务，并且可以用做名字服务以及配置服务。&lt;&#x2F;p&gt;
&lt;p&gt;设计基于一些良好的 idea：共识协议提供了容错能力，一致性客户端 cache 减少了服务负载同时保留了简单的语义，及时的更新通知，熟悉的文件系统接口。我们使用 cacheing， protocol-conversion servers, simple load adaptation 使得一个 Chubby 实例可以服务成千上万 client。并且可以通过 proxies 和 partitioning 扩展。&lt;&#x2F;p&gt;
&lt;p&gt;Chubby 成为 Google 的主要名字服务；是 MapReduce 的约定机制；是 GFS 和 BitTable 的选主组件；是高可用文件的标准组件，例如访问控制。&lt;&#x2F;p&gt;
</content>
    </entry>
    <entry xml:lang="en">
        <title>Bitcask: A Log-Structured Hash Table for Fast Key&#x2F;Value Data</title>
        <published>2021-03-02T00:00:00+00:00</published>
        <updated>2021-03-02T00:00:00+00:00</updated>
        <author>
          <name>Unknown</name>
        </author>
        <link rel="alternate" href="https://wendajiang.github.io/bitcask/" type="text/html"/>
        <id>https://wendajiang.github.io/bitcask/</id>
        <content type="html">&lt;p&gt;译者注：豆瓣的 beansdb 使用 bitcask 概念 https:&#x2F;&#x2F;github.com&#x2F;douban&#x2F;gobeansdb&lt;&#x2F;p&gt;
&lt;p&gt;Bitcask 的起源与 Riak 分布式数据库的历史联系在一起。在 Riak 的 key&#x2F;value 集群中，每个节点都使用插件化的本地存储；几乎任何 k&#x2F;v 形式的引擎都可以来用。这种插件化的设计可以使 Riak 并行化使得存储引擎可以在不影响其他代码的情况下单独升级和测试。&lt;&#x2F;p&gt;
&lt;p&gt;已经存在很多这种 key&#x2F;value 存储引擎，包括但不限于 Berkeley DB，Tokyo Cabinet, Innostore。在评估此类引擎时，我们考虑了许多目标，包括：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;每条数据读写的低延迟&lt;&#x2F;li&gt;
&lt;li&gt;高吞吐，尤其是随机写入&lt;&#x2F;li&gt;
&lt;li&gt;处理远大于 RAM 吞吐能力的数据集的能力&lt;&#x2F;li&gt;
&lt;li&gt;crash 友好性，不管是快速恢复还是不丢失数据&lt;&#x2F;li&gt;
&lt;li&gt;容易备份和恢复&lt;&#x2F;li&gt;
&lt;li&gt;简单，易理解的代码结构和数据格式&lt;&#x2F;li&gt;
&lt;li&gt;在重负载和大规模下的行为可预知&lt;&#x2F;li&gt;
&lt;li&gt;Riak 易于使用的 license&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;实现其中的一些是容易的，但是实现所有特性很难。&lt;&#x2F;p&gt;
&lt;p&gt;就上述所有目标而言，没有现成的 key&#x2F;value 存储系统。我们就这个问题与 Eric Brewer 进行讨论，他提出了一个关键 idea: hash table log merging: 这样做可能比 LSM-trees 快得多。&lt;&#x2F;p&gt;
&lt;p&gt;这促使我们以全新的视角探索了在 1980 和 1990 年代首次开发的 log-structured file system 中使用的一些技术。这次探索引出了 Bitcask   的发展，实现了所有上述特性。当 Bitcask 被作为 Riak 的底层为目标开发出来后，可以作为一个本地 key&#x2F;value 存储引擎通用于其他应用。&lt;&#x2F;p&gt;
&lt;p&gt;最终使用的模型非常简单。一个 Bitcask 实例是一个目录，同一时间只有一个操作系统进程写入 Bitcask。你可以将此进程看做 database server。任何时候，只有一个文件是“活动的”，可以被服务器写入。当文件大小达到阈值，就会被关闭，然后一个新的“活动”文件就被创建出来。一旦文件被关闭，或者由于服务器关闭导致文件被关闭，该文件就被视为不可变的，不会再被服务器写入。模型如下图所示：&lt;&#x2F;p&gt;
&lt;!-- ![image-20210302212335119](https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;2021-03-02-bitcask&#x2F;image-20210302212335119.png) --&gt;
&lt;div align=center&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;2021-03-02-bitcask&#x2F;image-20210302212335119.png&quot; style=&quot;zoom:68%;&quot; &#x2F;&gt;&lt;&#x2F;div&gt;
&lt;p&gt;“活动”文件只能被追加写，这意味着磁盘不需要寻道，数据格式如下：&lt;&#x2F;p&gt;
&lt;!-- ![image-20210302212434833](https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;2021-03-02-bitcask&#x2F;image-20210302212434833.png) --&gt;
&lt;div align=center&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;2021-03-02-bitcask&#x2F;image-20210302212434833.png&quot; style=&quot;zoom:68%;&quot; &#x2F;&gt;&lt;&#x2F;div&gt;
&lt;p&gt;每次写入，文件尾部被追加一条记录。请注意，删除只是写入一个特殊的逻辑删除值，在下一次归并时会被删除。因此，Bitcask 数据文件就像下面的线性条目序列：&lt;&#x2F;p&gt;
&lt;!-- ![image-20210302212631666](https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;2021-03-02-bitcask&#x2F;image-20210302212631666.png) --&gt;
&lt;div align=center&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;2021-03-02-bitcask&#x2F;image-20210302212631666.png&quot; style=&quot;zoom:68%;&quot; &#x2F;&gt;&lt;&#x2F;div&gt;
&lt;p&gt;在每次追加后，内存中的数据结构被称为 &amp;quot;keydir&amp;quot; 会被更新。&amp;quot;keydir&amp;quot; 是一个 hash table ，描述了 Bitcask 中每个 key 的位置（固定结构）（file, offset, value size）&lt;&#x2F;p&gt;
&lt;!-- ![image-20210302212851494](https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;2021-03-02-bitcask&#x2F;image-20210302212851494.png) --&gt;
&lt;div align=center&gt;&lt;img src=&quot;hhttps:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;2021-03-02-bitcask&#x2F;image-20210302212851494.png&quot; style=&quot;zoom:68%;&quot; &#x2F;&gt;&lt;&#x2F;div&gt;
&lt;p&gt;（译者注：file_id表示哪个文件，value_pos 表示offset， 以及value size表示从value_pos取多少数据）&lt;&#x2F;p&gt;
&lt;p&gt;当发生写入时，&#x27;keydir&#x27; 自动根据最新数据更新，老数据仍然存在与硬盘中，但是读取使用 &#x27;keydir&#x27; 记录的最新版本的数据信息。正如稍后我们看到的，归并过程会删除老数据。&lt;&#x2F;p&gt;
&lt;p&gt;读取数据很简单，不会超过一次硬盘寻道。我们在 &#x27;keydir&#x27; 中查找数据的 key 位置，然后使用获得的 file_id, value_pos, value_sz 直接读取数据。在很多情况下，操作系统的文件系统预读高速缓存使此操作比预期要快得多，读取过程如下图&lt;&#x2F;p&gt;
&lt;!-- ![image-20210302213531626](https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;2021-03-02-bitcask&#x2F;image-20210302213531626.png) --&gt;
&lt;div align=center&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;2021-03-02-bitcask&#x2F;image-20210302213531626.png&quot; style=&quot;zoom:68%;&quot; &#x2F;&gt;&lt;&#x2F;div&gt;
&lt;p&gt;这个简单的过程会随着使用时间占用越来越多的存储空间，因为我们一直在写入新数据。一个单独的“归并”进程用来解决这个问题，“归并”进程遍历所有“不活动”数据文件，然后生成一组只包含“活动”数据的文件。&lt;&#x2F;p&gt;
&lt;p&gt;完成此操作之后，我们将在每个数据文件旁创建一个“hint file”，包含对应数据文件的位置和值的大小。&lt;&#x2F;p&gt;
&lt;!-- ![image-20210302213951415](https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;2021-03-02-bitcask&#x2F;image-20210302213951415.png) --&gt;
&lt;div align=center&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;2021-03-02-bitcask&#x2F;image-20210302213951415.png&quot; style=&quot;zoom:68%;&quot; &#x2F;&gt;&lt;&#x2F;div&gt;
&lt;p&gt;当 Bitcask 被 Erlang 进程打开时，会检查是否已经有其他进程已经打开当前 Bitcask，如果有，就会共享 keydir 信息，如果没有，会扫描所有数据文件，然后重建一个新的 keydir。如果数据文件有 ‘hint file’，可以加速这个重建过程。&lt;&#x2F;p&gt;
&lt;p&gt;上述就是 Bitcask 基本操作。显然，我们没有在这个文档中阐释所有操作细节；我们的目标是帮你了解 Bitcask 的概况。实际上还有一些细节讨论：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;上面提到操作系统文件系统的cache可以提升读性能。我们也讨论了加入 bitcask 内部 cache 提升读性能，但是鉴于还没有实现，所以不清楚有多少回报&lt;&#x2F;li&gt;
&lt;li&gt;我们会尽快对 Bitcask 的各个接口做基准测试，但是最开始 Bitcask 就不是为了最快，而是在尽可能快的速度下拥有高质量并且简单的代码，设计和文件格式。不过还是要说，在最初的简单基准测试中，许多场景中 Bitcask 已经快于很多快速存储系统&lt;&#x2F;li&gt;
&lt;li&gt;最困难的实现细节对大多数外人来说也不感兴趣，因此在这份简短的文档中也没有比如 keydir locking 方案的描述&lt;&#x2F;li&gt;
&lt;li&gt;Bitcask 没有对数据进行压缩，因为这样做的成本收益比很大程度上取决于应用&lt;&#x2F;li&gt;
&lt;li&gt;读写条目的低延迟
Bitcask 非常快。我们计划尽快做基准测试，但是在简单测试中，我们对 bitcask 达到目标很有信息&lt;&#x2F;li&gt;
&lt;li&gt;高吞吐，尤其是随机写
笔记本的低速硬盘测试，可以做到每秒 5000-6000 次写入&lt;&#x2F;li&gt;
&lt;li&gt;处理比 RAM 容量更大的数据集
上面提到的测试使用了超过 RAM 10倍的数据集，并且行为没有变化，这符合我们对于 Bitcask 设计的期望&lt;&#x2F;li&gt;
&lt;li&gt;crash 友好，既能快速恢复又不会丢失数据
由于数据文件和提交log在 Bitcask 中是一样的，恢复很容易，无需重放，而且 hint file 可以加速重建过程&lt;&#x2F;li&gt;
&lt;li&gt;易于备份和恢复
在文件关闭后就不可变，因此备份可以使用操作系统的任何操作，恢复只需要将数据文件放置在所需目录即可&lt;&#x2F;li&gt;
&lt;li&gt;相对简单，易于理解的代码结构和数据格式
Bitcask 概念很简单，代码整洁，数据文件非常易于理解和管理。&lt;&#x2F;li&gt;
&lt;li&gt;在负载重或者数据量大的时候行为可预知
在大量访问负载情况下，我们已经看到 Bitcask 表现出色。到目前为止，只达到了两位数 GB 的数据，但是我们不久之后对其进行测试。Bitcask 的设计让我们预期在大数据量的情况下不会表现出太大不同，唯一可预见的就是 keydir 可能会随着数据量而变大可以会占用更多内存。实践中，这种限制不太有问题，即使存在数百万个 key，也只会占用 GB 级别的内存。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;总而言之，鉴于最开始阐述的一组要求，Bitcask 是最适合这些要求的产品。&lt;&#x2F;p&gt;
</content>
    </entry>
    <entry xml:lang="en">
        <title>dataflow_model</title>
        <published>2021-03-02T00:00:00+00:00</published>
        <updated>2021-03-02T00:00:00+00:00</updated>
        <author>
          <name>Unknown</name>
        </author>
        <link rel="alternate" href="https://wendajiang.github.io/dataflow-model/" type="text/html"/>
        <id>https://wendajiang.github.io/dataflow-model/</id>
        <content type="html">&lt;h1 id=&quot;zhai-yao&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#zhai-yao&quot; aria-label=&quot;Anchor link for: zhai-yao&quot;&gt;摘要&lt;&#x2F;a&gt;&lt;&#x2F;h1&gt;
&lt;p&gt;在日常商业运营中，无边界、乱序、大规模数据集越来越普遍了。（例如，网站日志，手机应用统计，传感器网络）。同时，对这些数据的消费需求也越来越复杂。比如说按事件发生时间序列处理数据，按数据本身的特征进行窗口计算等等。同时人们也越来越苛求立刻得到数据分析结果。然而，实践表明，我们永远无法同时优化数据处理的准确性、延迟程度和处理成本等各个维度。因此，数据工作者面临如何协调这些几乎相互冲突的数据处理技术指标的窘境，设计出来各种纷繁的数据处理系统和实践方法。&lt;&#x2F;p&gt;
&lt;p&gt;我们建议数据处理的方法必须进行根本性的改进。作为数据工作者，我们不能把无边界数据集（数据流）切分成有边界的数据，等待一个批次完整后处理。相反地，我们应该假设我们永远无法知道数据流是否终结，何时数据会变完整。唯一应该确信的是，新的数据会源源不断而来，老的数据可能会被撤销或更新。而能够让数据工作者应对这个挑战的唯一可行的方法是通过一个遵守原则的抽象来平衡折衷取舍数据处理的准确性、延迟程度和处理成本。&lt;&#x2F;p&gt;
&lt;p&gt;在这篇论文中，我们提出了Dataflow模型，并详细地阐述了它的语义，设计的核心原则，以及在实践开发过程中对模型的检验。&lt;&#x2F;p&gt;
&lt;h1 id=&quot;1-jian-jie&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#1-jian-jie&quot; aria-label=&quot;Anchor link for: 1-jian-jie&quot;&gt;1. 简介&lt;&#x2F;a&gt;&lt;&#x2F;h1&gt;
&lt;p&gt;现代数据处理是一个复杂而又令人兴奋的领域。MapReduce和它的衍生系统（如Hadoop, Pig, Hive, Spark等）解决了处理数据的“量”上的问题。流处理SQL上社区也做了很多的工作（如查询系统【1,14,15】，窗口【22】，数据流【24】，时间维度【28】，语义模型【9】）。在低延时处理上 Spark Streaming, MillWheel, Storm等做了很多尝试。数据工作者现在拥有了很多强有力的工具把大规模无序的数据加工成结构化的数据，而结构化的数据拥有远大于原始数据的价值。但是我们仍然认为现存的模型和方法在处理一些常见的场景时有心无力。&lt;&#x2F;p&gt;
&lt;p&gt;考虑一个例子：一家流媒体平台提供商通过视频广告，向广告商收费把视频内容进行商业变现。收费标准按广告收看次数、时长来计费。这家流媒体的平台支持在线和离线播放。流媒体平台提供商希望知道每天向广告商收费的金额，希望按视频和广告进行汇总统计。另外，他们想在大量的历史离线数据上进行历史数据分析，进行各种实验。&lt;&#x2F;p&gt;
&lt;p&gt;广告商和内容提供者想知道视频被观看了多少次，观看了多长时间，视频被播放时投放了哪个广告，或者广告播放是投放在哪个视频内容中，观看的人群统计分布是什么。广告商也很想知道需要付多少钱，而内容提供者想知道赚到了多少钱。 而他们需要尽快得到这些信息，以便调整预算&#x2F;调整报价，改变受众，修正促销方案，调整未来方向。所有这些越实时越好，因涉及到金额，准确性是至关重要的。&lt;&#x2F;p&gt;
&lt;p&gt;尽管数据处理系统天生就是复杂的，视频平台还是希望一个简单而灵活的编程模型。最后，由于他们基于互联网的业务遍布全球，他们需要的系统要能够处理分散在全球的数据。&lt;&#x2F;p&gt;
&lt;p&gt;上述场景需要计算的指标包括每个视频观看的时间和时长，观看者、视频内容和广告是如何组合的（即按用户，按视频的观看“会话”）。概念上这些指标都非常直观，但是现有的模型和系统并无法完美地满足上述的技术要求。&lt;&#x2F;p&gt;
&lt;p&gt;批处理系统如MapReduce (包括Hadoop的变种，如Pig，Hive)，FlumeJava, Spark等无法满足时延的要求，因为批处理系统需要等待收集所有的数据成一个批次后才开始处理。对有些流处理系统来说，目前不了解它们在大规模使用的情况下是否还能保持容错性（如(Aurora [1], TelegraphCQ [14], Niagara [15], Esper[17]），而那些提供了可扩展性和容错性的系统则缺乏准确性或语义的表达性。很多系统缺乏“恰好处理一次”的语义（如Storm, Samza, Pulsar）影响了数据的准确性。或者提供了窗口但语义局限于基于记录数或基于数据处理时间的窗口（Spark Streamming, Sonora, Trident）。而大多数提供了基于事件发生时间窗口的，或者依赖于消息必须有序（SQLStream）或者缺乏按事件发生时间触发窗口计算的语义（Stratosphere&#x2F;Flink）。CEDR和Trill可能值得一提，它们不仅提供了有用的标记触发语义，而且提供了一种增量模型，这一点上和我们这篇论文一致，但它们的窗口语义无法有效地表达基于会话的窗口。它们基于标记的触发语义也无法有效处理3.3节中的某些场景。MillWheel和Spark Streaming的可扩展性良好，容错性不错，低延时，是一种合理的方案，但是对于会话窗口缺乏一种直观的高层编程模型。我们发现只有Pulsar系统对非对齐窗口（译者注：指只有部分记录进入某一特定窗口，会话窗口就是一种非对齐窗口）提供了高层次语义抽象，但是它缺乏对数据准确性的保证。Lambda架构能够达到上述的大部分要求，但是系统体系太过复杂，必须构建和维护两套系统（译者注：指离线和在线系统）。Summingbird改善了Lambda体系的复杂性，提供了针对批处理和流处理系统的一个统一封装抽象，但是这种抽象限制了能支持的计算的种类，并且仍然需要维护两套系统，运维复杂性仍然存在。&lt;&#x2F;p&gt;
&lt;p&gt;上述的问题并非无药可救，这些系统在活跃的发展中终究会解决这些问题。但是我们认为所有这些模型和系统（除了CEDR和Trill）存在一个比较大的问题。这个问题是他们假设输入数据（不管是无边界或者有边界的）在某个时间点后会变完整。我们认为这种假设是有根本性的问题。我们面临的一方面是庞大无序的数据，另一方面是数据消费者复杂的语义和时间线上的各种需求。对于当下如此多样化和多变的数据使用用例（更别说那些浮现在地平线上的 译者注：应该是指新的，AI时代的到来带来的对数据使用的新玩法），我们认为任何一种有广泛实用价值的方法必须提供简单，强有力的工具，可以为手上某个具体的使用案例平衡数据的准确性、延迟程度和处理成本（译者注：意指对某些用例可能需要低延迟更多，某些用例需要准确性更多。而一个好的工具需要能够动态根据用户的使用场景、配置进行适应，具体的技术细节由工具本身消化）。最后，我们认为需要摆脱目前一个主流的观点，认为执行引擎负责描述系统的语义。合理设计和构建的批，微批次，流处理系统能够保证同样程度的准确性。而这三种系统在处理无边界数据流时都非常常见。如果我们抽象出一个具有足够普遍性，灵活性的模型，那么执行引擎的选择就只是延迟程度和处理成本之间的选择。&lt;&#x2F;p&gt;
&lt;p&gt;从这个方面来说，这篇论文的概念性贡献在于提出了一个统一的模型能够：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;对无边界，无序的数据源，允许按数据本身的特征进行窗口计算，得到基于事件发生时间的有序结果，并能在准确性、延迟程度和处理成本之间调整。&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;解构数据处理管道的四个相关维度，使得它们透明地，灵活地进行组合。&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;计算什么结果&lt;&#x2F;li&gt;
&lt;li&gt;按事件发生时间计算&lt;&#x2F;li&gt;
&lt;li&gt;在流计算处理时间时被真正触发计算&lt;&#x2F;li&gt;
&lt;li&gt;早期的计算结果如何在后期被修正&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;分离数据处理的计算逻辑表示和对逻辑的物理实现，使得对批处理，微批处理，流计算引擎的选择成为简单的对准确性、延迟程度和处理成本之间的选择。&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;具体来说，上述的贡献包含：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;一个支持非对齐事件发生时间窗口的模型，一组简单的窗口创建和使用的API。（参考2.2）&lt;&#x2F;li&gt;
&lt;li&gt;一个根据数据处理管道特征来决定计算结果输出次数的触发模型。一组强有力而灵活的描述触发语义的声明式API。&lt;&#x2F;li&gt;
&lt;li&gt;能把数据的更新和撤回和上述窗口、触发模型集成的增量处理模型。（2.3）&lt;&#x2F;li&gt;
&lt;li&gt;基于MillWheel流处理引擎和FlumeJava批处理引擎的可扩展实现。为Google Cloud Dataflow重写了外部实现，并提供了一个开源的运行引擎不特定的SDK。（3.1）&lt;&#x2F;li&gt;
&lt;li&gt;指导模型设计的一组核心设计原则。&lt;&#x2F;li&gt;
&lt;li&gt;Google在处理大规模无边界乱序数据流的处理经验，这也是驱动我们开发这套模型的原因。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;最后，不足为奇地，这个模型没有任何魔术效果。那些现有的强一致性批处理系统，微批处理系统，流处理系统，Lambda系统所无法计算的东西仍然无法解决。CPU,RAM Disk的内在约束依然存在。我们所提供的是一个能够简单地定义表达并行计算的通用框架。这种表达的方式和底层的执行引擎无关，同时针对任何特定的问题域，提供了根据手上数据和资源的情况来精确地调整延时程度和准确性的能力。从这一点上来说，这个模型的目标是简化大规模数据处理管道的构建。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;1-1-wu-bian-jie-you-bian-jie-yu-liu-chu-li-pi-chu-li&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#1-1-wu-bian-jie-you-bian-jie-yu-liu-chu-li-pi-chu-li&quot; aria-label=&quot;Anchor link for: 1-1-wu-bian-jie-you-bian-jie-yu-liu-chu-li-pi-chu-li&quot;&gt;1.1 无边界、有边界与流处理、批处理&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;（本论文中）当描述无限&#x2F;有限数据集时，我们更愿意使用有边界&#x2F;无边界这组词汇，而不是流&#x2F;批。因为流&#x2F;批可能意味着使用某种特定的执行引擎。在现实中，无边界数据集可以用批处理系统反复调度来处理，而良好设计的流处理系统也可以完美地处理有边界数据集。从这个模型的角度来看，区分流&#x2F;批的意义是不大的，因此我们保留这组词汇（流、批）用来专指执行引擎。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;1-2-chuang-kou&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#1-2-chuang-kou&quot; aria-label=&quot;Anchor link for: 1-2-chuang-kou&quot;&gt;1.2 窗口&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;窗口操作把一个数据集切分为有限的数据片以便于聚合处理。当面对无边界的数据时，有些操作需要窗口（以定义大多数聚合操作需要的边界：汇总，外链接，以时间区域定义的操作；如最近5分钟xx等）。另一些则不需要（如过滤，映射，内链接等）。对有边界的数据，窗口是可选的，不过很多情况下仍然是一种有效的语义概念（如回填一大批的更新数据到之前读取无边界数据源处理过的数据 译者注：类似于Lambda架构）。窗口基本上都是基于时间的；不过也有些系统支持基于记录数的窗口。这种窗口可以认为是基于一个逻辑上的时间域，该时间域中的元素包含顺序递增的逻辑时间戳。窗口可以是对齐的，也就是说窗口应用于所有落在窗口时间范围内的数据。也可以是非对齐的，也就是应用于部分特定的数据子集（如按某个键值筛选的数据子集）。图一列出了处理无边界数据时常见的三种窗口。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;v2-a55432fc17fe70f896047a2484a88a26_720w.jpg&quot; alt=&quot;img&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;固定&lt;&#x2F;strong&gt;窗口（有时叫翻滚窗口）是按固定窗口大小定义的，比如说小时窗口或天窗口。它们一般是对齐窗口，也就是说，每个窗口都包含了对应时间段范围内的所有数据。有时为了把窗口计算的负荷均匀分摊到整个时间范围内，有时固定窗口会做成把窗口的边界的时间加上一个随机数，这样的固定窗口则变成了不对齐窗口。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;滑动&lt;&#x2F;strong&gt;窗口按窗口大小和滑动周期大小来定义，比如说小时窗口，每一分钟滑动一次。这个滑动周期一般比窗口大小小，也就是说窗口有相互重合之处。滑动窗口一般也是对齐的；尽管上面的图为了画出滑动的效果窗口没有遮盖到所有的键，但其实五个滑动窗口其实是包含了所有的3个键，而不仅仅是窗口3包含了所有的3个键。固定窗口可以看做是滑动窗口的一个特例，即窗口大小和滑动周期大小相等。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;会话&lt;&#x2F;strong&gt;是在数据的子集上捕捉一段时间内的活动。一般来说会话按超时时间来定义，任何发生在超时时间以内的事件认为属于同一个会话。会话是非对齐窗口。如上图，窗口2只包含key 1，窗口3则只包含key2。而窗口1 和 4 都包含了key 3。（译者注：假设key 是用户id， 那么两次活动之间间隔超过了超时时间，因此系统需要重新定义一个会话窗口。）&lt;&#x2F;p&gt;
&lt;h2 id=&quot;1-3-shi-jian-yu&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#1-3-shi-jian-yu&quot; aria-label=&quot;Anchor link for: 1-3-shi-jian-yu&quot;&gt;1.3 时间域&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;当处理包含事件发生时间的数据时，有两个时间域需要考虑。尽管已经有很多文献提到（特别是时间管理【28】，语义模型【9】，窗口【22】，乱序处理【23】，标记【30】，心跳【21】，水位线【2】，帧【31】），这里仍然重复一下，因为这个概念清晰之后2.3节会更易于理解。这两个时间域是：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;事件时间&lt;&#x2F;strong&gt;，即当该事件发生时，该事件所在的系统记录下来的系统时间。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;处理时间&lt;&#x2F;strong&gt;，即在数据处理管道中处理数据时，一个事件被数据处理系统观察到的时间，是数据处理系统的时间。注意我们这里不假设在分布式系统中时钟是同步的。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;一个事件的事件发生时间是永远不变的，但是一个事件的处理时间随着它在数据管道中一步步被处理时持续变化的。这个区别是非常重要的，特别是我们需要根据事件的发生时间进行分析的时候。&lt;&#x2F;p&gt;
&lt;p&gt;在数据处理过程中，由于系统本身的一些现实影响（通信延迟，调度算法，处理时长，管道中间数据序列化等）会导致这两个时间存在差值且动态波动（见图2）。使用记录全局数据处理进度的标记、或水位线，是一种很好的方式来可视化这个差值。在本论文中，我们采用一种类似MillWheel的水位线，它是一个时间戳，代表小于这个时间戳的数据已经完全被系统处理了（通常用启发式方法建立）。&lt;&#x2F;p&gt;
&lt;p&gt;对大多数现实世界中分布式数据集，系统缺乏足够的信息来建立一个100%准确的水位线。举例来说，在视频观看“会话”的例子中，考虑离线观看。如果有人把他们的移动设备带到野外，系统根本没有办法知道他们何时会回到有网络连接的地带，然后开始上传他们在没有网络连接时观看视频的数据。因此，大多数的水位定义是基于有限的信息启发式地定义。对于带有未处理数据的元数据的结构化输入源，比如说日志文件（译者注：可能应该不是泛指一般的日志文件），水位线的猜测明显要准确些，因此大多数情况下可以作为一个处理完成的估计。另外，很重要的一点，一旦水位线建立之后，它可以被传递到数据处理管道的下游（就像标记（Punctuation）那样 译者注：类似于Flink的checkpoint barrier）。当然下游要明确知道这个水位线仍然是一个猜测。&lt;&#x2F;p&gt;
&lt;p&gt;我们之前曾经说过，数据已经被完全处理的标记经常和数据的准确性是相互冲突的，因此，我们不会太过于依赖于水位线。不过，它确实是一种有用的手段。系统可以用它猜测所有事件发生时间早于水位线的数据已经完全被观察到。应用可以用它来可视化处理时间差，也用它来监控系统总体的健康状况和总体处理进展，也可以用它里做一些不影响数据准确性的决策，比如基本垃圾回收策略等。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;v2-712226a05c501613551b829f89d8912d_720w.jpg&quot; alt=&quot;img&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;在理想的情况下，两个时间的差值应该永远为零；事件一旦发生，我们就马上处理掉。现实则更像图2那样。从12点开始，由于数据处理管道的延迟，水位线开始偏离真实时间，12:02时则靠近回来，而12:03的时候延迟变得更大。在分布式数据处理系统里，这种偏差波动非常普遍，在考虑数据处理系统如何提供一个正确的，可重复的结果时，把这种情况纳入考虑很关键。&lt;&#x2F;p&gt;
&lt;h1 id=&quot;2-dataflow-mo-xing&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#2-dataflow-mo-xing&quot; aria-label=&quot;Anchor link for: 2-dataflow-mo-xing&quot;&gt;2. Dataflow 模型&lt;&#x2F;a&gt;&lt;&#x2F;h1&gt;
&lt;p&gt;在这一个小节中，我们将定义正式的系统模型。我们还会解释为什么它的语义足够泛化，能涵盖标准的批处理，微批次处理，流处理，以及混合了流批语义的Lambda架构。代码示例是基于Dataflow的Java SDK的一个简化版本，是从FlumeJava API演化而来。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;2-1-he-xin-bian-cheng-mo-xing&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#2-1-he-xin-bian-cheng-mo-xing&quot; aria-label=&quot;Anchor link for: 2-1-he-xin-bian-cheng-mo-xing&quot;&gt;2.1 核心编程模型&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;我们先从经典的批处理模型开始来考虑我们的核心编程模型。Dataflow SDK把所有的数据抽象为键值对，对键值对有两个核心的数据转换操作：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ParDo&lt;&#x2F;strong&gt; 用来进行通用的并行化处理。每个输入元素（这个元素本身有可能是一个有限的集合）都会使用一个UDF进行处理（在Dataflow中叫做DoFn），输出是0或多个输出元素。这个例子是把键的前缀进行展开，然后把值复制到展开后的键构成新的键值对并输出。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;v2-fdb05d7170252b4732f7075f04fb6479_720w.jpg&quot; alt=&quot;img&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;GroupByKey&lt;&#x2F;strong&gt; 用来按键值把元素重新分组&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;v2-a13eb70a554501ba3a653ca65ee6e1d2_720w.jpg&quot; alt=&quot;img&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;ParDo 操作因为是对每个输入的元素进行处理，因此很自然地就可以适用于无边界的数据。而 GroupByKey 操作，在把数据发送到下游进行汇总前，需要收集到指定的键对应的所有数据。如果输入源是无边界的，那么我们不知道何时才能收集到所有的数据。所以通常的解决方案是对数据使用窗口操作。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;2-2-chuang-kou&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#2-2-chuang-kou&quot; aria-label=&quot;Anchor link for: 2-2-chuang-kou&quot;&gt;2.2 窗口&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;支持聚合操作的系统经常把GroupByKey操作重新定义成为GroupByKeyAndWindow 操作。我们在这一点上的主要贡献是支持非对齐窗口。这个贡献包含两个关键性的洞见：第一是从模型简化的角度上，把所有的窗口策略都当做非对齐窗口，而底层实现来负责把对齐窗口作为一个特例进行优化。 第二点是窗口操作可以被分隔为两个互相相关的操作：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;set&lt;Window&gt; &lt;strong&gt;AssignWindows&lt;&#x2F;strong&gt;(T datum) 即窗口分配操作。这个操作把元素分配到0或多个窗口中去。这个也就是Li在[22]中提到的桶操作符。&lt;&#x2F;li&gt;
&lt;li&gt;set&lt;window&gt; &lt;strong&gt;MergeWindows&lt;&#x2F;strong&gt;(Set&lt;Window&gt; windows) 即窗口合并操作，这个操作在汇总时合并窗口。这使得数据驱动的窗口在随着数据到达的过程中逐渐建立起来并进行汇总操作。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;对于任何一种窗口策略，这两种操作都是密切相关的。滑动窗口分配需要滑动窗口合并，而会话窗口分配需要会话窗口合并。&lt;&#x2F;p&gt;
&lt;p&gt;注意，为了原生地支持事件发生时间窗口，我们现在定义系统中传递的数据不再仅仅是键值对 (key, value)， 而是一个四元组 (key, value, event_time, window)。数据进入系统时需要自带事件发生时间戳（后期在管道处理过程中也可以修改），然后初始化分配一个默认的覆盖所有事件发生时间的全局窗口。而全局窗口语义默认等同于标准的批处理模型。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;2-2-1-chuang-kou-fen-pei&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#2-2-1-chuang-kou-fen-pei&quot; aria-label=&quot;Anchor link for: 2-2-1-chuang-kou-fen-pei&quot;&gt;2.2.1 窗口分配&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;从模型角度来说，把一条数据分配给某几个窗口意味着把这条数据复制给了这些窗口。以图3为例，它是把两条记录分配给一个2分钟宽，每一分钟滑动一次的窗口。（简单起见，时间戳用HH:MM的格式给出）&lt;&#x2F;p&gt;
&lt;p&gt;在这个例子中，两条数据在两个窗口中冗余存在，因而最后变成了四条记录。另外注意一点，窗口是直接关联到数据元素本身的，因此，窗口的分配可以在处理管道的聚合发生前的任何一处进行。这一点很重要，因为聚合操作有可能是下游复杂组合数据转换的一个子操作。（如Sum.integersPerKey 译者注：下文会提到，这个转换是指键值对中的值为整形，把整形值按键进行求和）&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;v2-aecdc6366f06894c580da4cab2afeff1_720w.jpg&quot; alt=&quot;img&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h3 id=&quot;2-2-2-chuang-kou-he-bing&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#2-2-2-chuang-kou-he-bing&quot; aria-label=&quot;Anchor link for: 2-2-2-chuang-kou-he-bing&quot;&gt;2.2.2 窗口合并&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;窗口合并作为GroupByKeyAndWindow的一部分出现，要解释清楚的话，我们最好拿例子来阐述。我们拿会话窗口来作为例子，因为会话窗口正是我们想要解决的用例之一。图4展示了例子数据4条，3条包含的键是k1，一条是k2，窗口按会话窗口组织，会话的过期时间是30分钟。所有4条记录初始时都属于缺省的全局窗口。AssignWindows的会话窗口实现把每个元素都放入一个30分钟长的单个窗口，这个窗口的时间段如果和另外一个窗口的时间段相互重合，则意味着这两个窗口应该属于同一个会话。AssignWindows后是GroupByKeyAndWindow的操作，这个操作其实由五个部分组成：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;DropTimestamps&lt;&#x2F;strong&gt; – 删除数据上的时间戳，因为窗口合并后，后续的计算只关心窗口。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;GroupByKey&lt;&#x2F;strong&gt; – 把（值，窗口）二元组按键进行分组&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;MergeWindows&lt;&#x2F;strong&gt; – 窗口合并。把同一个键的（值，窗口）进行窗口合并。具体的合并方式取决于窗口策略。在这个例子中，窗口v1和v4重叠，因此会话窗口策略把这两个窗口合并为一个新的，更长的会话窗口。（如粗体所示）&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;GroupAlsoByWindow&lt;&#x2F;strong&gt; – 对每个键，把值按合并后的窗口进行进一步分组。在本例中，由于v1和v4已经合并进了同一个窗口，因此这一步里面v1和v4被分到了同一组。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;ExpandToElements&lt;&#x2F;strong&gt; – 把已经按键，按窗口分好组的元素扩展成(键，值，事件发生时间，窗口)四元组。这里的时间戳是新的按窗口的时间戳。在这个例子里我们取窗口的结束时间作为这条记录的时间戳，但任何大于或等于窗口中最老的那条记录的时间戳都认为是符合水位线正确性的。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;v2-bc7600fc44456e50844e7c05d6a92ac8_720w.jpg&quot; alt=&quot;img&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h3 id=&quot;2-2-3-api&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#2-2-3-api&quot; aria-label=&quot;Anchor link for: 2-2-3-api&quot;&gt;2.2.3 API&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;下面我们使用Cloud Dataflow SDK来展示使用窗口操作的例子，现对同一个键的整型数值求和。&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;PCollection&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;KV&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;String&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Integer&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;gt; input &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;IO&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;read&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;...&lt;&#x2F;span&gt;&lt;span&gt;);
&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;PCollection&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;KV&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;String&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Integer&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;gt; output &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; input&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Sum&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;integersPerKey&lt;&#x2F;span&gt;&lt;span&gt;());
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;假如说要对30分钟长的会话窗口进行同样的计算，那么只要在求和前增加一个 &lt;code&gt;window.into&lt;&#x2F;code&gt; 调用就可以了：&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;PCollection&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;KV&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;String&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Integer&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;gt; input &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;IO&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;read&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;...&lt;&#x2F;span&gt;&lt;span&gt;);
&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;PCollection&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;KV&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;String&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Integer&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;gt; output &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; input
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Window&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;into&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Sessions&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;withGapDuration&lt;&#x2F;span&gt;&lt;span&gt;( &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Duration&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;standardMinutes&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;30&lt;&#x2F;span&gt;&lt;span&gt;))))
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Sum&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;integersPerKey&lt;&#x2F;span&gt;&lt;span&gt;());
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;2-3-hong-fa-qi-he-zeng-liang-chu-li&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#2-3-hong-fa-qi-he-zeng-liang-chu-li&quot; aria-label=&quot;Anchor link for: 2-3-hong-fa-qi-he-zeng-liang-chu-li&quot;&gt;2.3 触发器和增量处理&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;构建非对齐的事件发生时间窗口是一个进步，不过我们还有两个问题需要解决。&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;我们需要提供基于记录和基于处理时间的窗口。否则我们会和现有的其他系统的窗口语义不兼容&lt;&#x2F;li&gt;
&lt;li&gt;我们需要知道何时把窗口计算结果发往下游。由于数据事件发生时间的无序性，我们需要某种其他的信号机制来明确窗口已经完结（译者注：就是说，窗口所应该包含的数据已经完全到达并且被窗口观察到，包含到）。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;关于第一点，基于记录数和基于处理时间的窗口，我们会在2.4里解决。 而眼下需要讨论建立一个保证窗口完整性的方法。提到窗口完整性，一个最开始的想法是使用某种全局事件发生时间进展机制，比如水位线来解决。然而，水位线本身对数据处理的准确性有两个主要的影响&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;水位线可能设置的&lt;strong&gt;过短&lt;&#x2F;strong&gt;，因此在水位线达到后仍然有记录到达。对于分布式的数据源头来说，很难去推断出一个完全完美的事件发生时间水位线，因此无法完全依赖于水位线，否则我们无法达到１００％的准确性。&lt;&#x2F;li&gt;
&lt;li&gt;水位线可能设置的&lt;strong&gt;过长&lt;&#x2F;strong&gt;。因为水位线是全局性的进度指标，只要一个迟到的数据项就能影响到整个数据处理管道的水位线。就算是一个正常工作的数据处理管道，它的处理延迟波动很小，受输入源的影响，这种延迟的基准仍然可能有几分钟甚至更高。因此，使用水位线作为窗口完整信号并触发窗口计算结果很可能导致整个处理结果比Lambda架构有更高的延迟。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;由于上述的原因，我们认为光使用水位线是不够的。从 Lambda 架构中我们获得了规避完整性问题的启发：它不是尽快地提供完全准确的答案，而是说，它先是尽快通过流式处理管道提供一个最佳的低延迟估计，同时承诺最终会通过批处理管道提供正确的和一致的答案（当然前提条件是批处理作业启动时，需要的数据应该已经全部到达了；如果数据后期发生了变化，那么批处理要重新执行以获得准确答案）。如果我们要在一个单一的数据处理管道里做到同样的事情（不管采用哪种执行引擎），那么我们需要一种对任一窗口能够提供多种答案（或者可以叫做窗格 译者注：对窗口这个比喻的引申）的方式。我们把这种功能叫做“触发器”。这种“触发器”可以选择在何时触发指定窗口的输出结果。&lt;&#x2F;p&gt;
&lt;p&gt;简单来说，触发器是一种受内部或者外信号激励的激发 GroupByKeyAndWindow 执行并输出执行结果的机制。他们对窗口模型是互补的，各自从不同的时间维度上影响系统的行为：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;窗口&lt;&#x2F;strong&gt; 决定哪些事件发生时间段（where）的数据被分组到一起来进行聚合操作&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;触发&lt;&#x2F;strong&gt; 决定在什么处理时间（when）窗口的聚合结果被处理输出成一个窗格&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;我们的系统提供了基于窗口的完成度估计的预定义触发器。（完成度估计基于水位线。完成度估计也包括水位线完成百分位。它提供了一种有效的处理迟到记录的语义，而且在批处理和流处理引擎中都适用。允许使用者处理少量的一部分的记录来快速获得结果，而不是痴痴地等待最后的一点点数据到来）。触发器也有基于处理时间的，基于数据抵达状况的（如记录数，字节数，数据到达标记（punctuations），模式匹配等）。我们也支持对基础触发器进行逻辑组合（与，或），循环，序列和其他一些复合构造方法。另外，用户可以基于执行引擎的元素（如水位计时器，处理时间计时器，数据到达，复合构造）和任意的外部相关信号（如数据注入请求，外部数据进展指标，RPC完成回调等）自定义触发器。在2.4里我们会更详细地看一些具体的例子。&lt;&#x2F;p&gt;
&lt;p&gt;除了控制窗口结果计算何时触发，触发器还提供了三种不同的模式来控制不同的窗格（计算结果）之间是如何相互关联的。&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;抛弃&lt;&#x2F;strong&gt; 窗口触发后，窗口内容被抛弃，而之后窗口计算的结果和之前的结果不存在相关性。当下游的数据消费者（不管是数据处理管道的内部还是外部）希望触发计算结果之间相互独立（比如对插入的数据进行求和的场景），那么这种情况就比较适用。另外，抛弃因为不需要缓存历史数据，因此对比其他两种模式，抛弃模式在状态缓存上是最高效的。不过累积性的操作可以建模成Dataflow的 Combiner，对窗口状态管理可以用增量的方式处理。对我们视频观看会话的用例来说，抛弃模式是不够的，因为要求下游消费者只关心会话的部分数据是不合理的。&lt;&#x2F;li&gt;
&lt;li&gt;**累积：**触发后，窗口内容被完整保留住持久化的状态中，而后期的计算结果成为对上一次结果的一个修正的版本。这种情况下，当下游的消费者收到同一个窗口的多次计算结果时，会用新的计算结果覆盖掉老的计算结果。这也是Lambda架构使用的方式，流处理管道产出低延迟的结果，之后被批处理管道的结果覆盖掉。对视频会话的用例来说，如果我们把会话窗口的内容进行计算然后把结果直接写入到支持更新的输出源（如数据库或者键值存储），这种方案是足够的了。&lt;&#x2F;li&gt;
&lt;li&gt;**累积和撤回：**出发后，在进行累积语义的基础上，计算结果的一份复制也被保留到持久化状态中。当窗口将来再次触发时，上一次的结果值先下发做撤回处理，然后新的结果作为正常数据下发。如果数据处理管道有多个串行的GroupByKeyAndWindow操作时，撤回是必要的，因为同一个窗口的不同触发计算结果可能在下游会被分组到不同键中去。在这种情况下，除非我们通过一个撤回操作，撤回上一次聚合操作的结果，否则下游的第二次聚合操作会产生错误的结果。Dataflow的combiner操作是支持撤回的，只要调用uncombine方法就可以进行撤回。而对于视频会话用例来说，这种模型是非常理想的。比如说，如果我们在下游从会话创建一开始，我们就基于会话的某些属性进行汇总统计，例如检查不受欢迎的广告（比如说在很多会话中这个广告的被观察时长不长于5秒）。早期的计算结果随着输入的增加（比如说原来在野外观看视频的用户已经回来了并上传了他们的日志）可能变得无效。对于包含多个阶段的聚合操作的复杂数据处理管道，撤回方式帮助我们应对源头数据的变化，得到正确的数据处理结果。（简单的撤回实现只能支持确定性的计算，而非确定性计算的支持需要更复杂，代价也更高。我们已经看到这样的使用场景，比如说概率模型 译者注：比如说基于布隆过滤器的UV统计）&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;2-4-li-zi&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#2-4-li-zi&quot; aria-label=&quot;Anchor link for: 2-4-li-zi&quot;&gt;2.4 例子&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;我们现在来考察一系列的例子来说明Dataflow模型支持的计算模式是非常普遍适用的。我们下面例子是关于2.2.3中提到的对整数求和的例子：&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;PCollection&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;KV&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;String&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Integer&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;gt; output &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; input
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Sum&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;integersPerKey&lt;&#x2F;span&gt;&lt;span&gt;());
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;我们假设从某个数据源我们观察到了10个数据点，每个数据点都是一个比较小的整数。我们会考虑有边界输入源和无边界输入源两种情况。为了画图简单，我们假设这些数据点的键是一样的，而生产环境里我们这里所描述的数据处理是多个键并行处理的。图5展示了数据在我们关心的两个时间轴上的分布。X轴是事件发生时间（也就是事件发生的时间），而Y轴是处理时间（即数据管道观测到数据的时间）。（译者注：圆圈里的数值是从源头采样到的数值）除非是另有说明，所有例子假设数据的处理执行都是在流处理引擎上。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;v2-62b57ed826090a2426f5f4fd69f8961f_720w.jpg&quot; alt=&quot;img&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;很多例子都要考虑水位线，因此我们的图当中也包括了理想的水位线，也包括了实际的水位线。直的虚线代表了理想的水位线，即，事件发生时间和数据处理时间不存在任何延迟，所有的数据一产生就马上消费了。不过考虑到分布式系统的不确定性，这两个时间之间有偏差是非常普遍的。在图5中，实际的水位线（黑色弯曲虚线）很好的说明了这一点。另外注意由于实际的水位线是猜测获得的，因此有一个迟到比较明显的数据点落在了水位线的后面。&lt;&#x2F;p&gt;
&lt;p&gt;如果我们在传统的批处理系统中构建上述的对数据进行求和的数据处理管道，那么我们会等待所有的数据到达，然后聚合成一个批次（因为我们现在假设所有的数据拥有同样的键），再进行求和，得到了结果51。如图6所示黑色的长方形是这个运算的示意图。长方形的区域代表求和运算涵盖的处理时间和参与运算的数据的事件发生时间区间。长方形的上沿代表计算发生，获得结果的管道处理时间点。因为传统的批处理系统不关心数据的事件发生时间，所有的数据被涵盖在一个大的全局性窗口中，因此包含了所有事件发生时间内的数据。而且因为管道的输出在收到所有数据后只计算一次，因此这个输出包含了所有处理时间的数据（译者注：处理时间是数据系统观察到数据的时间，而不是运算发生时的时间。。）&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;v2-969ece4764996258ceef28bbbc9d67d9_720w.jpg&quot; alt=&quot;img&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;注意上图中包含了水位线。尽管在传统批处理系统中不存在水位线的概念，但是在语义上我们仍然可以引入它。批处理的水位线刚开始时一直停留不动。直到系统收到了所有数据并开始处理，水位线近似平行于事件发生时间轴开始平移，然后一直延伸到无穷远处。我们之所以讨论这一点，是因为如果让流处理引擎在收到所有数据之后启动来处理数据，那么水位线进展和传统批处理系统是一模一样的。（译者注：这提示我们其实水位线的概念可以同样适用于批处理）&lt;&#x2F;p&gt;
&lt;p&gt;现在假设我们要把上述的数据处理管道改造成能够接入无边界数据源的管道。在Dataflow模型中，默认的窗口触发方式是当水位线移过窗口时吐出窗口的执行结果。但如果对一个无边界数据源我们使用了全局性窗口，那么窗口就永远不会触发（译者注：因为窗口的大小在不停地扩大）。因此，我们要么用其他的触发器触发计算（而不是默认触发器），或者按某种别的方式开窗，而不是一个唯一的全局性窗口。否则，我们永远不会获得计算结果输出。&lt;&#x2F;p&gt;
&lt;p&gt;我们先来尝试改变窗口触发方式，因为这会帮助我们产生概念上一致的输出（一个全局的包含所有时间的按键进行求和），周期性地输出更新的结果。在这个例子中，我们使用了Window.trigger操作，按处理时间每分钟周期性重复触发窗口的计算。我们使用累积的方式对窗口结果进行修正（假设结果输出到一个数据库或者KV数据库，因而新的结果会持续地覆盖之前的计算结果）。这样，如图7所示，我们每分钟（处理时间）产生更新的全局求和结果。注意图中半透明的输出长方形是相互重叠的，这是因为累积窗格处理机制计算时包含了之前的窗口内容：&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;PCollection&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;KV&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;String&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Integer&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;gt; output &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; input 
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Window&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;trigger&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Repeat&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;AtPeriod&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;MINUTE&lt;&#x2F;span&gt;&lt;span&gt;)))
&lt;&#x2F;span&gt;&lt;span&gt;               &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;accumulating&lt;&#x2F;span&gt;&lt;span&gt;()) 
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Sum&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;integersPerKey&lt;&#x2F;span&gt;&lt;span&gt;());
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;v2-1f07ed02bea7a45db0dd3ab94f4b93f8_720w.jpg&quot; alt=&quot;img&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;如果我们想要求出每分钟的和的增量，那么我们可以使用窗格的抛弃模式，如图8所示。注意这是很多流处理引擎的处理时间窗口的窗口计算模式。窗格不再相互重合，因此窗口的结果包含了相互独立的时间区域内的数据：&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;PCollection&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;KV&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;String&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Integer&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;gt; output &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; input
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Window&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;trigger&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Repeat&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;AtPeriod&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;MINUTE&lt;&#x2F;span&gt;&lt;span&gt;)))
&lt;&#x2F;span&gt;&lt;span&gt;               &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;discarding&lt;&#x2F;span&gt;&lt;span&gt;()) 
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Sum&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;integersPerKey&lt;&#x2F;span&gt;&lt;span&gt;());
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;v2-65f8ac21791f60795f35b3220e214c16_720w.jpg&quot; alt=&quot;img&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;另外一种更健壮的处理时间窗口的实现方式，是把数据摄入时的数据到达时间作为数据的事件发生时间，然后使用事件发生时间窗口。这样的另一个效果是系统对流入系统的数据的事件发生时间非常清楚，因而能够生成完美的水位线，不会存在迟到的数据。如果数据处理场景中不关心真正的事件发生时间，或者无法获得真正的事件发生时间，那么采用这种方式生成事件发生时间是一种非常低成本且有效的方式。&lt;&#x2F;p&gt;
&lt;p&gt;在我们讨论其他类型的窗口前，我们先来考虑下另外一种触发器。一种常见的窗口模式是基于记录数的窗口。我们可以通过改变触发器为每多少条记录到达触发一次的方式来实现基于记录数的窗口。图9是一个以两条记录为窗口大小的例子。输出是窗口内相邻的两条记录之和。更复杂的记录数窗口（比如说滑动记录数窗口）可以通过定制化的窗口触发器来支持：&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;PCollection&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;KV&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;String&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Integer&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;gt; output &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; input 
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Window&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;trigger&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Repeat&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;AtCount&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt;)))
&lt;&#x2F;span&gt;&lt;span&gt;               &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;discarding&lt;&#x2F;span&gt;&lt;span&gt;())
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Sum&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;integersPerKey&lt;&#x2F;span&gt;&lt;span&gt;());
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;v2-a12c1960a227f8b7866a9224b717b776_720w.jpg&quot; alt=&quot;img&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;我们接下来考虑支持无边界数据源的其他选项，不再仅仅考虑全局窗口。一开始，我们来观察固定的2分钟窗口，累积窗格：&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;PCollection&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;KV&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;String&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Integer&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;gt; output &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; input
&lt;&#x2F;span&gt;&lt;span&gt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Window&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;into&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;FixedWindows&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;of&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;MINUTES&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;span&gt;               &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;accumulating&lt;&#x2F;span&gt;&lt;span&gt;())
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Sum&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;integersPerKey&lt;&#x2F;span&gt;&lt;span&gt;())&lt;&#x2F;span&gt;&lt;span style=&quot;background-color:#ff79c6;color:#f8f8f0;&quot;&gt;;&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;这里没有定义触发器，那么系统采用的是默认触发器。相当于：&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;PCollection&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;KV&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;String&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Integer&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;gt; output &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; input
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Window&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;into&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;FixedWindows&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;of&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;MINUTES&lt;&#x2F;span&gt;&lt;span&gt;))
&lt;&#x2F;span&gt;&lt;span&gt;               &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;trigger&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Repeat&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;AtWatermark&lt;&#x2F;span&gt;&lt;span&gt;())))
&lt;&#x2F;span&gt;&lt;span&gt;               &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;accumulating&lt;&#x2F;span&gt;&lt;span&gt;())
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Sum&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;integersPerKey&lt;&#x2F;span&gt;&lt;span&gt;());
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;水位线触发器是指当水位线越过窗口底线时窗口被触发。我们这里假设批处理和流处理系统都实现了水位线（详见3.1）。Repeat代表的含义是如何处理迟到的数据。在这里Repeat意味着当有迟于水位线的记录到达时，窗口都会立即触发再次进行计算，因为按定义，此时水位线早已经越过窗口底线了。&lt;&#x2F;p&gt;
&lt;p&gt;图10-12描述了上述窗口在三种不同的数据处理引擎上运行的情况。首先我们来观察下批处理引擎上这个数据处理管道如何执行的。受限于我们当前的实现，我们认为数据源现在是有边界的数据源，而传统的批处理引擎会等待所有的数据到来。之后，我们会根据数据的事件发生时间处理，在模拟的水位线到达后窗口计算触发吐出计算结果。整个过程如图10所示：&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;v2-cc6e4839c5e47975367431e39a4777ac_720w.jpg&quot; alt=&quot;img&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;然后来考虑一下微批次引擎，每分钟做一次批次处理。系统会每分钟收集输入的数据进行处理，反复重复进行。每个批次开始后，水位线会从批次的开始时间迅速上升到批次的结束时间（技术上来看基本上是即刻完成的，取决于一分钟内积压的数据量和数据处理管道的吞吐能力）。这样每轮微批次完成后系统会达到一个新的水位线，窗口的内容每次都可能会不同（因为有迟到的数据加入进来），输出结果也会被更新。这种方案很好的兼顾了低延迟和结果的最终准确性。如图11所示：&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;v2-62770bbedd7c6b1871e40d6f1b68a789_720w.jpg&quot; alt=&quot;img&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;接下来考虑数据管道在流处理引擎上的执行情况，如图12所示。大多数窗口在水位线越过它们之后触发执行。注意值为9的那个数据点在水位线之后到达。不管什么原因（移动设备离线，网络故障分区等），系统并没有意识到那一条数据并没有到达，仍然提升了水位线并触发了窗口计算。当值为9的那条记录到达后，窗口会重新触发，计算出一个新的结果值。&lt;&#x2F;p&gt;
&lt;p&gt;如果说我们一个窗口只有一个输出，而且针对迟到的数据仅做一次的修正，那么这个计算方式还是不错的。不过因为窗口要等待水位线进展，整体上的延迟比起微批次系统可能要更糟糕，这就是我们之前在2.3里所说的，单纯依赖水位线可能引起的问题（水位线可能太慢）&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;v2-afb4589c5c3f14e5f12cec3d23b93c73_720w.jpg&quot; alt=&quot;img&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;如果我们想降低整体的延迟，那么我们可以提供按数据处理时间的触发器进行周期性的触发，这样我们能够尽早得到窗口的计算结果，并且在随后得到周期性的更新，直到水位线越过窗口边界。参见图13。这样我们能够得到比微批次系统更低的延迟，因为数据一到达就进入了窗口随后就可能被触发，而不像在微批次系统里必须等待一个批次数据完全到达。假设微批次系统和流处理系统都是强一致的，那么我们选择哪种引擎，就是在能接受的延迟程度和计算成本之间的选择（对微批次系统也是批大小的选择）。这就是我们这个模型想要达到的目标之一。参见图13：固定窗口，流处理，部分窗格。&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;PCollection&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;KV&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;String&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Integer&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;gt; output &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; input
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Window&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;into&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;FixedWindows&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;of&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;MINUTES&lt;&#x2F;span&gt;&lt;span&gt;))
&lt;&#x2F;span&gt;&lt;span&gt;               &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;trigger&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;SequenceOf&lt;&#x2F;span&gt;&lt;span&gt;(
&lt;&#x2F;span&gt;&lt;span&gt;                   &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;RepeatUntil&lt;&#x2F;span&gt;&lt;span&gt;(
&lt;&#x2F;span&gt;&lt;span&gt;                       &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;AtPeriod&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;MINUTE&lt;&#x2F;span&gt;&lt;span&gt;),
&lt;&#x2F;span&gt;&lt;span&gt;                       &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;AtWatermark&lt;&#x2F;span&gt;&lt;span&gt;()),
&lt;&#x2F;span&gt;&lt;span&gt;                   &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Repeat&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;AtWatermark&lt;&#x2F;span&gt;&lt;span&gt;())))
&lt;&#x2F;span&gt;&lt;span&gt;               &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;accumulating&lt;&#x2F;span&gt;&lt;span&gt;())
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Sum&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;integersPerKey&lt;&#x2F;span&gt;&lt;span&gt;());
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;v2-65de2909b0b6ee930ab3d2ce16dd7400_720w.jpg&quot; alt=&quot;img&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;作为最后一个例子，我们来看一下如何支持之前提到的视频会话需求（为了保持例子之间的一致性，我们继续把求和作为我们的计算内容。改变成其他的聚合函数也是很容易的）。我们把窗口定义为会话窗口，会话超时时间为1分钟，并且支持回撤操作。这个例子也体现了我们把模型的四个维度拆开之后带来的灵活的可组合性（计算什么，在哪段事件发生时间里计算，在哪段处理时间里真正触发计算，计算产生的结果后期如何进行修正）。也演示了对之前的计算结果可以进行撤回是一个非常强力的工具，否则可能会让下游之前接收到的数据无法得到修正。&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;PCollection&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;KV&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;String&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Integer&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;gt; output &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; input      &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Window&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;into&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Sessions&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;withGapDuration&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;MINUTE&lt;&#x2F;span&gt;&lt;span&gt;))
&lt;&#x2F;span&gt;&lt;span&gt;               &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;trigger&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;SequenceOf&lt;&#x2F;span&gt;&lt;span&gt;(
&lt;&#x2F;span&gt;&lt;span&gt;                 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;RepeatUntil&lt;&#x2F;span&gt;&lt;span&gt;(
&lt;&#x2F;span&gt;&lt;span&gt;                   &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;AtPeriod&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;MINUTE&lt;&#x2F;span&gt;&lt;span&gt;),
&lt;&#x2F;span&gt;&lt;span&gt;                   &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;AtWatermark&lt;&#x2F;span&gt;&lt;span&gt;()),
&lt;&#x2F;span&gt;&lt;span&gt;                   &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Repeat&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;AtWatermark&lt;&#x2F;span&gt;&lt;span&gt;())))
&lt;&#x2F;span&gt;&lt;span&gt;                &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;accumulatingAndRetracting&lt;&#x2F;span&gt;&lt;span&gt;()) 
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Sum&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;integersPerKey&lt;&#x2F;span&gt;&lt;span&gt;());
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;v2-ba733141314a46b1bfca5853d73e77d8_720w.jpg&quot; alt=&quot;img&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;在这个例子中，我们首先接收到了数据5 和数据7。由于5和7之间事件发生时间大于1分钟，因此被当做了两个会话。在第一次窗口被触发时，产生了两条计算结果，和分别为5和7。在第二个因处理时间引起的窗口触发时，我们接收到了数据3,4,3，并且第一个3和上一个7之间时间大于1分钟，因此被分组到一个新的会话窗口，窗口触发计算并输出了计算结果10。紧接着，数据8到达了。数据8的到达使得数据7,3,4,3,8合并成了一个大窗口。当水位线越过数据点8后，新窗口计算被触发。触发后需要先撤回之前两个小窗口的计算结果，撤回方式是往下游发送两条键为之前的两个会话标记，值为-7和-10的记录，然后发送一个新的值为25的新窗口计算结果。同样，当值为9的记录迟于水位线到达后，之前的所有7条记录都合并成了一个会话，因此要对之前的会话再次进行撤回。值为-5和-25的记录又被发送往下游，新的值为39的会话记录随后也被发往下游。同样的操作在处理最后3条值为3,8,1的记录时也会发生，先是输出了结果值3，随后回撤了这个计算结果，输出了合并会话后的结果值12。&lt;&#x2F;p&gt;
&lt;h1 id=&quot;3-shi-xian-he-she-ji&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#3-shi-xian-he-she-ji&quot; aria-label=&quot;Anchor link for: 3-shi-xian-he-she-ji&quot;&gt;3. 实现和设计&lt;&#x2F;a&gt;&lt;&#x2F;h1&gt;
&lt;h2 id=&quot;3-1-shi-xian&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#3-1-shi-xian&quot; aria-label=&quot;Anchor link for: 3-1-shi-xian&quot;&gt;3.1 实现&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;我们已经用FlumeJava实现了这个模型，使用MillWheel作为底层的流执行引擎；在本文写作的时候，针对公有云服务Cloud Dataflow的重新实现也接近完成。由于这些系统要么是谷歌的内部系统，要么是共有云服务，因此为简洁起见，实现的细节我们略掉了。可以提及的让人感兴趣的一点是，核心的窗口机制代码，触发机制代码是非常通用的，绝大部分都同时适用于批处理引擎实现和流处理引擎实现。这个实现本身也值得在将来进行更进一步的分析。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;3-2-she-ji-yuan-ze&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#3-2-she-ji-yuan-ze&quot; aria-label=&quot;Anchor link for: 3-2-she-ji-yuan-ze&quot;&gt;3.2 设计原则&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;尽管我们很多的设计其实是受到3.3节所描述的真实业务场景启发，我们在设计中也遵从了一系列的核心原则。这些原则我们认为是这个模型必须要遵循的。&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;永远不要依赖任何的数据完整性标记（译者注：如水位线）&lt;&#x2F;li&gt;
&lt;li&gt;灵活性，要能覆盖已知的多样化的使用用例，并且覆盖将来可能的使用用例&lt;&#x2F;li&gt;
&lt;li&gt;对于每个预期中的执行引擎，（模型抽象）不但要正确合理，而且要有额外的附加价值&lt;&#x2F;li&gt;
&lt;li&gt;鼓励实现的透明性&lt;&#x2F;li&gt;
&lt;li&gt;支持对数据在它们产生的上下文中进行健壮的分析。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;可以这么说，下述的使用案例决定了模型的具体功能，而这些设计原则决定了模型整体的特征和框架。我们认为这两者是我们设计的模型具有完全性，普遍性的根本原因。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;3-3-ye-wu-chang-jing&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#3-3-ye-wu-chang-jing&quot; aria-label=&quot;Anchor link for: 3-3-ye-wu-chang-jing&quot;&gt;3.3 业务场景&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;在我们设计Dataflow模型的过程中，我们考虑了FlumeJava和MillWheel系统在这些年遇到的各种真实场景。那些良好工作的设计，我们保留到了模型中，而那些工作不那么良好的设计激励我们采用新的方法重新设计。下面我们简单介绍一些影响过我们设计的场景。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;3-3-1-da-gui-mo-shu-ju-hui-xie-he-lambdajia-gou-tong-yi-mo-xing&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#3-3-1-da-gui-mo-shu-ju-hui-xie-he-lambdajia-gou-tong-yi-mo-xing&quot; aria-label=&quot;Anchor link for: 3-3-1-da-gui-mo-shu-ju-hui-xie-he-lambdajia-gou-tong-yi-mo-xing&quot;&gt;3.3.1 大规模数据回写和Lambda架构；统一模型&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;有一些团队在MillWheel上跑日志链接作业。这其中有一个特别大的日志链接处理作业在MillWheel上按流模式运行，而另外一个单独的FlumeJava批处理作业用来对流处理作业的结果进行大规模的回写。一个更好的设计是使用一个统一的模型，对数据处理逻辑只实现一次，但是能够在流处理引擎和批处理引擎不经修改而同时运行。这是第一个激发我们思考去针对批处理，微批次处理和流处理建立一个统一模型的业务场景。这也是图10-12所展示的。&lt;&#x2F;p&gt;
&lt;p&gt;有一些团队在MillWheel上跑日志链接作业。这其中有一个特别大的日志链接处理作业在MillWheel上按流模式运行，而另外一个单独的FlumeJava批处理作业用来对流处理作业的结果进行大规模的回写。一个更好的设计是使用一个统一的模型，对数据处理逻辑只实现一次，但是能够在流处理引擎和批处理引擎不经修改而同时运行。这是第一个激发我们思考去针对批处理，微批次处理和流处理建立一个统一模型的业务场景。这也是图10-12所展示的。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;3-3-2-fei-dui-qi-chuang-kou-hui-hua&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#3-3-2-fei-dui-qi-chuang-kou-hui-hua&quot; aria-label=&quot;Anchor link for: 3-3-2-fei-dui-qi-chuang-kou-hui-hua&quot;&gt;3.3.2 非对齐窗口：会话&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;从一开始我们就知道我们需要支持会话；事实上这是我们窗口模型对现有模型而言一个重大的贡献。会话对谷歌来说是一个非常重要的使用场景（也是MillWheel创建的原因之一）。会话窗口在一系列的产品域中都有应用，如搜索，广告，分析，社交和YouTube。基本上任何关心把用户的分散活动记录进行相互关联分析都需要通过会话来进行处理。因此，支持会话成为我们设计中的最重要考虑。如图14所示，支持会话在Dataflow中是非常简单的。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;3-3-3-zhi-fu-hong-fa-qi-lei-jia-he-che-hui&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#3-3-3-zhi-fu-hong-fa-qi-lei-jia-he-che-hui&quot; aria-label=&quot;Anchor link for: 3-3-3-zhi-fu-hong-fa-qi-lei-jia-he-che-hui&quot;&gt;3.3.3 支付：触发器，累加和撤回&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;有两个在MillWheel上跑支付作业的团队遇到的问题对模型的一部分也有启发作用。当时我们的设计实践是使用水位线作为数据完全到达的指标。然后写额外的逻辑代码来处理迟到的数据或者更改源头数据。由于缺乏一个支持更新和撤回的系统，负责资源利用率方案的团队最终放弃了我们的平台，构建了自己独立的解决方案（他们最后使用的模型和我们同时设计开发的模型事实上非常类似）。另一个支付团队的数据源头有少部分缓慢到达的数据，造成了水位线延迟，这给他们带来了大问题。这些系统上的缺陷成为我们对现有系统需要进行改良设计的重要动因，并且把我们的考虑点从保证数据的完整性转移到了对迟到数据的可适应性。对于这个场景的思考总结带来了两个方面：一个方面是能够精确，灵活地确定何时将窗口内容物化的触发器（如7-14所示），对同样的输入数据集也可以使用多种多样地结果输出模式进行处理。另外一方面是通过累积和撤回能够支持增量处理。（图14）&lt;&#x2F;p&gt;
&lt;h3 id=&quot;3-3-4-tong-ji-ji-suan-shui-wei-xian-hong-fa-qi&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#3-3-4-tong-ji-ji-suan-shui-wei-xian-hong-fa-qi&quot; aria-label=&quot;Anchor link for: 3-3-4-tong-ji-ji-suan-shui-wei-xian-hong-fa-qi&quot;&gt;3.3.4 统计计算：水位线触发器&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;很多MillWheel作业用来进行汇总统计（如平均延迟）。对这些作业来说，100%的准确性不是必须的，但是在合理的时间范围内得到一个接近完整的统计是必须的。考虑到对于结构化的输入（如日志文件），使用水位线就能达到很高程度的准确度。这些客户发现使用单次的的基于水位线的触发器就可以获得高度准确的统计。水位线触发器如图12所示。&lt;&#x2F;p&gt;
&lt;p&gt;我们有一些滥用检测的作业运行在MillWheel中。滥用检测是另外一种快速处理大部分数据比缓慢处理掉所有数据要远远更有价值的场景。因此，他们会大量地使用水位线百分位触发器。这个场景促使我们在模型中加入了对水位线百分位触发器的支持。&lt;&#x2F;p&gt;
&lt;p&gt;与此相关的，批处理作业中的一个痛点是部分处理节点的缓慢进度会成为执行时间中的长尾，拖慢整个进度。除了可以通过动态平衡作业来缓解这个问题，FlumeJava也支持基于整体完成百分度来选择是否终止长尾节点。用统一模型来描述批处理中遇到的这个场景的时候，水位线百分位触发器可以很自然地进行表达，不需要在引入额外的定制功能、定制接口。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;3-3-5-tui-jian-chu-li-shi-jian-hong-fa-qi&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#3-3-5-tui-jian-chu-li-shi-jian-hong-fa-qi&quot; aria-label=&quot;Anchor link for: 3-3-5-tui-jian-chu-li-shi-jian-hong-fa-qi&quot;&gt;3.3.5 推荐：处理时间触发器&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;另外一种我们考虑过的场景是从大量的谷歌数据资产中构建用户活动树（本质上是会话树）。这些树用来根据用户的兴趣来做推荐。在这些作业中我们使用处理时间作为触发器。这是因为，对于用户推荐来说，周期性更新的，即便是基于不完备数据的用户活动树比起持续等待水位线越过会话窗口边界（即会话结束）获得完全的数据要有意义的多。这也意味着由于部分少量数据引起的水位线进展延迟不影响基于其他已经到达的数据进行计算并获得有效的用户活动树。考虑到这种场景，我们包含了基于处理时间的触发器（如图7和图8所示）&lt;&#x2F;p&gt;
&lt;h3 id=&quot;3-3-6-yi-chang-tan-ce-shu-ju-qu-dong-he-zu-he-hong-fa-qi&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#3-3-6-yi-chang-tan-ce-shu-ju-qu-dong-he-zu-he-hong-fa-qi&quot; aria-label=&quot;Anchor link for: 3-3-6-yi-chang-tan-ce-shu-ju-qu-dong-he-zu-he-hong-fa-qi&quot;&gt;3.3.6 异常探测：数据驱动和组合触发器&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;在MillWheel的论文中，我们描述了一种用来检测谷歌网站搜索查询趋势的微分异常探测数据处理管道。当我们为模型设计触发器的时候，这种微分异常探测系统启发我们设计了数据驱动触发器。这种微分探测器检测网站检索流，通过统计学估计来计算搜索查询请求量是否存在一个毛刺。如果系统认为一个毛刺即将产生，系统将发出一个启动型号。当他们认为毛刺已经消除，那么他们会发出一个停止信号（译者注：可能会对接系统自动对系统扩容或缩容）。尽管我们可以采用别的方式来触发计算，比如说Trill的标点符(Punctuations)，但是对于异常探测你可能希望一旦系统确认有异常即将发生，系统应该立即输出这个判断。标点符的使用事实上把流处理系统转换成了微批次处理系统，引入了额外的延迟。在调查过一些用户场景后，我们认为标点符不完全适合我们。因此我们在模型中引入了可定制化数据驱动触发器。同时这个场景也驱使我们支持触发器组合，因为在现实场景中，一个系统可能在处理多种微分计算，需要根据定义的一组逻辑来支持多种多样的输出。图9中的AtCount触发器是数据驱动触发器的例子，而图10-14使用了组合触发器。&lt;&#x2F;p&gt;
&lt;h1 id=&quot;4-zong-jie&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#4-zong-jie&quot; aria-label=&quot;Anchor link for: 4-zong-jie&quot;&gt;4. 总结&lt;&#x2F;a&gt;&lt;&#x2F;h1&gt;
&lt;p&gt;在MillWheel的论文中，我们描述了一种用来检测谷歌网站搜索查询趋势的微分异常探测数据处理管道。当我们为模型设计触发器的时候，这种微分异常探测系统启发我们设计了数据驱动触发器。这种微分探测器检测网站检索流，通过统计学估计来计算搜索查询请求量是否存在一个毛刺。如果系统认为一个毛刺即将产生，系统将发出一个启动型号。当他们认为毛刺已经消除，那么他们会发出一个停止信号（译者注：可能会对接系统自动对系统扩容或缩容）。尽管我们可以采用别的方式来触发计算，比如说Trill的标点符(Punctuations)，但是对于异常探测你可能希望一旦系统确认有异常即将发生，系统应该立即输出这个判断。标点符的使用事实上把流处理系统转换成了微批次处理系统，引入了额外的延迟。在调查过一些用户场景后，我们认为标点符不完全适合我们。因此我们在模型中引入了可定制化数据驱动触发器。同时这个场景也驱使我们支持触发器组合，因为在现实场景中，一个系统可能在处理多种微分计算，需要根据定义的一组逻辑来支持多种多样的输出。图9中的AtCount触发器是数据驱动触发器的例子，而图10-14使用了组合触发器。&lt;&#x2F;p&gt;
&lt;p&gt;根据我们多年在谷歌处理大规模无边界数据的实践经验，我们相信我们提出的模型一个非常好的进展。它支持非对齐，事件发生时间窗口。这些都是当前用户所需要的。它提供了灵活的窗口触发机制，支持窗口累积和撤回，把关注点从寻求等待数据的完整性变为自动适应现实世界中持续变更的数据源。它对批处理，微批次，流处理提供了统一的抽象，允许数据开发人员灵活从三者中选择。同时，它避免了单一系统容易把系统本身的构建蔓延到数据处理抽象层面中去的问题。它的灵活性让数据开发者能根据使用场景恰当地平衡数据处理的准确性，成本和延迟程度。对于处理多样化的场景和需求来说，这一点很关键。最后，通过把数据处理的逻辑划分为计算什么，在哪个事件发生时间范围内计算，在什么处理时间点触发计算，如何用新的结果订正之前的数据处理结果让整个数据处理逻辑透明清晰。我们希望其他人能够认同这个模型并且和我们一起推进这个复杂而又令人着迷的领域的发展。&lt;&#x2F;p&gt;
</content>
    </entry>
    <entry xml:lang="en">
        <title>streaming101</title>
        <published>2021-03-02T00:00:00+00:00</published>
        <updated>2021-03-02T00:00:00+00:00</updated>
        <author>
          <name>Unknown</name>
        </author>
        <link rel="alternate" href="https://wendajiang.github.io/streaming101/" type="text/html"/>
        <id>https://wendajiang.github.io/streaming101/</id>
        <content type="html">&lt;p&gt;原文：https:&#x2F;&#x2F;www.oreilly.com&#x2F;radar&#x2F;the-world-beyond-batch-streaming-101&#x2F;&lt;&#x2F;p&gt;
&lt;p&gt;流数据处理是当今大数据世界的一大难题，理由如下：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;业务希望获取更加及时的数据，因而切换到流式处理是降低延迟的好办法。&lt;&#x2F;li&gt;
&lt;li&gt;为海量又无限的数据而设计的系统，更能应对这种日益增长的业务数据的需求。&lt;&#x2F;li&gt;
&lt;li&gt;在数据到达时即处理数据，能够使得工作负载更加均匀，从而产生更一致和可预测的资源消耗&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;尽管业务驱动导致流计算的兴趣日益增加，但是和批处理相比，现有的大多数流式系统仍然不够成熟，这也导致了最近该领域的很多有意思的发展。&lt;&#x2F;p&gt;
&lt;p&gt;作为一个最近5年多一直在谷歌的大规模流式系统（MillWheel, Cloud Dataflow）工作的我来说，很乐于看到这种源源不断的流计算的思潮。对于如何保证人们理解并应用流式系统，特别是在现存的批处理和流处理系统存在一定的语义鸿沟的情况下，我很感兴趣。因而接下来的内容将分为两个部分：&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;Streaming 101：第一篇文章会介绍基本的背景情况以及一些术语，然后再深入到时域，以及对批处理和流处理的一般方法做高度的概括。&lt;&#x2F;li&gt;
&lt;li&gt;Dataflow 模型：第二篇文章主要介绍 Cloud Dataflow 所使用的批流统一的模型，并以一个例子应用不同的场景来辅助说明。最后对现有的批处理和流处理系统做一个简要的语义上的比较。&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;闲话少说，下面进入主题。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;bei-jing&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#bei-jing&quot; aria-label=&quot;Anchor link for: bei-jing&quot;&gt;&lt;strong&gt;背景&lt;&#x2F;strong&gt;&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;开始前，我会介绍一些重要的背景信息， 以帮助构建接下来我将要讨论的主题框架。下面我会分为三个部分：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;术语&lt;&#x2F;strong&gt;：越是讨论复杂的话题，就越是需要精准的定义。对于当下有各种解释的术语，我会具体说明在这里的含义。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;功能&lt;&#x2F;strong&gt;：我会指出流式系统的缺点，同时提出构建数据处理系统的框架思想，以满足消费者日益增长的需求。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;时域&lt;&#x2F;strong&gt;：我会介绍数据处理中两种主要的时域、它们的相关性，并指出二者带来的困难。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;zhu-yu-liu-streaming-shi-shi-yao&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#zhu-yu-liu-streaming-shi-shi-yao&quot; aria-label=&quot;Anchor link for: zhu-yu-liu-streaming-shi-shi-yao&quot;&gt;&lt;strong&gt;术语： 流（streaming）是什么？&lt;&#x2F;strong&gt;&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;在接下来的内容之前，首先我们要解决的是：流到底是什么？“流”可以表示各种不同的意思，这可能导致我们误解流到底是什么以及流式系统究竟能做什么。鉴于此，我会尽可能地准确定义这些术语。&lt;&#x2F;p&gt;
&lt;p&gt;当前问题的关键在于许多事情应该由它们是&lt;em&gt;什么&lt;&#x2F;em&gt;（例如无限数据处理、近似结果等）来定义，然而事实上经常由它们在历史上是&lt;em&gt;如何&lt;&#x2F;em&gt;（例如通过流计算引擎）实现的来进行介绍。术语上的这种不准确导致了流的真正含义变得模糊，有时候甚至把流式系统的功能局限于流的特性，如近似和推测结果。由于精心设计的流式系统也能够和批处理系统一样产生正确、一致、可重复的结果。所以这里我倾向给“流”下一个更加精确的定义：&lt;em&gt;一种针对无限数据集而设计的数据处理引擎&lt;&#x2F;em&gt;。仅此而已。（为了防止有失偏颇，有必要说明一下这个定义同时包括了真正的流以及微批的实现方式。）&lt;&#x2F;p&gt;
&lt;p&gt;作为“流”的常见场景，下面是我常听到的，每个都被精确定义，我也建议我们的社区应该采用：&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;无限数据&lt;&#x2F;strong&gt;：一种不断增长的，本质上无限的数据集。这些通常被称为“流数据”（streaming data）。然而，当应用于数据集时，流或批的术语是有问题的，因为这意味着使用特定的&lt;em&gt;执行引擎&lt;&#x2F;em&gt;来处理这些数据集。两种类型的数据集之间的关键区别在于现实中它们的有限性，因此最好用这种能够区分它们特征的术语。因此，我倾向于将无限的“流”数据集称为无限数据，有限的“批”数据集叫做有限数据。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;无限数据处理&lt;&#x2F;strong&gt;：一种持续的数据处理模式，适用于上述的无限数据。虽然我个人很想使用“流”这个术语来描述数据处理的类型，但是这种情况下的使用再次暗示使用了流计算引擎，这根本就是误导；而自从设计了批处理系统以来，我们就一直重复运行批处理引擎来处理无限数据（相反地，精心设计的流式系统能够比批处理系统更会处理有限数据）。因此，为了清楚定义，我将简单地称之为&lt;em&gt;无限数据处理&lt;&#x2F;em&gt;。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;低延迟、近似、推测结果&lt;&#x2F;strong&gt;：结果的类型往往和流计算引擎相关。事实上，批处理系统从一开始就没有被设计为低延迟或者推测结果，这是历史事实，仅此而已。当然，如果有必要的话批处理引擎完全有能力产生近似结果。因此，对于上述的术语，应该按照它们本来的样子（低延迟、近似、推测结果）来描述，这胜过说它们历史上如何表现的（通过流计算引擎）。&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;从现在开始，任何时候使用术语“流”，意思都是设计用于无限数据集的执行引擎，仅此而已。当我谈到上述任何其他术语时，我会直接说无限数据，无限数据处理或低延迟、近似、推测结果。这些是我们在 Cloud Dataflow 中采用的术语，同时我鼓励其他人也如此使用。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;bei-guo-fen-kua-da-de-liu-chu-li-de-ju-xian&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#bei-guo-fen-kua-da-de-liu-chu-li-de-ju-xian&quot; aria-label=&quot;Anchor link for: bei-guo-fen-kua-da-de-liu-chu-li-de-ju-xian&quot;&gt;&lt;strong&gt;被过分夸大的流处理的局限&lt;&#x2F;strong&gt;&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;接下来，谈一谈流式处理系统能做什么和不能做什么，重点在能做什么；其中我最想做的事情就是讨论一个精心设计的流处理究竟可以做到什么。流式系统长期以来一直被放在提供低延迟，不准确&#x2F;推测结果的场景里，通常结合批处理系统来提供最终正确的结果，即 Lambda 架构。&lt;&#x2F;p&gt;
&lt;p&gt;对于不熟悉 Lambda 架构的你来说，只需要知道它的基本思想就是在批处理系统旁边运行一个流处理系统，并且执行基本相同的计算。流式处理系统提供低延迟、不准确的结果（由于使用近似算法，或者因为流系统本身不提供准确性的保证），所以每过一段时间，批处理系统便持续滚动处理并计算出正确的结果。该思想最初是由 Twitter 的 Nathan Marz（Apache Storm 的创始人）提出的，最终是相当成功的因为在当时这是个很棒的想法；流计算引擎在正确性方面让人失望，而批处理天生笨拙，所以 Lambda 为您提供了一种方法让您鱼和熊掌兼得。然而维护 Lambda 系统是一件麻烦：需要构建和维护两个版本的管道，并且要将两者的结果合并。&lt;&#x2F;p&gt;
&lt;p&gt;和一些常年从事于强一致性流计算引擎的人一样，我对 Lambda 架构的整个概念感到有点讨厌。不出所料，当 Jay Kreps 的文章 Lambda 架构质疑 一出，我变成了他的铁粉。这是反对双模式执行的必要性的首次有力陈述。Kreps 使用 Kafka 这样的可重放系统作为流计算架构的内部连接，从而解决了可重复的问题，甚至进一步提出了 Kappa 架构，这基本意味着可以使用一个精心设计的系统来运行单一的管道。我不确定这个概念需要个名字，但是我完全支持这个概念。&lt;&#x2F;p&gt;
&lt;p&gt;老实说，我会走得更远。我会讨论一个精心设计的流式系统事实上提供了一个批处理功能之上的严格超集。感谢 Flink 的开发者将这一思想牢记于心，并构建了一个一直完全流式的系统，甚至包含批的模式。&lt;&#x2F;p&gt;
&lt;p&gt;所有这一切的必然结果是广泛成熟的流式系统，加上用于无限数据处理的健壮框架，最终 Lambda 架构将回到它所属的大数据的历史洪荒中去。我相信这将成为现实。因为在这场比赛中打败批处理，你今需要两个概念：&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;正确性&lt;&#x2F;strong&gt;——这让你与批处理&lt;em&gt;平起平坐&lt;&#x2F;em&gt;
首先，正确性归结为一致性存储。流式系统需要伴随时间存在的检查点来持久化状态信息（有些内容 Kreps 在他的 为什么本地状态是是流处理的基本原语 有提及），而且必须设计得足够好，能够在机器出现故障时保持一致性。当 Spark Streaming 几年前首次出现在公开的大数据场景下时，那简直是幽暗的流计算世界里一致性的灯塔。庆幸的是自那以后情况有所好转，但是仍然有不少流式系统运行在没有强一致性的情况下；我真的不敢相信至多一次处理仍然是个问题，但事实就是。
重申一下，因为这点很重要：仅仅一次的处理要求很强的一致性，这对于正确性是必要条件，而且这对于希望达到甚至超过批处理系统的能力的任何系统而言都是必需的。除非你真的不在乎结果，否则我恳求你不要使用那些不能提供强一致性状态的流式系统。批处理系统不需要你事先验证它们是否能够产生正确的结果；因而不要把时间浪费在那些不能实现相同目标的流式系统上。
如果想了解更多关于流式系统中如何实现强一致性，可以参考 MillWheel 和 Spark Streaming 论文。两篇论文花了大量时间讨论一致性。由于这些论文对此给出了高质量的介绍，本文将不会赘述。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;关于时间的推理工具&lt;&#x2F;strong&gt;——这让你&lt;em&gt;超越&lt;&#x2F;em&gt;批处理
对于乱序无限数据流，数据产生的时间和数据真正被处理的时间之间的的偏差很大，用于推理时间的工具至关重要。越来越多的现代数据集体现了这个特点，现有的批处理系统（以及大多数流处理系统）缺乏必要的工具来应对这个问题。接下来以及下一篇文章，我们都将聚焦于此。
首先，我们将对时域概念有一个基本的了解，之后我们将更深入了解我所说的无限的、乱序的、不同的事件时间倾斜是什么意思。剩下的时间我们再了解使用批处理和流式系统处理有限和无限的数据的常用方法。&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;h2 id=&quot;shi-jian-shi-jian-vs-chu-li-shi-jian&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#shi-jian-shi-jian-vs-chu-li-shi-jian&quot; aria-label=&quot;Anchor link for: shi-jian-shi-jian-vs-chu-li-shi-jian&quot;&gt;&lt;strong&gt;事件时间 vs. 处理时间&lt;&#x2F;strong&gt;&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;要阐述无限数据的处理方式，需要清楚地了解时间所涉及的领域。在任何数据处理系统中，通常有两种时间值得关注：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;事件时间&lt;&#x2F;strong&gt;，即事件发生的真实时间&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;处理时间&lt;&#x2F;strong&gt;，即事件被系统观察到的时间&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;并不是所有情况下都需要关心事件的时间（如果你的不需要，万岁啊——你的生活因此更加简单），但大多数情况下需要，例如根据时间刻画用户行为，大多数计费应用程序、不同类型的异常检测。&lt;&#x2F;p&gt;
&lt;p&gt;在一个理想的世界中，事件在发生时即被处理，因而事件时间和处理时间总是相等的。然而，现实并非如此，事件时间和处理时间之间总会存在偏差，而且通常严重受到数据底层输入源，执行引擎甚至硬件的影响。可能影响的因素包括：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;共享资源限制，如网络拥塞，网络分区或在非专用环境中共享CPU。&lt;&#x2F;li&gt;
&lt;li&gt;软件因素，如分布式系统的复杂逻辑、资源竞争等。&lt;&#x2F;li&gt;
&lt;li&gt;数据本身的特性，包括 key 的分布、吞吐的差异、乱序（例如将飞机上的所有乘客的手机都从飞行模式中退出来）。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;因此，如果要将实际系统中事件时间和处理时间的进度关系画出来的话，您得到的应该是类似于图1中红线的结果。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;v2-1cbbcbcc4b3c08ca0b767fa247114674_720w.jpg&quot; alt=&quot;img&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;斜率为1的黑色虚线表示理想状态下，处理时间和事件时间一致；红线表示现实情况。在这个例子中，系统在处理时间的前段落后一点，在中间偏向理想状态，然后再次落后直到最后。黑色虚线与红线之间的水平距离是处理时间和事件时间之间的偏差。这种偏差本质上就是处理管道所带来的延迟。&lt;&#x2F;p&gt;
&lt;p&gt;由于事件时间和处理时间之间的关系不是静态的，如果关注数据的事件时间，那么就不能仅仅基于在你的数据管道中所观察到的时间来分析数据。不幸的是，现有的大多数系统都是为处理时间而设计的。为了处理无限数据集的无穷的特性，这些系统通常对于传入的数据提供了窗口概念。下面将深入讨论窗口，但它本质上其实就是将无限数据集沿着时间的边界切分成有限数据集。&lt;&#x2F;p&gt;
&lt;p&gt;如果您关注正确性并且希望基于事件时间分析数据，那么就不能像那些现有的系统一样来使用处理时间（即处理时间窗口）来定确定那些边界；由于处理时间和事件时间不具备一致的相关性，使用处理时间会导致一些数据划分到错误的窗口中（由于分布式系统的固有滞后，各种类型输入源的在线&#x2F;离线特性等等），导致不正确的结果。我会在下面的例子以及接下来一篇文章中详细介绍这个问题。&lt;&#x2F;p&gt;
&lt;p&gt;不幸的是，按照事件时间进行窗口操作也不是那么乐观。对于事件时间窗口来说，基于无限的数据，乱序和可变的时间延迟会引入一致性的问题：处理时间和事件时间之间的关系是不可预测的，那么给定一个事件时间 X，你如何确定所有数据都到达了？对于多数真实的数据源，你恐怕无法简简单单就做到。目前使用的绝大多数数据处理系统都依赖于一些完整性的概念，这使得它们不太容易处理无限的数据集。&lt;&#x2F;p&gt;
&lt;p&gt;所以我建议与其试图将无限数据变成最终一致的有限批次数据，还不如设计一些工具让我们生活在这种不确定的世界中，从而应对这些复杂的数据集。新数据将要到达，旧数据可能会被撤回或更新，我们构建的任何系统都应该能够应对这些事实，这里使用完整性的概念是方便阐述，而不是必要的术语。&lt;&#x2F;p&gt;
&lt;p&gt;在深入研究我们是如何使用 Cloud Dataflow 中用到的 Dataflow 模型来构建这样一个系统之前，让我们先学习一些背景知识：一般的数据处理模式。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;shu-ju-chu-li-mo-shi&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#shu-ju-chu-li-mo-shi&quot; aria-label=&quot;Anchor link for: shu-ju-chu-li-mo-shi&quot;&gt;&lt;strong&gt;数据处理模式&lt;&#x2F;strong&gt;&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;至此，我们已经掌握了足够的背景知识，现在开始研究有限及无限数据处理中常见的几种处理模式。我们针对这两种计算引擎，研究它们的处理类型以及相关之处（这里指的是批处理和流式处理，我把微批处理和流处理放在了一起，因为这二者在这级别上的差异并不是很大）。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;you-xian-shu-ju&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#you-xian-shu-ju&quot; aria-label=&quot;Anchor link for: you-xian-shu-ju&quot;&gt;&lt;strong&gt;有限数据&lt;&#x2F;strong&gt;&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;处理有限数据是非常简单的，我们都很熟悉，例如Hadoop，在最开始都是为了处理有限数据集而出现的。在下图中，从左边开始，一个混乱无序的数据集，经过数据处理引擎（通常是批处理引擎，精心设计的流处理引擎也可以），如 MapReduce，最后在右侧产生一个更具价值的新的结构化数据集：&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;v2-3e6d3db2c04cb8e2d0f0170b87d957bc_720w.jpg&quot; alt=&quot;img&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;尽管作为这个方案的一部分，您实际上可以计算出无数种可能性，但整个模型是非常简单的。而更有意思的的是处理无限数据集。现在来看看处理无限数据的几种方式，从传统批处理引擎使用的方法开始，最后看看设计用于无限数据的系统使用的方法，诸如大多数流处理或微批引擎。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;wu-xian-shu-ju-pi-chu-li&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#wu-xian-shu-ju-pi-chu-li&quot; aria-label=&quot;Anchor link for: wu-xian-shu-ju-pi-chu-li&quot;&gt;&lt;strong&gt;无限数据——批处理&lt;&#x2F;strong&gt;&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;批处理引擎虽然不是为无限数据集处理而设计，但是自批处理系统诞生以来都在用于处理无限数据集。而且很容想到，这种处理方式就是将无限数据集分解成适合于批处理的有限数据集。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;gu-ding-chuang-kou&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#gu-ding-chuang-kou&quot; aria-label=&quot;Anchor link for: gu-ding-chuang-kou&quot;&gt;&lt;strong&gt;固定窗口&lt;&#x2F;strong&gt;&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;处理无限数据集的最常见方法就是将输入数据分配到固定大小的窗口中，将这些窗口中作为单独、有限的数据集进行处理，然后不断运行。例如像日志这种输入源，将事件写入文件目录，名称对应所属的窗口，只要基于时间执行 shuffle，让数据分配到合适的事件时间窗口中即可。&lt;&#x2F;p&gt;
&lt;p&gt;实际上，大多数系统仍然有一个完整性的问题需要处理：如果一些事件由于网络分区而延迟该怎么办？如果需要从全球各地收集事件，必须在处理之前传输到一个公共的位置？如果事件来自移动设备又该怎么办？这意味着必须要有某种方式来解决此类问题（例如延迟处理直到确定已收集所有事件，或者在数据迟到时，为指定窗口重新处理整个批次）。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;v2-71c2d103f221b4bc04989c8831e26888_720w.jpg&quot; alt=&quot;img&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;hui-hua&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#hui-hua&quot; aria-label=&quot;Anchor link for: hui-hua&quot;&gt;&lt;strong&gt;会话&lt;&#x2F;strong&gt;&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;当您面对更加复杂的窗口策略（如会话）时，还希望使用批处理引擎来处理无限数据，这样几乎是徒劳的。会话窗口通常被定义为一个活动周期，超过一定时间不再活动就认为会话窗口中止。当使用批处理引擎计算会话窗口时，通常会遇到会话的数据拆分在2个或多个批次中的情况，如下图中的红色标记所示。可以通过增加每批次数据量的大小来减少拆分数量，但是代价是增加了延迟。另一个选择是增加额外的逻辑，从之前的运行中合并会话，但带来了更高的复杂度。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;v2-720db47cda67af2450491b66960702e4_720w.jpg&quot; alt=&quot;img&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;不管怎样，使用传统的批处理引擎来计算会话都不够理想。更好的方式是以流的方式来构建会话，接下来我们一起看看吧。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;wu-xian-shu-ju-liu-shi-chu-li&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#wu-xian-shu-ju-liu-shi-chu-li&quot; aria-label=&quot;Anchor link for: wu-xian-shu-ju-liu-shi-chu-li&quot;&gt;&lt;strong&gt;无限数据——流式处理&lt;&#x2F;strong&gt;&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;与大多数基于批的无限数据处理方法的特殊性相反，流式系统是专为无限数据构建的。如前所述，对于现实世界的很多分布式输入数据源，不仅要处理无限的数据，而且要处理这样的数据：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;高度无序的事件时间&lt;&#x2F;strong&gt;，这意味着如果想在事件发生的上下文来分析数据，则需要在Pipeline中进行基于时间的 shuffle。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;多样的事件时间差&lt;&#x2F;strong&gt;，这意味着你不能仅仅假设大部分数据的事件时间 X 的与时间 Y 的差距在一个常数 &lt;code&gt;ε&lt;&#x2F;code&gt; 内。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;处理具备这些特征的数据，一般有几种方法，我通常将它们分为以下四类：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;时间无关&lt;&#x2F;li&gt;
&lt;li&gt;近似解&lt;&#x2F;li&gt;
&lt;li&gt;基于处理时间的窗口&lt;&#x2F;li&gt;
&lt;li&gt;基于事件时间的窗口&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;下面我们来依次分析。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;shi-jian-wu-guan&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#shi-jian-wu-guan&quot; aria-label=&quot;Anchor link for: shi-jian-wu-guan&quot;&gt;&lt;strong&gt;时间无关&lt;&#x2F;strong&gt;&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;时间无关的处理一般用于与时间无关的场景，即所有相关逻辑都是数据驱动的。由于这种情况下持续的数据输入最为重要，流处理引擎除了满足数据传输的特性外，不需要其他的。因此，基本上所有流处理系统都支持时间无关的使用场景（系统到系统的一致性保证，对关心正确性的人有用）。批处理系统非常适用于时间无关的无限数据集处理，它会通过简单地将无限数据切分成任意的有限数据集然后单独地处理它们。我们将在本节中看几个具体的例子，由于时间无关的处理简单直观，所以并不会花很多时间在上面。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;guo-lu&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#guo-lu&quot; aria-label=&quot;Anchor link for: guo-lu&quot;&gt;&lt;strong&gt;过滤&lt;&#x2F;strong&gt;&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;一种最基本的时间无关的处理就是过滤。假设正在处理 Web 流量日志，并且要过滤掉非特定域名的所有流量。每条记录到达时，检查是否来自某个来源，如果不是则丢弃。由于这种处理只针对单个元素，而事实上数据源是无限的、乱序的以及多样的事件时间差这几个因素是无关紧要的。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;v2-947094ef1f6dc432cf7e1599297b4bff_720w.jpg&quot; alt=&quot;img&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;nei-lian-jie&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#nei-lian-jie&quot; aria-label=&quot;Anchor link for: nei-lian-jie&quot;&gt;&lt;strong&gt;内连接&lt;&#x2F;strong&gt;&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;另一个时间无关的例子是内连接（或者叫哈希连接）。当 join 两个无限数据源时，如果只关心连接的结果，则不需要关注时间。从一个数据源接收1个值，你可以直接缓存为持久化状态；一旦来自另一个源的第2个值到达时，仅需要发出连接上的记录。（在实际中，有一些记录可能没有合适的关联数据进行连接，此时可能需要基于时间进行清理掉旧数据，但是对于很少或没有未完成连接的情况，这问题不大。）&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;v2-8b8ef9c6ecf79e1d3b100226cd0afe3b_720w.jpg&quot; alt=&quot;img&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;至于外连接则存在我们之前讨论过的数据完整性问题：一方数据到了，你怎么知道另一方数据是否会到达？ 在实际中，很难确定，所以必须使用超时的概念，这也因此要引入时间元素。而时间元素在本质上就是一种窗口形式，稍后会更详细地介绍。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;jin-si-suan-fa&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#jin-si-suan-fa&quot; aria-label=&quot;Anchor link for: jin-si-suan-fa&quot;&gt;&lt;strong&gt;近似算法&lt;&#x2F;strong&gt;&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;v2-1b89b685b2ee73ed50901256aa0c03c5_720w.jpg&quot; alt=&quot;img&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;第二类方法是近似算法，例如近似Top-N、流的K均值等。它们采用无限输入数据源，并提供输出数据。近似算法的优点在于它们的开销比较小，专为无限数据集而设计。缺点是算法本身往往是复杂的（这使得难以引出新的算法），并且这种近似的特性限制了它的用武之地。&lt;&#x2F;p&gt;
&lt;p&gt;值得注意的是：这些算法通常在其设计中考虑了时间因素（例如某种内置的衰减）。而且一般采用到达时处理元素的策略，所以通常是基于处理时间的。这一点对于可以证明近似算法的误差范围特别重要。如果这些误差范围在数据顺序到达的情况下可以证明，那么在应对不同事件时间的差距时它们什么也不是，这些算法也将无用。&lt;&#x2F;p&gt;
&lt;p&gt;近似算法是一个很有趣的主题，由于它们本质上是与时间无关的处理，因此它们非常简单易用，此处便不再赘述。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;chuang-kou&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#chuang-kou&quot; aria-label=&quot;Anchor link for: chuang-kou&quot;&gt;&lt;strong&gt;窗口&lt;&#x2F;strong&gt;&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;无限数据剩下的两种处理，都是基于窗口的变体。 在深入不同窗口类型的差异之前，需要明确一下窗口的含义。 窗口其实就是对数据源（不论是无限还是有限的）在时间上进行切分，得到有限的数据块。 下图显示了三种不同的窗口模式：&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;v2-4075f899b86812647027c868124a3861_720w.jpg&quot; alt=&quot;img&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;固定窗口&lt;&#x2F;strong&gt;：固定窗口将时间分割成具有固定大小时间段。通常（如图8所示），固定窗口均匀的分隔整个数据集，这是&lt;em&gt;对齐&lt;&#x2F;em&gt;窗口的示例。在某些情况下，希望对于数据的不同子集（如根据键来）进行相移，以随着时间的推移更均匀地扩展窗口完成负载，而不是随着数据变化，否则那就是&lt;em&gt;非对齐&lt;&#x2F;em&gt;窗口了。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;滑动窗口&lt;&#x2F;strong&gt;：滑动窗口由固定长度和时间周期定义。如果时间周期小于长度，则窗口重叠。如果周期等于长度，则等同于固定窗口。如果周期大于长度，有一些数据就无法分配到窗口中。与固定窗口一样，滑动窗口通常对齐，在某些使用情况下可能会为优化性能而不对齐。注意，图 8 中的滑动窗口被绘制出滑动感；实际上，所有五个窗口将应用于整个数据集。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;会话窗口&lt;&#x2F;strong&gt;：会话是一种动态窗口，会话由事件序列组成，会话之间由于大于某个超时时间而产生间隔。会话通常用于分析一段时间内的用户行为，通过将一系列时间相关的事件（例如，一次观看的视频序列）分组在一起。会话很有意思的，因为长度不能被事先定义而取决于实际数据。它是非对齐窗口的典型示例，因为会话在不同的数据子集（例如不同的用户）上几乎不相同。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;其中的处理时间和事件时间时我们主要关注的。窗口在两种时间类型中都是有意义的，接下来我们看看二者的区别。 因为处理时间在现有系统中应用最广，那么首先从处理时间开始。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;ji-yu-chu-li-shi-jian-de-chuang-kou&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#ji-yu-chu-li-shi-jian-de-chuang-kou&quot; aria-label=&quot;Anchor link for: ji-yu-chu-li-shi-jian-de-chuang-kou&quot;&gt;&lt;strong&gt;基于处理时间的窗口&lt;&#x2F;strong&gt;&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;v2-3b76991ce608ac02a13415cb53d3c3d9_720w.jpg&quot; alt=&quot;img&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;当基于处理时间划分窗口时，系统将进入的数据缓冲到窗口中，一直到窗口末尾的时间。 例如，在5分钟固定窗口的情况下，系统将缓冲数据，处理时间为5分钟，之后将其在5分钟内收到所有数据视为1个窗口，并将其发送到下游进行处理。&lt;&#x2F;p&gt;
&lt;p&gt;处理时间有以下几个优点：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;简单&lt;&#x2F;strong&gt;。不需要根据时间 shuffle 数据，因而实现起来容易。只需在数据到达时缓冲数据，并在窗口关闭时向下游发送。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;容易判断完整性&lt;&#x2F;strong&gt;。由于系统很清楚地知道窗口的数据，所以很容易判断窗口是否已经完成。这意味着使用处理时间可以不再需要处理“迟到的”数据。&lt;&#x2F;li&gt;
&lt;li&gt;如果你想&lt;strong&gt;根据收到的数据推测信息&lt;&#x2F;strong&gt;，那么处理时间很合适。许多监控方案属于这一类。 举例来说，跟踪每秒发送到全球规模Web服务的请求数， 来检测中断，计算这些请求的速率是处理时间窗口的完美用法。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;此外，处理时间窗口有一个很大的缺点：&lt;em&gt;如果数据中带有事件时间，而处理时间窗口需要反映出这些事件真实发生的时间的话，那么则要求这些事件以事件时间的顺序到达&lt;&#x2F;em&gt;。可惜的是，事件时间有序的数据在大多数现实的分布式场景中并不常见。&lt;&#x2F;p&gt;
&lt;p&gt;考虑一个简单的案例，有一个移动 App 收集使用统计信息以供后续处理。如果给定的移动设备离线（短时间内连接失败，调为飞行模式等），则在该设备上线之前不会上传数据。这意味着数据可能会出现事件时间偏差几分钟、几个小时、几天、几周甚至更长时间。这时使用处理时间窗口的话是无法从这样的数据集中推断出设备离线或者其他有用的信息的。&lt;&#x2F;p&gt;
&lt;p&gt;再举一个例子，当整个系统正常时，一些分布式输入源在一切正常运转时似乎能够提供事件时间有序（或接近有序）的数据。这个时候的事件时间偏差比较小，但并不意味着会始终这样。在全球性的场景中，Web 服务跨越了多个大陆，收集数据受限于跨洋线路的带宽，进一步降低了带宽和&#x2F;或提高了延迟，那么输入数据的一部分可能突然以比以前更大的偏差到达系统。如果通过处理时间窗口处理数据，则窗口不再代表其中实际发生的数据；相反，窗口代表事件到达系统的时间窗口，而这会导致旧数据和当前数据混在一起。&lt;&#x2F;p&gt;
&lt;p&gt;在这两种情况下，要想事件按照事件时间顺序的处理，需要的是事件时间窗口。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;ji-yu-shi-jian-shi-jian-de-chuang-kou&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#ji-yu-shi-jian-shi-jian-de-chuang-kou&quot; aria-label=&quot;Anchor link for: ji-yu-shi-jian-shi-jian-de-chuang-kou&quot;&gt;&lt;strong&gt;基于事件时间的窗口&lt;&#x2F;strong&gt;&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;在你需要以事件真实发生的时间来观察数据时，需要使用事件时间窗口。这是窗口的黄金法则。可惜的是，当今的大多数系统缺乏对于事件事件的本地支持（虽然有些具有很好的一致性模型的系统，比如 Hadoop 或者 Spark Streaming，也可以构建这样的一个窗口的系统）。&lt;&#x2F;p&gt;
&lt;p&gt;下图显示了将无限数据源中的数据，按照1小时长度的固定窗口进行切分的示例：&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;v2-46847d1d5aedf9c01c4652cfb66b4f14_720w.jpg&quot; alt=&quot;img&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;该图中的白实线标出了两个感兴趣的数据。 从图中可以看出，这两类数据都到达处理时间窗口，但是与它们所属的事件时间窗口不匹配。 因此，想按照事件时间进行处理，如果使用处理时间窗口，则计算结果将不正确。显然，使用事件时间窗口才能达到事件时间上的正确性。&lt;&#x2F;p&gt;
&lt;p&gt;另外在处理无限数据的时候，使用事件时间窗口，可以创建动态大小的窗口。例如会话窗口，此种情况下，使用固定窗口会将紧密相关联数据分隔到不同的窗口（之前在“无限数据——批处理”部分的会话窗口示例中说明过）：&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;v2-85d463cf4fc4446a63694e33f832edc1_720w.jpg&quot; alt=&quot;img&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;当然，强大的语义来之不易，事件时间窗口也不例外。事件时间窗口由于通常比窗口本身的实际长度（处理时间）更长，因而具有以下两个缺点：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;缓存&lt;&#x2F;strong&gt;：由于窗口的生命周期变长，需要缓存更多的数据。持久化存储通常是最廉价缓存方式（其他主要是CPU，网络带宽和RAM）。因此，当使用具有强一致持久化状态和良好的内存缓存的数据处理系统时，这一般不是个大问题。此外，一些聚合运算不需要缓存整个输入集（例如求和或平均值），而是只需要增量计算，这在持久化状态中占用很小。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;完整性&lt;&#x2F;strong&gt;：由于难以知道一个窗口是否&lt;em&gt;所有&lt;&#x2F;em&gt;的数据都到齐了，那么我们怎么知道在哪个时刻计算结果呢？事实上，不必如此。但是对于许多类型的输入源，系统可以通过像 MillWheel 的 Watermark（下篇文章将详细讨论）来给出对于窗口的数据到齐的准确的启发式估计。但是在必须要保证绝对正确的情况下（例如计费），唯一的选择是为管道提供一种方式来表示何时计算结果，以及这些结果如何随着时间的推移而更正。处理窗口的完整性是一个有趣的话题，但最好结合具体的例子来探讨，下一章我们再见。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;zong-jie&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#zong-jie&quot; aria-label=&quot;Anchor link for: zong-jie&quot;&gt;&lt;strong&gt;总结&lt;&#x2F;strong&gt;&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;哇喔，信息量好大啊。对于看到此处的你值得表扬！到这里我们已经完成了我想要介绍的一半的内容，所以回头看看，回顾一下之前介绍过的内容，在深入到第二部分之前，我们稍微放慢脚步。第一部分是无聊的阐述，第二部分才是真正有趣的地方。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;hui-gu&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#hui-gu&quot; aria-label=&quot;Anchor link for: hui-gu&quot;&gt;&lt;strong&gt;回顾&lt;&#x2F;strong&gt;&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;总结下，我讲过：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;澄清了术语，特别是&lt;strong&gt;将”流”（streaming）的定义限定为&lt;&#x2F;strong&gt;仅适用于执行引擎，而使用更加描述到位的术语如&lt;strong&gt;无限数据&lt;&#x2F;strong&gt;和&lt;strong&gt;近似&#x2F;推测结果&lt;&#x2F;strong&gt;这样不归属于流的范畴的概念。&lt;&#x2F;li&gt;
&lt;li&gt;评估了精心设计的批处理和流式系统的相对功能，假定&lt;strong&gt;流式处理事实上是批处理的严格超集&lt;&#x2F;strong&gt;，而像 Lambda 架构这样的概念（认为流式处理不如批处理）注定会随着流式处理的成熟而退役。&lt;&#x2F;li&gt;
&lt;li&gt;提出了流式系统赶超批处理系统所需的两个高阶概念，分别是&lt;strong&gt;正确性&lt;&#x2F;strong&gt;和&lt;strong&gt;时间推理工具&lt;&#x2F;strong&gt;。&lt;&#x2F;li&gt;
&lt;li&gt;分析了&lt;strong&gt;事件时间和处理时间&lt;&#x2F;strong&gt;之间的重要&lt;strong&gt;区别&lt;&#x2F;strong&gt;，介绍了在分析数据时&lt;strong&gt;这些差异所带来的困难&lt;&#x2F;strong&gt;，并&lt;strong&gt;提出了方法上的转变&lt;&#x2F;strong&gt;，&lt;strong&gt;从完整性的概念转向简单地适应数据随时间而变化&lt;&#x2F;strong&gt;。&lt;&#x2F;li&gt;
&lt;li&gt;研究了当今世界针对有限和无限数据，批处理和流式处理引擎常用的&lt;strong&gt;主要数据处理方法&lt;&#x2F;strong&gt;，一般将无限数据处理方法分为以下几种：&lt;strong&gt;时间无关&lt;&#x2F;strong&gt;、&lt;strong&gt;近似解&lt;&#x2F;strong&gt;、&lt;strong&gt;基于处理时间的窗口&lt;&#x2F;strong&gt;、&lt;strong&gt;基于事件时间的窗口&lt;&#x2F;strong&gt;。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;jie-xia-lai&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#jie-xia-lai&quot; aria-label=&quot;Anchor link for: jie-xia-lai&quot;&gt;&lt;strong&gt;接下来&lt;&#x2F;strong&gt;&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;本文为我在第二部分的具体案例做了铺垫，接下来将包含以下几点：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;将 Dataflow 模型中的数据处理概念分解为四块：&lt;strong&gt;what、where、when、how&lt;&#x2F;strong&gt;。&lt;&#x2F;li&gt;
&lt;li&gt;详细介绍&lt;strong&gt;在多个场景下处理简单、具体的数据集实例&lt;&#x2F;strong&gt;，重点介绍 Dataflow 模型所支持的多个用例，以及涉及到的具体 API。这些例子将有助于理解本文介绍的事件时间和处理时间的概念，另外将探索一些新概念，如水位线。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;对于现有的数据处理系统，比较&lt;&#x2F;strong&gt;这两篇文章中涉及到的一些重要特征，从而更容易从中作出选择，并改善其中的不足，我的终极目标是在整个大数据社区对于数据处理系统，尤其是流式系统的改善。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
    </entry>
    <entry xml:lang="en">
        <title>streaming102</title>
        <published>2021-03-02T00:00:00+00:00</published>
        <updated>2021-03-02T00:00:00+00:00</updated>
        <author>
          <name>Unknown</name>
        </author>
        <link rel="alternate" href="https://wendajiang.github.io/streaming102/" type="text/html"/>
        <id>https://wendajiang.github.io/streaming102/</id>
        <content type="html">&lt;p&gt;原文：https:&#x2F;&#x2F;www.oreilly.com&#x2F;radar&#x2F;the-world-beyond-batch-streaming-102&#x2F;&lt;&#x2F;p&gt;
&lt;p&gt;闲话少说，下面进入主题。先总结下，上次的内容主要分三块：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;术语&lt;&#x2F;strong&gt;，定义了我所谓的“流”（streaming）到底是什么意思。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;批与流&lt;&#x2F;strong&gt;，比较了这两种类型系统的理论功能，并提出了两个可以让流式系统超越批处理系统的概念：正确性和时间推理工具。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;数据处理模式&lt;&#x2F;strong&gt;，介绍了批处理和流式系统用于处理有限及无限数据的基本方法。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;本文中，将继续关注上次说的数据处理模式，而且通过具体实例来介绍细节。下面将本文主要分为两个部分：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;**Streaming 101 回顾：**简单回顾之前介绍的一些概念，并用一个实例来加以说明。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Streaming 102&lt;&#x2F;strong&gt;：作为上篇的配套教程，详细介绍了处理无限数据的其他概念，并继续用具体案例来解释。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;通过本文，您将掌握一个健壮的无序数据处理所需的核心原则和概念，同时拥有让您超越批处理的时间推理工具。&lt;&#x2F;p&gt;
&lt;p&gt;为了让您对于实现方式有个直观的认识，我将会使用 &lt;a href=&quot;https:&#x2F;&#x2F;link.zhihu.com&#x2F;?target=https%3A&#x2F;&#x2F;github.com&#x2F;GoogleCloudPlatform&#x2F;DataflowJavaSDK&quot;&gt;Dataflow SDK&lt;&#x2F;a&gt; 的代码片段（即 &lt;a href=&quot;https:&#x2F;&#x2F;link.zhihu.com&#x2F;?target=https%3A&#x2F;&#x2F;cloud.google.com&#x2F;dataflow&#x2F;&quot;&gt;Google Cloud Dataflow&lt;&#x2F;a&gt; 的 API），并辅以动画让这些概念可视化。我使用的是 Dataflow SDK 而不是人们所熟悉的 Spark Streaming 或者 Storm 等，原因在于还没有一个别的系统更加适合用于表达我想介绍的例子。不过好消息是有些项目正在朝着这个方向努力。更好的消息是，我们（谷歌）如今已经（联合 data Artisans、Cloudera、Talend 等公司）向 Apache 软件基金会提交了一份创建 Apache Dataflow 孵化项目的议案。希望围绕 &lt;a href=&quot;https:&#x2F;&#x2F;zhuanlan.zhihu.com&#x2F;p&#x2F;59876058&quot;&gt;Dataflow 模型&lt;&#x2F;a&gt; 提供的健壮的无序数据处理语义来构建一个开放的社区及生态。这让我很期待 2016 年。擦，跑题了。&lt;&#x2F;p&gt;
&lt;p&gt;不过这篇文章缺少了我上次承诺的比较部分。对不起，我低估了我所要将的内容究竟有多少，究竟要花多少时间。但是呢，我又不知道该把所拖延的和该拓展的内容放在哪里。如果能安慰您的话呢，其实我在2015年的新加坡的 Strata + Hadoop World 做了一个演讲，题目是“&lt;a href=&quot;https:&#x2F;&#x2F;link.zhihu.com&#x2F;?target=http%3A&#x2F;&#x2F;conferences.oreilly.com&#x2F;strata&#x2F;big-data-conference-sg-2015&#x2F;public&#x2F;schedule&#x2F;detail&#x2F;44947&quot;&gt;大规模数据处理的演进&lt;&#x2F;a&gt;”（2016年会在伦敦的 Strata + Hadoop World 做一个更新版本的演讲），其中涵盖了一些我之前想做的承诺的部分；&lt;a href=&quot;https:&#x2F;&#x2F;link.zhihu.com&#x2F;?target=http%3A&#x2F;&#x2F;goo.gl&#x2F;5k0xaL&quot;&gt;这里&lt;&#x2F;a&gt;有当时的 PPT。虽然不是完全一样，但是值得一读。&lt;&#x2F;p&gt;
&lt;p&gt;好，现在我们开始看“流”。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;hui-gu-yu-lu-xian-tu&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#hui-gu-yu-lu-xian-tu&quot; aria-label=&quot;Anchor link for: hui-gu-yu-lu-xian-tu&quot;&gt;回顾与路线图&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;在Streaming 101中，首先澄清了一些术语,介绍了&lt;strong&gt;有限数据&lt;&#x2F;strong&gt; VS &lt;strong&gt;无限数据&lt;&#x2F;strong&gt;。有限数据源具有有限的大小，通常被称为“批处理”数据。无限数据源具有无限大小，通常被称为“流”数据。在后边将会尽量避免使用批处理和流式来修饰数据源，因为这些名称有其局限性并容易让人误解。&lt;&#x2F;p&gt;
&lt;p&gt;然后，解释了&lt;strong&gt;批处理&lt;&#x2F;strong&gt;和&lt;strong&gt;流式处理&lt;&#x2F;strong&gt;引擎之间的区别：批处理引擎是设计优先考虑有限数据（现在批处理引擎也提供了micro-batch的方式处理流式数据），而流式处理引擎设计用于处理无限数据。我只会在描述执行引擎时使用批处理和流式处理。&lt;&#x2F;p&gt;
&lt;p&gt;定义完术语之后，介绍了与处理无限数据有关的两个重要的基本概念。首先阐述&lt;strong&gt;事件时间&lt;&#x2F;strong&gt;（事件发生的时间）&lt;strong&gt;和处理时间&lt;&#x2F;strong&gt;（数据在系统中被处理的时间）&lt;strong&gt;之间的关键区别&lt;&#x2F;strong&gt;。这为Streaming 101中提出的主要论文提供了基础：如果关心事件实际发生时间，则必须基于事件的事件时间，而不是处理时间。&lt;&#x2F;p&gt;
&lt;p&gt;接下来介绍了&lt;strong&gt;窗口&lt;&#x2F;strong&gt;的概念（即沿时间边界切分数据集），这是一种常用的方法，用于应对无限数据源的数据处理，无限数据源理论上永远不会结束。窗口策略的最常见且简单的例子是固定和滑动的窗口，更复杂的窗口类型，例如会话窗口（其中窗口由数据本身的特征决定，捕获每个用户的活动会话窗口，会话窗口之后紧接着是用户的不活动期）也比较广泛的用法。&lt;&#x2F;p&gt;
&lt;p&gt;除了前文中介绍的概念，现在再介绍3个新的概念：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;**水位线：**水位线是相对于事件时间的输入完整性的概念。水位线表示一个时间 X，表示所有事件时间 &amp;lt;X 的所有数据都到齐了。因此，当处理无限数据源时，水位线可以作为进度的度量。&lt;&#x2F;li&gt;
&lt;li&gt;**触发器：**触发器是一种由外部条件触发、表明何时计算窗口结果的机制。触发器可以让我们灵活的选择何时计算结果并发送给下游，而且随着数据的不停的到来，窗口可以产生多次输出。所以，窗口结束前可以先提供近似结果，并且能够灵活应对上游数据的变化（可能是上游发送的数据修正）或者数据延迟到达（例如，移动场景在某人的离线时，某人的电话记录了各种动作及其事件时间，然后在重新获得连接时继续上传这些事件进行处理）。&lt;&#x2F;li&gt;
&lt;li&gt;**累积：**累积模式指定在同一窗口中观察到的多个结果之间的关系。这些结果可能完全相互之间完全独立，或者它们之间可能存在重叠。不同的累积模式具有不同的语义和与计算成本，适用于不同的场景。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;最后，在回答无限数据处理中的4个问题时，更容易搞清楚这些概念和它们之间的关联关系：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;**What****计算的结果是什么？**这个由 Pipeline 中的转换来决定。例如计算总和、构建直方图、训练机器学习模型等等。它也是经典批处理需要回答的问题。&lt;&#x2F;li&gt;
&lt;li&gt;**Where****在事件时间中的哪个位置计算结果？**这个一般由在 Pipeline 中使用事件时间窗口来决定。这包括从Streaming 101（固定，滑动和会话）窗口的常见示例，和一些貌似没有窗口概念的用例（例如Streaming 101中的时间无关的处理；经典批处理也通常属于此类）以及其他更复杂的窗口类型，如限时拍卖。此外，如果在记录到达系统时将入口时间指定为事件时间，还可以包括处理时间窗口。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;When&lt;&#x2F;strong&gt; 在处理时间中的哪个时刻触发计算结果？我们通过使用水位线和触发器来回答的这个问题。这里的场景比较多样，但最常见的模式是在给定窗口的输入完成时使用水位线来描绘，触发器允许提前计算结果（对于在窗口完成之前发出的推测性的、部分的结果）和延迟计算结果（水位线只是预估窗口的数据全部到达,并不是100%确定，在水位线声明给定窗口的全部到达之后，也有可能会有隶属于该窗口的数据到达）。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;How&lt;&#x2F;strong&gt; 如何修正结果？这个问题由所使用的累积类型回答：&lt;strong&gt;丢弃&lt;&#x2F;strong&gt;（其中结果是相互独立和不同的），&lt;strong&gt;累积&lt;&#x2F;strong&gt;（后来的结果建立在先前的结果上），&lt;strong&gt;累积和撤回&lt;&#x2F;strong&gt;（当前的累积值和上次触发的值撤回一起发送）。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;后边将一一讨论这些问题，试图让大量清楚哪些概念与&lt;strong&gt;What&lt;&#x2F;strong&gt;&#x2F;&lt;strong&gt;Where&lt;&#x2F;strong&gt;&#x2F;&lt;strong&gt;When&lt;&#x2F;strong&gt;&#x2F;&lt;strong&gt;How&lt;&#x2F;strong&gt;中的哪个问题有关。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;streaming-101-hui-gu&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#streaming-101-hui-gu&quot; aria-label=&quot;Anchor link for: streaming-101-hui-gu&quot;&gt;Streaming 101 回顾&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;首先，回顾一下Streaming 101中提出的一些概念，这一次还将提供一些具体的例子使这些概念更具体。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;what-bian-huan&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#what-bian-huan&quot; aria-label=&quot;Anchor link for: what-bian-huan&quot;&gt;What: 变换&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;经典批处理中 Transform 解决了以下问题：“&lt;strong&gt;要计算什么结果？&lt;&#x2F;strong&gt;”许多人可能已经熟悉经典的批处理，所以我们将以它为基础，加入其他概念，以便于理解。&lt;&#x2F;p&gt;
&lt;p&gt;对于这一部分，我们来看一个示例：计算由10个整数值组成的简单数据集的总和。这么说有点抽象，在实际中，可以想象一个游戏，10个人组成一个团队，每个人的最终得分相加，就是团队的成绩。也可以想象计费和使用情况的监控使用情况这样的场景。&lt;&#x2F;p&gt;
&lt;p&gt;对于每个示例，将包括一个简短的 Dataflow Java SDK 伪代码片段，以使 Pipeline 的定义更具体。因为是伪代码，所以有时会省略细节（如使用具体的I &#x2F; O源）、使用简称（Java中的当前触发器名称太冗长）。除了这些（大部分我在 &lt;a href=&quot;https:&#x2F;&#x2F;link.zhihu.com&#x2F;?target=https%3A&#x2F;&#x2F;www.oreilly.com&#x2F;ideas&#x2F;the-world-beyond-batch-streaming-102%23PS&quot;&gt;Postscript&lt;&#x2F;a&gt; 中明确列举）的小事情之外，其它基本上是真实的 Dataflow SDK代码。稍后还将提供一个链接到实际的代码演练，可以编译和运行自己的类似例子感兴趣的人，可以实际尝试一下。&lt;&#x2F;p&gt;
&lt;p&gt;如果熟悉像 Spark Streaming 或 Flink 这样的计算引擎，那么在看 Dataflow 示例代码的时候就会容易一些。接下来开始让人崩溃的旅程，在Dataflow中有两个基本的原语：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;PCollection，表示可能要执行并行转换（因此以“P”打头）的数据集。&lt;&#x2F;li&gt;
&lt;li&gt;PTransform，处理 PCollection 并创建新的 PCollection。PTransform 可以执行元素转换，它们可以将多个元素聚合在一起，或者它们可以是其他 PTransform 的组合。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;v2-76788cf66e79c8422fb72034b9bc854f_720w.jpg&quot; alt=&quot;img&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;center&gt;图1. 转换类型&lt;&#x2F;center&gt;
&lt;p&gt;如果觉得不甚明白或者想刨根问底，可以看看 &lt;a href=&quot;https:&#x2F;&#x2F;link.zhihu.com&#x2F;?target=https%3A&#x2F;&#x2F;cloud.google.com&#x2F;dataflow&#x2F;model&#x2F;programming-model&quot;&gt;Google Dataflow Java SDK 文档&lt;&#x2F;a&gt;。&lt;&#x2F;p&gt;
&lt;p&gt;为了对例子说明，假设我们从一个 PCollection&amp;lt;KV&amp;lt;String，Integer&amp;gt;&amp;gt;命名为“input”（即由一个键&#x2F;值对的字符串和整数组成的 PCollection，其中字符串是类似团队名称，整数是相应团队中个人的得分）。在现实世界的 Pipeline 中，通过从 I&#x2F;O 源读取 PCollection 原始数据（例如日志记录）获得输入，将日志记录解析为适当的键&#x2F;值对，然后将其转换为 PCollection&amp;lt;KV&amp;lt;String，Integer&amp;gt;&amp;gt; 。为了在第一个例子中清楚起见，将包括所有这些步骤的伪代码，但是在随后的例子中，删除了 I&#x2F;O 和解析部分。&lt;&#x2F;p&gt;
&lt;p&gt;因此，对于简单地从 I&#x2F;O 源读取数据的管道，解析出团队&#x2F;分数键值对，并计算每队的得分数，代码如下：&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;PCollection&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;String&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt; raw &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;IO&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;read&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;...&lt;&#x2F;span&gt;&lt;span&gt;);
&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;PCollection&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;KV&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;String&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Integer&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;gt; input &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; raw&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;ParDo&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;of&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;new &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;ParseFn&lt;&#x2F;span&gt;&lt;span&gt;())&lt;&#x2F;span&gt;&lt;span style=&quot;background-color:#ff79c6;color:#f8f8f0;&quot;&gt;;&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;PCollection&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;KV&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;String&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Integer&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;gt; scores &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; input
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Sum&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;integersPerKey&lt;&#x2F;span&gt;&lt;span&gt;());
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;清单1. 计算总和的 Pipeline&lt;&#x2F;p&gt;
&lt;p&gt;从数据源读取键值对数据，键是String类型(团队名称)，值是Integer类型（团队中各人得分）。然后对每个键(团队)计算总和(团队得分)，并输出。&lt;&#x2F;p&gt;
&lt;p&gt;对于所有的示例，在每个示例的 Pipeline 的代码片段之后，有1个该Pipeline执行的动画示例。动画中看到一个 Key（即一个团队）的10条输入数据执行Pipeline的样子；在一个实际的Pipeline 中，类似的操作将有成千上万个，在很多台机器上并行执行。为了能清晰的说明，示例中演示了1个Key的执行过程。&lt;&#x2F;p&gt;
&lt;p&gt;动画中每个点代表一个输入或输出数据，输入和输出都有两个时间维度：事件时间（X轴）和处理时间（Y轴）。因此，Pipeline 按照处理时间维度执行，从下向上延伸，如加粗的上升白线所示。输入是圆圈，圆圈内的数字代表该特定记录的值。输入开始是灰色圆圈，随着Pipeline处理变换颜色。&lt;&#x2F;p&gt;
&lt;p&gt;当 Pipeline 处理到某一个值的时候，会将其累加并记录在 State 中，并最终将聚合结果作为输出。State和输出由矩形表示，矩形顶部不断变化的数字表示累加值，矩形覆盖的区域表示到当前处理时刻，所有矩形中的数据已经被处理。对于清单1中的 Pipeline，在经典批处理引擎上执行时，会看起来像这样（请注意，点击下面的图片启动动画，然后会一直循环播放）：&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;image-20200924163454383.png&quot; alt=&quot;image-20200924163454383&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;center&gt;图2. 经典的批处理&lt;&#x2F;center&gt;
&lt;p&gt;上边是在批处理引擎上执行Pipeline，累加输入的数据，直到所有输入处理完毕（由顶部的虚线绿色线表示），此时输出为51。在此示例中，因为没有应用任何特定的窗口，所以在事件时间维度上计算了整个数据集的总和；因此，用于累加的State和输出的矩形覆盖X轴的整体。但是，如果要处理一个无限数据源，那么经典批处理将是不够的，不能等待输入结束，因为它实际上永远不会结束。所以需要的使用在Streaming 101中提到的一个概念是---窗口。因此，想要回答第二个问题“在事件时间的哪个位置计算结果？”，现在先简要回顾一下窗口。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;where-chuang-kou&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#where-chuang-kou&quot; aria-label=&quot;Anchor link for: where-chuang-kou&quot;&gt;Where: 窗口&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;窗口是把数据在时间上进行切分。常见的窗口策略有：固定窗口、滑动窗口、会话窗口。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;v2-0654171e5af72b5ff6a71906589116e6_720w.jpg&quot; alt=&quot;img&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;center&gt;图3. 窗口策略&lt;&#x2F;center&gt;
&lt;p&gt;为了更好地了解实际中的如何使用窗口，来看一下的上边提到的整数求和Pipeline，使用了长度为2分钟的时间窗口。使用 Dataflow SDK，只需要简单的添加 Window.into 转换即可（下面代码中的第二行）：&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;PCollection&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;KV&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;String&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Integer&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;gt; scores &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; input
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Window&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;into&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;FixedWindows&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;of&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Duration&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;standardMinutes&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt;))))
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Sum&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;integersPerKey&lt;&#x2F;span&gt;&lt;span&gt;());
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;清单2. 使用窗口的求和代码&lt;&#x2F;p&gt;
&lt;p&gt;回想一下，Dataflow提供了一种统一的批处理和流式处理模型，因为语义上，批处理只是流式处理的一个子集。因此，首先在批处理引擎上执行此Pipeline；在批处理引擎上执行此Pipeline，原理简单明了，可以很好的跟在流式处理引擎上执行做对比。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;image-20200924163551278.png&quot; alt=&quot;image-20200924163551278&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;center&gt;图4. 批处理上窗口的求和&lt;&#x2F;center&gt;
&lt;p&gt;如前所述，输入在不断累加存储在State中，直到输入被完全处理，然后产生输出。然而，在这种情况下，不是1个输出，而是4个：在时间上切分成了4个事件时间窗口，每个窗口产生一个输出。&lt;&#x2F;p&gt;
&lt;p&gt;到此为止，我们重新回顾了Streaming 101中引入的两个主要概念：事件时间和处理时间之间的关系以及窗口。再进一步，开始阐述本节开头提到的新概念：水位线，触发器和累积。下边开始Streaming 102。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;streaming-102&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#streaming-102&quot; aria-label=&quot;Anchor link for: streaming-102&quot;&gt;Streaming 102&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;在上边我们看到了在批引擎上执行使用了窗口的Pipeline。理想情况下，我们希望具有较低的处理延迟，同时也希望能涵盖对无限数据集的处理。切换到流式引擎是朝着正确方向迈出的一步。批处理引擎可以明确的知道，每个窗口的数据是否完整了（即，有限数据集中所有的数据都被处理了），但目前缺乏确定无限数据集的完整性的实用方法。接下来介绍水位线。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;when-shui-wei-xian&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#when-shui-wei-xian&quot; aria-label=&quot;Anchor link for: when-shui-wei-xian&quot;&gt;When: 水位线&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;水位线是问题答案的前半部分：“在处理时间的什么时候计算窗口的结果？” 水位线是事件时间中输入完整性的时间概念。换句话说，它们是系统根据当前处理的数据的事件时间判断处理进度和完整性的方法（有限或无限数据集，在无限数据的情况下作用更为明显）。&lt;&#x2F;p&gt;
&lt;p&gt;回想一下 Streaming 101 中这个图，这里稍作修改，其中描述了事件时间和处理时间之间的偏差，现实中大多数的分布式数据处理系统中的时间偏差一直在变化。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;pic1.zhimg.com&#x2F;80&#x2F;v2-b61ac0f238531c03156474d0a14661a2_720w.jpg&quot; alt=&quot;img&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;center&gt;图5. 事件时间进度、偏差、水位线&lt;&#x2F;center&gt;
&lt;p&gt;图中表示现实（reality）的红色曲线本质上是水位线。随着处理时间的推移，它跟踪事件时间完整性的进度。在概念上，可以将水位线视为函数 F(P) -&amp;gt; E，在处理时间中选取一个点，返回事件时间的一个点。（更准确地说，对函数的输入实际上是在 Pipeline 中观察到水位线的点上游的一切的当前状态：输入源，缓冲数据，正在处理的数据等；但在概念上，将其视为从处理时间到事件时间的映射更简单。）在事件时间点 E 上系统会认为事件时间小于 E 的所有数据都到齐了。换句话说，这是一个断言，不再有事件时间小于 E 的数据。根据水位线的类型：完美的或启发式的，这种断言可能是严格的保证或者经过训练的估计：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;**理想的水位线：**在完全了解所有输入数据的情况下，可以构建理想的水位线；在这种情况下，没有延迟数据；所有数据都提前或准时到达。&lt;&#x2F;li&gt;
&lt;li&gt;**启发式水位线：**对于许多分布式输入源，完全了解输入数据是不切实际的，在这种情况下，最佳选择是提供。启发式的水位线使用任何有关输入的信息（分区，分区内排序，文件增长率等），以提供尽可能准确的进度估计。在许多情况下，启发式水位线可以预测的非常准确。即使如此，使用启发式水位线意味着它有时可能是不正确的的，这将导致有些数据被划分为延迟数据。我们将在下面的触发器部分中了解如何处理延迟数据。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;水位线是一个有趣和复杂的话题，未来会写一篇新的文章专门阐述。现在，为了更好地了解水位线的作用以及缺点，我们来看一下使用水位线的流式处理引擎的两个例子，以确定何时在清单2中执行使用窗口的Pipeline时实现输出。左边的例子使用理想的水位线；右边的一个使用启发式水位线。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;image-20200924163653862.png&quot; alt=&quot;image-20200924163653862&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;center&gt;图6. 理想的与推测的水位线&lt;&#x2F;center&gt;
&lt;p&gt;在这两种情况下，当水位线通过窗口的末尾时，窗口被触发计算。两个执行的主要区别在于右侧的水位线计算中使用的启发式算法，值9因为迟到的问题而没有被计算在内，这大大改变了水位的形状[3]。这些例子突出了水位线的两个缺点：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;太慢&lt;&#x2F;strong&gt;：当任何类型的水位线，由于已知的未处理数据（例如，由于网络带宽约束而缓慢增长的输入日志）被正确地延迟时，如果结果的计算只依赖水位线的触发，将直接导致输出结果的延迟。&lt;&#x2F;p&gt;
&lt;p&gt;这在左图中是最明显的，即迟到的9阻止所有后续窗口的水位线，即使这些窗口的输入数据已经更早的达到并且是完整的了。第二个窗口[12:02，12:04]尤其明显，从窗口中的第一个值到达到窗口计算并输出结果的时间需要将近七分钟。这个例子中的启发式水位线要稍微好一点（五分钟直到输出），但这不意味着启发式水位线从来不会受到其他水位线滞后的影响；在本例子选择了特殊的数据突出了这种对比。&lt;&#x2F;p&gt;
&lt;p&gt;这里的重点在于：水位线提供了一个非常有用的完整性概念，从延迟的角度来看，只考虑完整性是不够的。想象一下一个仪表板，显示重要的指标，按小时或天显示。我们不太可能想等待一整个小时或一天才能查看当前窗口的结果；这是使用经典批处理系统为这种系统提供数据的痛点之一。相反，随着输入的演变和最终的完成，这些窗口的结果会随着时间的推移而持续并不断的更新更好一些。&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;**太快：**当一个启发式水位线比实际的水位线更快的向前推进时，会导致原来没有延迟的数据变成了延迟数据。这是在右边的例子中发生的情况：在第1个窗口的输入数据全部到达之前，水位线进入第1个窗口的末尾，导致错误的输出值为5而不是14。这个缺点是严格的启发式水位线的问题；既然是启发式就意味着有时会是错误的。因此，如果关心正确性，单纯依靠水位线确定何时计算结果并发出是不够的。&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;在Streaming 101中，对关于无限数据流的强大的无序处理不足的完整性概念作了一些强调。水位线太慢或太快，是这些论据的基础。完全依赖于完整性概念的系统无法同时获得低延迟和正确性。触发器是解决这些缺点解决方案。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;when-hong-fa-qi-de-wei-da-zhi-chu-jiu-zai-yu-hong-fa-qi-ben-shen-hen-wei-da&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#when-hong-fa-qi-de-wei-da-zhi-chu-jiu-zai-yu-hong-fa-qi-ben-shen-hen-wei-da&quot; aria-label=&quot;Anchor link for: when-hong-fa-qi-de-wei-da-zhi-chu-jiu-zai-yu-hong-fa-qi-ben-shen-hen-wei-da&quot;&gt;When**: 触发器的伟大之处就在于触发器本身很伟大**&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;触发器是问题的另一半答案：“&lt;strong&gt;在处理时间的什么时候该计算窗口的结果并发出？&lt;&#x2F;strong&gt;”触发器用来表明在处理时间的什么适合该计算窗口的结果（尽管触发器本身可能会根据其他时间触发，例如在事件时间维度上使用水位线）。窗口的每个特定输出都称为窗口的窗格（&lt;em&gt;pane&lt;&#x2F;em&gt;）。&lt;&#x2F;p&gt;
&lt;p&gt;用于触发的信号的示例包括：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;水位线进度（即事件时间进度）&lt;&#x2F;strong&gt;，是图6中我们已经看到的隐式版本，当水位线通过窗口的末尾时，计算结果并输出[4]。另一个用例是在窗口生命周期的末尾时触发垃圾回收，稍后我们将看到一个例子。&lt;&#x2F;li&gt;
&lt;li&gt;**处理时间进度，**可以用于提供固定的周期更新，因为处理时间（不像事件时间）总是均匀地，没有延迟地进行。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;元素计数&lt;&#x2F;strong&gt;，可以用于在窗口积累固定数量的元素后触发。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;带标记的，或其他数据依赖触发器&lt;&#x2F;strong&gt;，即记录或记录的特性（例如，EOF元素或刷新事件）意味着需要产生输出的地方。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;除了基于具体信号触发的简单触发器之外，还有复合触发器，允许创建更复杂的触发逻辑。还有些复合触发器：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;重复触发器&lt;&#x2F;strong&gt;，重复触发器特别适用于处理时间触发器以提供定期更新。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;AND 触发&lt;&#x2F;strong&gt;器（逻辑AND），所有子触发器都符合触发条件才触发（例如，在水位线通过窗口结束之后，我们观察到一个终止的标记记录），它才会触发。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Or 触发器&lt;&#x2F;strong&gt;（逻辑或），子触发器中的任何一个符合触发条件都会引起触发（例如，在水位线通过窗口结束之后或我们观察到终止的标记记录）时。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;序列触发器&lt;&#x2F;strong&gt;，以子触发器按照预定义的顺序触发子依次触发。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;为了使触发器的概念更具体，继续介绍图6中使用的隐式默认触发器，将其添加到清单2中的代码中：&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;PCollection&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;KV&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;String&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Integer&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;gt; scores &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; input
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Window&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;into&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;FixedWindows&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;of&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Duration&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;standardMinutes&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt;)))
&lt;&#x2F;span&gt;&lt;span&gt;               &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;triggering&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;AtWatermark&lt;&#x2F;span&gt;&lt;span&gt;()))
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Sum&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;integersPerKey&lt;&#x2F;span&gt;&lt;span&gt;());
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;清单3. 显式设定默认触发器&lt;&#x2F;p&gt;
&lt;p&gt;对触发器能够做什么有了基本的了解，可以开始考虑解决水位线太慢或太快的问题。在这两种情况下，我们希望在水位线超过窗口末尾之前或之后能够有机会计算窗口的结果，并能够提供持续更新的机制（除了水位线超过窗口末尾那一刻）。所以，需要一些多次触发触发器。那么问题就变成了：多次触发用来干什么？&lt;&#x2F;p&gt;
&lt;p&gt;在&lt;strong&gt;太慢&lt;&#x2F;strong&gt;的情况下（即提供提前的推测结果），我们可能应该假设任何给定的窗口可能有稳定的输入数据，因为我们知道（通过窗口的早期阶段），我们观察到的这个窗口的输入是非常不完整的。因此，当处理时间提前（例如，每分钟一次）时周期性地触发可能是明智的，因为触发发射的数量将不依赖于实际观察到的窗口的数据量；在最坏的情况下，我们只会得到稳定的定期触发发射。&lt;&#x2F;p&gt;
&lt;p&gt;在&lt;strong&gt;太快&lt;&#x2F;strong&gt;的情况下（即，由于启发式水位线可能存在错误的推测，所以需要一种机制去能够处理延时数据去修正计算结果），假设水位线基于相对准确的启发式（通常是相当安全的假设）。在这种情况下，预计不会经常看到延迟很久的数据，但是在实际中确实存在挺多延迟数据，不过结果很快会得到修正。每收到1个延时数据触发一次的策略，能够让我们更快的修正更新计算结果，但是由于预期的后期数据不频繁，应该不会给系统带来大的冲击。请注意，这些只是示例：如果有不同的应用场景，可以自由选择不同的触发器（或选择不适用触发器）。&lt;&#x2F;p&gt;
&lt;p&gt;最后，我们需要协调这些各种触发器的时间安排：提前，准时和延迟。我们可以使用Sequence 触发器和一个特殊的 OrFinally 触发器组合来实现，OrFinally触发器用来中止这个组合触发器。&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;PCollection&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;KV&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;String&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Integer&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;gt; scores &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; input
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Window&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;into&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;FixedWindows&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;of&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Duration&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;standardMinutes&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt;)))
&lt;&#x2F;span&gt;&lt;span&gt;               &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;triggering&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Sequence&lt;&#x2F;span&gt;&lt;span&gt;(
&lt;&#x2F;span&gt;&lt;span&gt;                 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Repeat&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;AtPeriod&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Duration&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;standardMinutes&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;)))
&lt;&#x2F;span&gt;&lt;span&gt;                   &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;OrFinally&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;AtWatermark&lt;&#x2F;span&gt;&lt;span&gt;()),
&lt;&#x2F;span&gt;&lt;span&gt;                 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Repeat&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;AtCount&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;))))
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Sum&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;integersPerKey&lt;&#x2F;span&gt;&lt;span&gt;())&lt;&#x2F;span&gt;&lt;span style=&quot;background-color:#ff79c6;color:#f8f8f0;&quot;&gt;;&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;清单4. 手动设定提前和推迟触发&lt;&#x2F;p&gt;
&lt;p&gt;如上所示，伪代码看起来不错，给出了提前、准时、延迟触发的常用模式，对应在 Dataflow 中，提供了一个定制（但语义上相当的）API，使得更容易使用这样的触发器，如下所示：&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;PCollection&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;KV&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;String&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Integer&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;gt; scores &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; input
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Window&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;into&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;FixedWindows&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;of&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Duration&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;standardMinutes&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt;)))
&lt;&#x2F;span&gt;&lt;span&gt;               &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;triggering&lt;&#x2F;span&gt;&lt;span&gt;(
&lt;&#x2F;span&gt;&lt;span&gt;                 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;AtWatermark&lt;&#x2F;span&gt;&lt;span&gt;()
&lt;&#x2F;span&gt;&lt;span&gt;                   &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;withEarlyFirings&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;AtPeriod&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Duration&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;standardMinutes&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;)))
&lt;&#x2F;span&gt;&lt;span&gt;                   &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;withLateFirings&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;AtCount&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;))))
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Sum&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;integersPerKey&lt;&#x2F;span&gt;&lt;span&gt;());
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;清单5. 使用early&#x2F;late api指定提前和延迟触发&lt;&#x2F;p&gt;
&lt;p&gt;在流式处理引擎上执行清单4 或清单5 中的示例（包含了理想的水位线和启发式的Watermak），如下所示：&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;image-20200924163747760.png&quot; alt=&quot;image-20200924163747760&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;center&gt;图7. 提前和延迟触发&lt;&#x2F;center&gt;
&lt;p&gt;这个版本对图6 有两个明显的改进：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;对于第二个窗口中的“&lt;strong&gt;水位线太慢&lt;&#x2F;strong&gt;”的情况，[12:02, 12:04]：我们现在每分钟提供一次定期的提前计算。在理想的水位线案例中，差异最为突出，其中时间到首次输出从近7分钟降至3分半；在启发式案例中也有明显改善。这两个版本现在都可以随着时间的推移而稳定地进行计算和修正计算结果（具有值7,14，然后是22的窗格），降低了从数据输入到得到计算结果之间的延迟。&lt;&#x2F;li&gt;
&lt;li&gt;对于第一个窗口中的“&lt;strong&gt;启发式水位线太快&lt;&#x2F;strong&gt;”的情况，[12:00, 12:02]：当9的值延迟到达时，立即将其合并到一个值为14的新的修正的窗格中。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;这些新触发器的一个有趣的副作用是，它们有效地使理想和启发式水位线版本之间的输出模式标准化。而图6 中的两个版本是截然不同的，而现在这两个版本看起来很相似。&lt;&#x2F;p&gt;
&lt;p&gt;此时剩下的最大差异是窗口生命周期。在理想的水位线案例中，当水位线超过窗口末尾后，窗口过期，窗口中的数据再也不会被处理，可以被安全的回收。在启发式水位线案例中，我们仍然需要保留窗口一段时间来处理延迟数据。但是到目前为止，系统没有任何好的方式知道每个窗口需要保留多长时间。这是最大允许延迟的用武之地。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;when-zui-da-yun-xu-yan-chi-chao-guo-ji-ke-hui-shou&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#when-zui-da-yun-xu-yan-chi-chao-guo-ji-ke-hui-shou&quot; aria-label=&quot;Anchor link for: when-zui-da-yun-xu-yan-chi-chao-guo-ji-ke-hui-shou&quot;&gt;When: 最大允许延迟（超过即可回收）&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;在谈到最后一个问题（“&lt;strong&gt;如何修正结果？&lt;&#x2F;strong&gt;”）之前，先来聊一下持续运行、乱序数据流式处理系统中的实际面对的问题：垃圾收集。在图7 中的启发式水位线示例中，每个窗口的持续状态在该示例的整个生命周期内都会持续；这是必要的，以便在到达时适当地处理延迟数据。但是，尽管能够保留所有持续状态，直到数据全部处理完毕。实际上，当处理无限数据源时，一直保留给定窗口的状态（包括元数据）通常是不切实际；最终会耗尽内存、磁盘等的空间。&lt;&#x2F;p&gt;
&lt;p&gt;因此，任何现实世界的无序处理系统都需要提供一些限制其正在处理的窗口的生命周期的方法。最简洁的实现方在系统内定义一个最大允许延迟的边界，即限制任何给定记录最晚到达时间（相对于水位线时间）不能超过这个时间；任何超过这个时间的数据不再处理，直接丢弃掉。定义了最大允许延迟之后，还需要准确地确定窗口需要保留的时间：直到水位线超过了窗口的末尾时间+最大允许延迟时间[5]。允许系统丢弃超过最大延迟的数据，还能够节省系统的计算资源。&lt;&#x2F;p&gt;
&lt;p&gt;由于最大允许延迟和水位线之间的相互作用有点晦涩，举个例子说明一下。我们来看一下清单5 &#x2F;图7中的启发式水位线 Pipeline，并添加1分钟的最大允许延迟时间（请注意，之所以选择1分钟是为了更好的在图中说明概念，在现实世界中需要根据场景来确定合理的最大允许延迟时间）：&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;PCollection&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;KV&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;String&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Integer&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;gt; scores &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; input
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Window&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;into&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;FixedWindows&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;of&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Duration&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;standardMinutes&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt;)))
&lt;&#x2F;span&gt;&lt;span&gt;               &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;triggering&lt;&#x2F;span&gt;&lt;span&gt;(
&lt;&#x2F;span&gt;&lt;span&gt;                 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;AtWatermark&lt;&#x2F;span&gt;&lt;span&gt;()
&lt;&#x2F;span&gt;&lt;span&gt;                   &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;withEarlyFirings&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;AtPeriod&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Duration&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;standardMinutes&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;)))
&lt;&#x2F;span&gt;&lt;span&gt;                   &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;withLateFirings&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;AtCount&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;)))
&lt;&#x2F;span&gt;&lt;span&gt;               &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;withAllowedLateness&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Duration&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;standardMinutes&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;)))
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Sum&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;integersPerKey&lt;&#x2F;span&gt;&lt;span&gt;());
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;清单6. 带有最大允许延迟的提前和延迟触发&lt;&#x2F;p&gt;
&lt;p&gt;这个Pipeline的执行看起来像下面的图8所示，添加了以下功能来突出显示允许的延迟效应：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;加粗的水平方向的白线表示当前的处理时间，注释为Lateness Horizon的小刻度表示窗口的最大延时线（事件时间）。&lt;&#x2F;li&gt;
&lt;li&gt;一旦水位线超过窗口的最大延迟线，该窗口将被回收，这意味着窗口的所有信息都将被销毁。&lt;&#x2F;li&gt;
&lt;li&gt;虚线的矩形，表示窗口关闭时窗口覆盖的时间范围（在处理时间和事件时间两个维度上），一个小尾巴向右延伸，以表示窗口的延迟水平（与水位线对照）。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;在这个图中，为第一个窗口添加了一个额外的延迟数据6。6相对窗口是迟到的，但仍然在允许的最大延迟时间范围内，所以6被累加修正计算结果为11。然而，9 超过了最大允许延迟，直接被丢弃掉。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;image-20200924163828993.png&quot; alt=&quot;image-20200924163828993&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;center&gt;图8. 提前和推迟触发及允许延迟&lt;&#x2F;center&gt;
&lt;p&gt;关于最大迟延线的两个最后的说明：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;显然，如果从能够提供理想的水位线的资源中获取数据，则无需处理延迟数据，而0秒的最大延迟时间将是最佳的。这是我们在图7 的理想水位线部分中看到的。&lt;&#x2F;li&gt;
&lt;li&gt;有一些例外情况不需要指定最大延迟，即使在使用启发式的水位线时，比如在数据覆盖的时间的范围内，对有限的key进行统计，（例如，数据覆盖的时间的范围内内，按照Web浏览器分组，统计网站的总访问次数）。在这种情况下，系统中活动窗口的数量受限于使用的Key的数量。只要Key的数量仍然很低，就无须通过设置最大允许的延迟时间来限制窗口的生命周期。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;接下来继续讨论第4个也是最后一个问题。&lt;&#x2F;p&gt;
&lt;h3 id=&quot;how-lei-ji&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#how-lei-ji&quot; aria-label=&quot;Anchor link for: how-lei-ji&quot;&gt;How: 累积&lt;&#x2F;a&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;随着时间推移，触发器被用于为一个窗口生成多个窗格，我们发现自己面临最后一个问题：“如何随着时间修正结果？”在我们已经看到的例子中，每个窗格建立在其前一个窗格基础之上。然而，实际上有三种不同的累积方式[6]：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;丢弃&lt;&#x2F;strong&gt;：每当窗格计算完毕时，任何存储的窗口状态都将被丢弃。这意味着每个窗格与之前的窗格都是相互独立的。当下游消费者本身正在执行某种累计时，例如当将整数发送到希望自己计算总和的系统时，丢弃模式是有用的，下游系统将数据累积在一起形成最后的结果。&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;累积&lt;&#x2F;strong&gt;：如图7所示，每当窗格计算完毕时，保留该窗格所有的状态，未来输入的数据会累积到并更新现有状态。这意味着窗格是建立在前面窗格的基础之上的。以后的结果可以简单地覆盖以前的结果，例如在诸如BigTable或HBase的键&#x2F;值存储中存储输出结果时，累积模式很有用。&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;累积和撤回&lt;&#x2F;strong&gt;：和累积模式一样，但是当生成新窗格时，同时会为前一个窗格生成1个独立的撤回。撤回（与新的累积结果一起）本质上是在表达，“我以前告诉过你的结果是X，但我错了。撤回我上次告诉你的X，并将其替换为Y.“有两种情况，撤回是特别有用的：&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;当下游消费者将不同维度的数据重新分组时，新值可能会与先前的值不同，因此最终会在不同的组中。在这种情况下，新值不能简单的覆盖旧值；需要从旧组中删除旧值，然后将新值添加到新组中。&lt;&#x2F;li&gt;
&lt;li&gt;当使用动态窗口（例如，后边会有更详细的介绍）时，由于窗口合并，新值可能会替换多个旧窗口。在这种情况下，只从新窗口的信息中难以确定哪些旧窗口中需要撤回。对于旧的窗口进行明确的撤回使得任务变得简单明了。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;放在一起看时，每个类型的累积语义会更清晰。考虑图7中第二个窗口的三个窗格（事件时间范围[12:02，12:04））。下表显示了三个支持的累积模式（每个窗格的值）将在三种支持的累积模式中显示（累积模式是图7中使用的特定模式）：&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;v2-f4349623d5efb7fc7688963dd87587c7_720w.jpg&quot; alt=&quot;img&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;表1. 使用图7的第二个窗口比较累积模式&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;**丢弃：**每个窗格仅包含在特定窗格中到达的值。因此，该窗口的最终值是最后一个窗格的值，而不是总和。但是，如果要自己计算所有独立窗格，将得到正确的答案22.这就是为什么丢弃模式下，下游消费者自己在窗格上执行聚合时很有用。&lt;&#x2F;li&gt;
&lt;li&gt;**累积：**如图7所示，每个窗格包含在该特定窗格中到达的值以及前一个窗格中的所有值。因此，最后一个窗格的值是该窗口所有值的总和22。但是，如果要自己累积该窗口的所有窗格，则会对来自窗格2和窗格1的输入进行双重和三重计数，给出的总和是不正确的51.这就是为什么累积模式是最有用的，可以简单地用新的值覆盖以前的值，新值已经包含了迄今为止收到的所有数据。&lt;&#x2F;li&gt;
&lt;li&gt;**累积和撤回：**每个窗格都包含一个新的累积模式值以及前一个窗格值的撤回。因此，观察到的最后（非撤回）值以及所有窗格（包括撤回）的总和是正确的答案22.这就是为什么撤回是如此强大。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;下边的代码示例了丢弃模式：&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;PCollection&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;KV&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;String&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Integer&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;gt; scores &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; input
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Window&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;into&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;FixedWindows&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;of&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Duration&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;standardMinutes&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt;)))
&lt;&#x2F;span&gt;&lt;span&gt;               &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;triggering&lt;&#x2F;span&gt;&lt;span&gt;(
&lt;&#x2F;span&gt;&lt;span&gt;                 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;AtWatermark&lt;&#x2F;span&gt;&lt;span&gt;()
&lt;&#x2F;span&gt;&lt;span&gt;                   &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;withEarlyFirings&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;AtPeriod&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Duration&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;standardMinutes&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;)))
&lt;&#x2F;span&gt;&lt;span&gt;                   &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;withLateFirings&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;AtCount&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;)))
&lt;&#x2F;span&gt;&lt;span&gt;               &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;discardingFiredPanes&lt;&#x2F;span&gt;&lt;span&gt;())
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Sum&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;integersPerKey&lt;&#x2F;span&gt;&lt;span&gt;());
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;清单7. 提前&#x2F;推迟触发的丢弃模式&lt;&#x2F;p&gt;
&lt;p&gt;在流式处理引擎上使用启发式水位线的效果如下所示：&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;image-20200924164229012.png&quot; alt=&quot;image-20200924164229012&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;center&gt;图9. 提前&#x2F;推迟触发的丢弃模式&lt;&#x2F;center&gt;
&lt;p&gt;虽然输出的整体形状类似于图7的累积模式版本，但请注意，此丢弃版本中的任何一个窗格都不重叠。因此，每个输出与其他输出是独立的。&lt;&#x2F;p&gt;
&lt;p&gt;如果我们想看撤回的效果，那么这个变化将会是类似的（但是，请注意，Google Cloud Dataflow 的这个功能特性仍在开发中，所以这个API中的命名是临时的，可能与最终发布版本不同）：&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;PCollection&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;KV&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;String&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Integer&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;gt; scores &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; input
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Window&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;into&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;FixedWindows&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;of&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Duration&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;standardMinutes&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt;)))
&lt;&#x2F;span&gt;&lt;span&gt;               &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;triggering&lt;&#x2F;span&gt;&lt;span&gt;(
&lt;&#x2F;span&gt;&lt;span&gt;                 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;AtWatermark&lt;&#x2F;span&gt;&lt;span&gt;()
&lt;&#x2F;span&gt;&lt;span&gt;                   &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;withEarlyFirings&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;AtPeriod&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Duration&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;standardMinutes&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;)))
&lt;&#x2F;span&gt;&lt;span&gt;                   &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;withLateFirings&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;AtCount&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;)))
&lt;&#x2F;span&gt;&lt;span&gt;               &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;accumulatingAndRetractingFiredPanes&lt;&#x2F;span&gt;&lt;span&gt;())
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Sum&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;integersPerKey&lt;&#x2F;span&gt;&lt;span&gt;());
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;清单8. 使用提前&#x2F;延迟触发的累积撤回模式&lt;&#x2F;p&gt;
&lt;p&gt;在流式处理引擎的执行如下所示：&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;image-20200924164301217.png&quot; alt=&quot;image-20200924164301217&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;center&gt;图10. 提前&#x2F;推迟触发的累积撤回&lt;&#x2F;center&gt;
&lt;p&gt;由于每个窗口的窗格都是重叠的，所以看起来有点乱。撤回用红色表示，它与蓝色窗格结合重叠，看起来略带紫色。在一个给定的窗格中略微移动了两个输出的值（并用逗号分隔），使它们更容易区分。&lt;&#x2F;p&gt;
&lt;p&gt;将图9,7（启发式）和10的三张图动画效果的最终图放在一起，提供了三种模式的很好的视觉对比：&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;image-20200925160508695.png&quot; alt=&quot;image-20200925160508695&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;center&gt;图11. 丢弃模式、累积模式、累积和撤回模式的对比&lt;&#x2F;center&gt;
&lt;p&gt;从左到右是丢弃模式、累积模式、累积 &amp;amp; 撤回模式，三种模式需要的存储和计算成本依次递增。可以想像，在存储和计算成本方面，呈现的顺序（丢弃，累积，累积 &amp;amp; 撤回）的模式都相继更昂贵。为此，累积提供了一种新的维度，在正确性，延迟和成本的之间进行权衡。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;xiao-jie&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#xiao-jie&quot; aria-label=&quot;Anchor link for: xiao-jie&quot;&gt;小结&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;到此为止，我们接触了4个问题：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;**What：要计算什么结果？**转换操作。&lt;&#x2F;li&gt;
&lt;li&gt;**Where：在事件时间中的哪个位置计算结果？**由窗口决定。&lt;&#x2F;li&gt;
&lt;li&gt;**When：在处理时间中的哪个时刻触发计算结果？**由水位线和触发器决定。&lt;&#x2F;li&gt;
&lt;li&gt;**How：如何修正结果？**通过各种累积模式。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;我们目前只了解了一种窗口类型：基于事件时间的固定窗口。 从Streaming 101中我们提到了多种窗口，其中有两个是今天要详细阐述的：&lt;strong&gt;基于处理时间的固定窗口&lt;&#x2F;strong&gt;，&lt;strong&gt;基于事件时间的会话窗口&lt;&#x2F;strong&gt;。&lt;&#x2F;p&gt;
&lt;p&gt;以下链接：https:&#x2F;&#x2F;zhuanlan.zhihu.com&#x2F;p&#x2F;60236077&lt;&#x2F;p&gt;
&lt;h2 id=&quot;when-where-ji-yu-chu-li-shi-jian-de-chuang-kou&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#when-where-ji-yu-chu-li-shi-jian-de-chuang-kou&quot; aria-label=&quot;Anchor link for: when-where-ji-yu-chu-li-shi-jian-de-chuang-kou&quot;&gt;When&#x2F;Where: 基于处理时间的窗口&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;处理时间窗口重要的原因有两个：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;对于某些使用情况，例如使用情况监控（例如，Web服务流量的 QPS），希望在收到数据流时分析数据，处理时间窗口绝对是适当的方法。&lt;&#x2F;li&gt;
&lt;li&gt;对于事件发生时间很重要的（例如，分析用户行为趋势，计费，评分等）的场景，处理时间窗口绝对是错误的选择，要能够清晰的区分哪些场景合适。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;因此，值得深入了解处理时间窗口和事件时间窗口之间的差异，特别是考虑到当今大多数流处理系统中广泛使用了处理时间窗口。&lt;&#x2F;p&gt;
&lt;p&gt;当使用类似于本文中提到的模型时，作为一等公民的窗口是严格基于事件时间的，有两种方法可以用来实现处理时间窗口：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;**触发器：**忽略事件时间（即，使用跨越所有事件时间的全局窗口），并使用触发器在处理时间轴中提供该窗口的快照。&lt;&#x2F;li&gt;
&lt;li&gt;**进入时间：**将进入时间作为数据到达系统的事件时间，并从此开始使用正常的事件时间窗口。 目前 Spark Streaming 就是这么做的。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;请注意，这两种方法或多或少等同，但在在多处理步骤Pipeline的情况下略有不同：在触发器版本中，每个处理步骤都使用处理时间切分窗口，步骤之间相互独立，因此例如窗口X中的数据为 一个阶段可能会在下一阶段的窗口 X-1 或 X+1 中; 在进入时间版本中，一旦将数据归于窗口X中，由于不同的处理步骤时间使用水位线同步处理进度（Dataflow的做法），在整个处理过程中都会一直属于窗口X。对微批来说（ Spark Streaming的做法），微批的边界或其他因素，是在引擎级别协调处理。&lt;&#x2F;p&gt;
&lt;p&gt;正如一直强调的，处理时间窗口的最大缺点是，当输入的顺序发生变化时，窗口的内容会发生变化。 为了更具体地说明这一点，我们来看这三种用例：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;事件时间窗口&lt;&#x2F;strong&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;使用触发器的处理时间窗口&lt;&#x2F;strong&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;使用进入时间的处理时间窗口&lt;&#x2F;strong&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;我们将每个窗口应用到两个不同的输入数据集（总共有6个变体）。 两个输入数据包含完全相同的事件（即相同的值，发生在相同的事件时间），但顺序不同。 第1个数据集跟我们之前例子中的顺序一致，颜色为白色；第二个数据集调整了事件的处理顺序，如下图12所示，为紫色。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;image-20200924164831304.png&quot; alt=&quot;image-20200924164831304&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;image-20200925160925836.png&quot; style=&quot;zoom:68%;&quot; &#x2F;&gt;
&lt;center&gt;图12. 改变了处理时间，其他不变&lt;&#x2F;center&gt;
&lt;h2 id=&quot;ji-yu-shi-jian-shi-jian-de-chuang-kou&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#ji-yu-shi-jian-shi-jian-de-chuang-kou&quot; aria-label=&quot;Anchor link for: ji-yu-shi-jian-shi-jian-de-chuang-kou&quot;&gt;基于事件时间的窗口&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;为了建立一个基线，我们首先将基于事件时间的使用启发式Watermark的固定窗口处理两个顺序不同的数据集。 我们将重用清单5 &#x2F; 图7 中的提前&#x2F;延迟处理的代码，从而得到如下结果。 左边实际上是我们以前看到的; 右边是第二个数据集的结果。 这里要注意的一点是：尽管输出的整体形状不同（由于处理时间不同），&lt;strong&gt;四个窗口的最终结果保持不变&lt;&#x2F;strong&gt;：14,22,3和12：&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;image-20200924164906636.png&quot; alt=&quot;image-20200924164906636&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;center&gt;图13. 处理时间顺序不同的事件时间窗口&lt;&#x2F;center&gt;
&lt;h2 id=&quot;shi-yong-hong-fa-qi-de-chu-li-shi-jian-chuang-kou&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#shi-yong-hong-fa-qi-de-chu-li-shi-jian-chuang-kou&quot; aria-label=&quot;Anchor link for: shi-yong-hong-fa-qi-de-chu-li-shi-jian-chuang-kou&quot;&gt;使用触发器的处理时间窗口&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;现在我们来比较上述两种处理时间方法。 首先，将尝试触发器方法。使用处理时间窗口达到效果，需要考虑以下三个方面：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;窗口:&lt;&#x2F;strong&gt; 使用全局事件时间窗口，本质上是以事件窗格模拟处理时间窗口。.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;触发:&lt;&#x2F;strong&gt; 根据处理时间窗口的期望大小，在处理时间维度上周期性触发。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;累积:&lt;&#x2F;strong&gt; 使用丢弃模式来保持窗格彼此独立，从而让每个窗格都像一个独立的处理时间窗口。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;相应的代码看起来像清单9; 请注意，全局窗口是默认的，因此没有具体的覆盖策略：&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;PCollection&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;KV&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;String&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Integer&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;gt; scores &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; input
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Window&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;triggering&lt;&#x2F;span&gt;&lt;span&gt;(
&lt;&#x2F;span&gt;&lt;span&gt;                  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;Repeatedly&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;AtPeriod&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Duration&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;standardMinutes&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt;))))
&lt;&#x2F;span&gt;&lt;span&gt;               &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;discardingFiredPanes&lt;&#x2F;span&gt;&lt;span&gt;())
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Sum&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;integersPerKey&lt;&#x2F;span&gt;&lt;span&gt;());
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;清单9. 在全局事件窗口上使用重发触发器、丢弃模式，模拟处理时间窗口&lt;&#x2F;p&gt;
&lt;p&gt;当流处理引擎上输入两个不同顺序的数据集的时候，结果如下图14所示。关于此图有两点有点意思：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;由于我们基于事件时间的窗格模拟处理时间窗口，所以在处理时间轴中勾画了“窗口”，这意味着窗口宽度是在Y轴上度量而不是X轴。&lt;&#x2F;li&gt;
&lt;li&gt;由于处理时间窗口对输入数据的顺序敏感，在两个数据集中，每个窗口包含的数据都是不同的，即时事件发生的时间相同。 在左边我们得到12,21,18，而在右边我们得到7,36,4。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;image-20200924164934945.png&quot; alt=&quot;image-20200924164934945&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;center&gt;图14. 处理时间顺序不同的处理时间窗口&lt;&#x2F;center&gt;
&lt;h2 id=&quot;shi-yong-jin-ru-shi-jian-de-chu-li-shi-jian-chuang-kou&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#shi-yong-jin-ru-shi-jian-de-chu-li-shi-jian-chuang-kou&quot; aria-label=&quot;Anchor link for: shi-yong-jin-ru-shi-jian-de-chu-li-shi-jian-chuang-kou&quot;&gt;&lt;strong&gt;使用进入时间的处理时间窗口&lt;&#x2F;strong&gt;&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;最后，我们来看看通过将输入数据的事件时间映射为入口时间来实现的处理时间窗口。在代码方面，这里有四个方面值得一提：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;**时移：**当数据到达时，数据的事件时间被入口时间（数据到达时的处理时间）覆盖。请注意，我们目前在Dataflow中没有标准API来处理时间，尽管我们接下来会可能会使用伪代码I &#x2F; O源中的虚构方法来代表下面的代码。对于Google Cloud Pub &#x2F; Sub，只需在发布消息时将消息的timestampLabel字段留空;对于其他来源，需要查阅源代码文档。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;窗口:&lt;&#x2F;strong&gt; 返回使用标准的固定事件时间窗口。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;触发:&lt;&#x2F;strong&gt; 由于入口时间提供了计算理想Watermark的能力，所以可以使用默认触发器，在这种情况下，当Watermark通过窗口的末尾时，触发器会隐式触发一次。&lt;&#x2F;li&gt;
&lt;li&gt;**累积模式：**由于我们每个窗口只有一个输出，所以累积模式是无关紧要的。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;实际的代码可能是这样：&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;PCollection&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;String&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt; raw &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;IO&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;read&lt;&#x2F;span&gt;&lt;span&gt;()&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;withIngressTimeAsTimestamp&lt;&#x2F;span&gt;&lt;span&gt;();
&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;PCollection&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;KV&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;String&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Integer&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;gt; input &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; raw&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;ParDo&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;of&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;new &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;ParseFn&lt;&#x2F;span&gt;&lt;span&gt;())&lt;&#x2F;span&gt;&lt;span style=&quot;background-color:#ff79c6;color:#f8f8f0;&quot;&gt;;&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;PCollection&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;KV&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;String&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Integer&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;gt; scores &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; input
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Window&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;into&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;FixedWindows&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;of&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Duration&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;standardMinutes&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;2&lt;&#x2F;span&gt;&lt;span&gt;))))
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Sum&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;integersPerKey&lt;&#x2F;span&gt;&lt;span&gt;());
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;清单10. 显式设置默认触发器&lt;&#x2F;p&gt;
&lt;p&gt;在流式引擎上的执行将如下面的图15所示。当数据到达时，它们的事件时间被覆盖为它们的进入时间（即到达时的处理时间），导致在理想Watermark线上的向右水平移位。该图中有趣的注释：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;与其他处理时间窗口示例一样，当输入的顺序变化时，即使输入的值和事件时间保持不变，我们也会得到不同的结果。&lt;&#x2F;li&gt;
&lt;li&gt;与其他示例不同，窗口在事件时间维度上（因此沿X轴）重新划分了。尽管如此，这些窗口并不是原生的事件时间窗口;而是我们将处理时间简单地映射到事件时间上，擦除每个输入的原始记录，并用新的记录代替它，而事件的时间是表示Pipeline首次收到到数据的时间。&lt;&#x2F;li&gt;
&lt;li&gt;尽管如此，由于使用了Watermark，触发器仍然在与之前的处理时间示例完全相同的时间触发。此外，所产生的输出值与该示例相同，如左侧的12,21,18，右侧的7,36,4。&lt;&#x2F;li&gt;
&lt;li&gt;由于使用入口时间，所以理想的Watermark是可能的，所以实际的Watermark与理想的Watermark相匹配，斜率为1，向右上方延伸。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;image-20200924165003099.png&quot; alt=&quot;image-20200924165003099&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;center&gt;图15. 使用入口时间的处理时间窗口，处理两个内容一样但顺序不同的数据集&lt;&#x2F;center&gt;
&lt;p&gt;虽然看到不同的方法可以实现处理时间窗口很有趣，但是这里的大部分内容是自从第一篇文章以来一直提到的：事件时间窗口与顺序无关，至少在极限情况下如此（实际 在处理过程中的窗格可能会不同，直到输入完成），而处理时间窗口不是。 &lt;strong&gt;如果关心事件实际发生的时间，必须使用事件时间窗口，否则计算结果是无意义的。&lt;&#x2F;strong&gt; &lt;&#x2F;p&gt;
&lt;h2 id=&quot;where-hui-hua-chuang-kou&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#where-hui-hua-chuang-kou&quot; aria-label=&quot;Anchor link for: where-hui-hua-chuang-kou&quot;&gt;Where**: 会话窗口**&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;现在来看一下我最喜欢的特性之一：动态的、数据驱动的窗口，称为会话窗口。&lt;&#x2F;p&gt;
&lt;p&gt;会话是一种特殊类型的窗口，它捕获数据中的一段活动，在不活动一段时间后窗口中止。 它们在数据分析中特别有用，因为可以让我们看到某一个特定用户在一段时间内的行为。 这可以让我们分析会话内的活动的相关性，基于会话的长度来推断用户的参与水平等。&lt;&#x2F;p&gt;
&lt;p&gt;从窗口的角度来看，会话窗口在两个方面很有趣：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;它们是数据驱动窗口的示例&lt;&#x2F;strong&gt;：窗口的位置和大小是输入数据本身来决定，而不是在时间内基于某些预定义模式，如固定和滑动窗口。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;它们也是不对齐窗口的示例&lt;&#x2F;strong&gt;，即窗口并不将数据一视同仁，而是将数据的特定子集（例如，每个用户）进行切分。 这与对齐的窗口（如固定和滑动窗口）形成对比，这些窗口通常对数据一视同仁，进行切分。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;对于一些用例，可以提前在一个会话中的数据中标记一个共同标识符（例如，在线的的视频播放器，定时发出心跳包，心跳包内容是服务质量信息，对于任何给定的一次观看，分配一个会话ID，所有的心跳信息中都添加这个会话ID）。在这种情况下，会话更容易构建(按照会话ID区分会话)，本质上是按键分组的一种形式。&lt;&#x2F;p&gt;
&lt;p&gt;然而，在更一般的情况下（即，实际会话提前并不知道），&lt;strong&gt;会话只能从从数据中构建出来。当处理无序数据时，这变得特别棘手。&lt;&#x2F;strong&gt; &lt;&#x2F;p&gt;
&lt;p&gt;提供一般会话支持的关键是，根据定义，完整的会话窗口是一组较小的重叠窗口的组合，每个窗口包含单个记录，每个记录中的每个记录与下一个记录的间隔不超过预先定义的间隔。因此，即使会话中的数据乱序了，也可以简单地通过将各个数据的重叠窗口合并在一起来构建最终会话。&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;v2-32af9ecb9ae779eaafb3bb39524834b1_720w.jpg&quot; alt=&quot;img&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;center&gt;图16. 未合并的原始会话窗口和合并之后的会话窗口&lt;&#x2F;center&gt;
&lt;p&gt;下面来看一个代码示例，以清单8中的代码为基础，修改为使用会话窗口：&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; style=&quot;background-color:#282a36;color:#f8f8f2;&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;PCollection&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;KV&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;String&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Integer&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;gt; scores &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;=&lt;&#x2F;span&gt;&lt;span&gt; input
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Window&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;into&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Sessions&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;withGapDuration&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Duration&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;standardMinutes&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;)))
&lt;&#x2F;span&gt;&lt;span&gt;               &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;triggering&lt;&#x2F;span&gt;&lt;span&gt;(
&lt;&#x2F;span&gt;&lt;span&gt;                 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;AtWatermark&lt;&#x2F;span&gt;&lt;span&gt;()
&lt;&#x2F;span&gt;&lt;span&gt;                   &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;withEarlyFirings&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;AtPeriod&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Duration&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;standardMinutes&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;)))
&lt;&#x2F;span&gt;&lt;span&gt;                   &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;withLateFirings&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;AtCount&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bd93f9;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;)))
&lt;&#x2F;span&gt;&lt;span&gt;               &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;accumulatingAndRetractingFiredPanes&lt;&#x2F;span&gt;&lt;span&gt;())
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;font-style:italic;color:#66d9ef;&quot;&gt;Sum&lt;&#x2F;span&gt;&lt;span style=&quot;color:#ff79c6;&quot;&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#50fa7b;&quot;&gt;integersPerKey&lt;&#x2F;span&gt;&lt;span&gt;());
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;清单11. 基于会话窗口，提前和延迟触发，使用累加和撤销模式&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;在流处理引擎上执行如下所示：&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;image-20200924165052916.png&quot; alt=&quot;image-20200924165052916&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;center&gt;图17. 基于会话窗口，提前和延迟触发，使用累加和撤销模式&lt;&#x2F;center&gt;
&lt;p&gt;上图中的具体过程如下：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;当遇到具有值为5的第一个记录时，它被放置在从该记录的事件时间开始的单个原始会话窗口中，窗口宽度为会话窗口的超时时长，例如超时时长为1分钟，会话窗口宽度为1分钟。在后边遇到的任何窗口与该窗口重叠的都应该隶属于同一个会话，并且合并到此窗口中。&lt;&#x2F;li&gt;
&lt;li&gt;第二个到达记录是7，它类似地放在自己的原始会话窗口中，因为它不与5的窗口重叠。&lt;&#x2F;li&gt;
&lt;li&gt;同时，Watermark已经过第一个窗口的末尾，所以在12:06之前，包含值5的窗口被物化为准时的窗口。此后不久，当处理时间正好为12:06的时候，第二个窗口也被物化为具有值7的推测结果。&lt;&#x2F;li&gt;
&lt;li&gt;我们接下来观察一系列的记录，3,4和3，这3个会话窗口相互重叠。因此，它们都被合并在一起，并且在12:07的时候提前触发，发出一个值为10的单个窗口。&lt;&#x2F;li&gt;
&lt;li&gt;当8到达不久之后，它与具有值7的会话和与值10的会话重叠。所有这三个因此被合并在一起，形成具有值25的新的组合会话。当Watermark然后通过这个会话的末尾时，它物化了一个包含值25的新会话以及之前发布的两个窗口的撤消，但后来被并入它：7和10。&lt;&#x2F;li&gt;
&lt;li&gt;当9到达延迟到达时，类似的舞蹈发生在9号晚上，与值为5的原始会话，和值为25的会话变成了一个更大的值为39的一个较大的会话。值39和窗口25、5的撤销被立即延迟触发。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;就这么简单地将流处理模型分解为不同的、可组合的部分，这还真是了不起啊。至此，你可以将注意力放在业务逻辑上了，而非那些数据形式的细节。&lt;&#x2F;p&gt;
&lt;h2 id=&quot;zhong-yu-dao-jie-wei-liao-hao-kai-xin-a&quot;&gt;&lt;a class=&quot;zola-anchor&quot; href=&quot;#zhong-yu-dao-jie-wei-liao-hao-kai-xin-a&quot; aria-label=&quot;Anchor link for: zhong-yu-dao-jie-wei-liao-hao-kai-xin-a&quot;&gt;终于到结尾了，好开心啊&lt;&#x2F;a&gt;&lt;&#x2F;h2&gt;
&lt;p&gt;我讲完了所有的例子。此处应有掌声！您现在应该已经步入了健壮的流处理的世界中了，准备好高飞吧。在您离开之前，我想快速回顾一遍，防止您忘了。首先，我提到了几个重要的概念：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;事件时间与处理时间&lt;&#x2F;strong&gt;：事件发生时间和被数据处理系统处理的时间之间的重要区别。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;窗口&lt;&#x2F;strong&gt;：通常使用的方法是通过在时间边界（通过处理时间或事件时间）对其进行切分来管理无限数据，尽管我们将数据流模型中的窗口定义缩小仅表示事件时间内）。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;水位线&lt;&#x2F;strong&gt;：事件时间进度的概念，为在无限数据上运行的乱序处理系统提供了估计窗口数据完整性的手段。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;触发器&lt;&#x2F;strong&gt;：用于精确指定在合适计算窗口结果的机制，对于特定用例是有意义的。&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;累积&lt;&#x2F;strong&gt;：在单个窗口被多次触发计算的情况下，随着触发持续的修正窗口结果。&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;其次，我们用来构建我们探索的四个问题：&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;What&lt;&#x2F;strong&gt; 要计算出什么结果？= 转换&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Where&lt;&#x2F;strong&gt; 事件在哪里结果计算？ = 窗口&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;When&lt;&#x2F;strong&gt; 在处理时间维度上什么时候计算窗口结果？ = 水位线 + 触发器&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;How&lt;&#x2F;strong&gt; 如何不断的修正计算结果？= 累积&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;第三，最后一点，这种流处理模式所带来的灵活性（最终，需要做的是在处理数据的各种要素之间取得平衡，如正确性，延迟和成本），回顾一下，通过少量的代码修改，对相同的数据集处理而得到的输出的变化如下：&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;wendajiang.github.io&#x2F;pics&#x2F;streamprocess&#x2F;image-20200925162921517.png&quot; alt=&quot;image-20200925162921517&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;感谢您的耐心与兴趣，下次再会！&lt;&#x2F;p&gt;
</content>
    </entry>
</feed>
